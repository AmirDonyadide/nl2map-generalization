{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec34f9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Repo root: /Users/amirdonyadide/Documents/GitHub/IMGOFUP\n",
      "ðŸ“¦ Using src from: /Users/amirdonyadide/Documents/GitHub/IMGOFUP/src\n",
      "ðŸ”§ PROJ_ROOT env set to: /Users/amirdonyadide/Documents/GitHub/IMGOFUP\n"
     ]
    }
   ],
   "source": [
    "# ===================== 04_evaluate â€” CELL 0: Bootstrap =====================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path.cwd().resolve()\n",
    "REPO_ROOT = None\n",
    "for candidate in [p, *p.parents]:\n",
    "    if (candidate / \"src\" / \"imgofup\").is_dir():\n",
    "        REPO_ROOT = candidate\n",
    "        break\n",
    "if REPO_ROOT is None:\n",
    "    raise RuntimeError(\"Could not find repo root (no 'src/imgofup' found).\")\n",
    "\n",
    "SRC_DIR = REPO_ROOT / \"src\"\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "os.environ[\"PROJ_ROOT\"] = str(REPO_ROOT)\n",
    "\n",
    "print(\"ðŸ“¦ Repo root:\", REPO_ROOT)\n",
    "print(\"ðŸ“¦ Using src from:\", SRC_DIR)\n",
    "print(\"ðŸ”§ PROJ_ROOT env set to:\", os.environ[\"PROJ_ROOT\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33cbc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded EXPERIMENTS: ['openai_prompt_only', 'use_prompt_only', 'map_only', 'use_map', 'openai_map']\n"
     ]
    }
   ],
   "source": [
    "# ===================== 04_evaluate â€” CELL 1: Load EXPERIMENTS =====================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "NOTEBOOKS_DIR = Path.cwd().resolve()\n",
    "if not (NOTEBOOKS_DIR / \"experiments.py\").is_file():\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing notebooks/experiments.py. Create it to share EXPERIMENTS across notebooks.\"\n",
    "    )\n",
    "\n",
    "from experiments import make_experiments\n",
    "\n",
    "EXPERIMENTS = make_experiments(REPO_ROOT)\n",
    "\n",
    "for cfg in EXPERIMENTS.values():\n",
    "    cfg[\"train_out\"] = Path(cfg[\"train_out\"]).resolve()\n",
    "    cfg[\"model_out\"] = Path(cfg[\"model_out\"]).resolve()\n",
    "\n",
    "print(\"âœ… Loaded EXPERIMENTS:\", list(EXPERIMENTS.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea1bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded eval data for: ['openai_prompt_only', 'use_prompt_only', 'map_only', 'use_map', 'openai_map']\n"
     ]
    }
   ],
   "source": [
    "# ===================== 04_evaluate â€” CELL 2: Load Stage-2 cache + bundle paths =====================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from imgofup.config.constants import (\n",
    "    MAPS_ID_COL,\n",
    "    PARAM_TARGET_NAME,\n",
    ")\n",
    "\n",
    "STAGE2_DIRNAME = \"cache_stage2\"\n",
    "BUNDLE_NAME = \"cls_plus_regressors.joblib\"\n",
    "\n",
    "# Load per-experiment cached test set + labels\n",
    "EVAL_DATA = {}  # exp_name -> dict with X_test_s, df_test, y_test_cls, class_names, bundle_path\n",
    "\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "    model_out = Path(cfg[\"model_out\"]).expanduser().resolve()\n",
    "    cache_dir = model_out / STAGE2_DIRNAME\n",
    "    bundle_path = model_out / BUNDLE_NAME\n",
    "\n",
    "    if not cache_dir.is_dir():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing stage2 cache for {exp_name} at {cache_dir}. \"\n",
    "            \"Run 02 (cache saving cell) first.\"\n",
    "        )\n",
    "    if not bundle_path.is_file():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing bundle for {exp_name} at {bundle_path}. \"\n",
    "            \"Run 03 (bundle saving) first.\"\n",
    "        )\n",
    "\n",
    "    zX = np.load(cache_dir / \"X_scaled.npz\", allow_pickle=True)\n",
    "    X_test_s = np.asarray(zX[\"X_test_s\"], dtype=np.float64)\n",
    "\n",
    "    zL = np.load(cache_dir / \"labels.npz\", allow_pickle=True)\n",
    "    y_test_cls = np.asarray(zL[\"y_test_cls\"], dtype=int)\n",
    "\n",
    "    class_names = json.loads((cache_dir / \"class_names.json\").read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    df_test = pd.read_parquet(cache_dir / \"df_test.parquet\")\n",
    "\n",
    "    # basic sanity\n",
    "    if X_test_s.shape[0] != len(y_test_cls) or len(y_test_cls) != len(df_test):\n",
    "        raise ValueError(\n",
    "            f\"{exp_name}: mismatch lengths: X_test={X_test_s.shape[0]}, y_test={len(y_test_cls)}, df_test={len(df_test)}\"\n",
    "        )\n",
    "    if PARAM_TARGET_NAME not in df_test.columns:\n",
    "        raise KeyError(f\"{exp_name}: df_test missing '{PARAM_TARGET_NAME}' needed for param evaluation.\")\n",
    "    if MAPS_ID_COL not in df_test.columns:\n",
    "        raise KeyError(f\"{exp_name}: df_test missing '{MAPS_ID_COL}' (useful sanity).\")\n",
    "\n",
    "    EVAL_DATA[exp_name] = {\n",
    "        \"X_test_s\": X_test_s,\n",
    "        \"df_test\": df_test,\n",
    "        \"y_test_cls\": y_test_cls,\n",
    "        \"class_names\": class_names,\n",
    "        \"bundle_path\": str(bundle_path),\n",
    "        \"model_out\": str(model_out),\n",
    "    }\n",
    "\n",
    "print(\"âœ… Loaded eval data for:\", list(EVAL_DATA.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d5760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classifier comparison (sorted by TEST macro-F1) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>model_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai_prompt_only</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.964730</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.914519</td>\n",
       "      <td>/Users/amirdonyadide/Documents/GitHub/IMGOFUP/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use_prompt_only</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947169</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.876250</td>\n",
       "      <td>/Users/amirdonyadide/Documents/GitHub/IMGOFUP/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai_map</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.944360</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.866066</td>\n",
       "      <td>/Users/amirdonyadide/Documents/GitHub/IMGOFUP/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>use_map</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.889212</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.766735</td>\n",
       "      <td>/Users/amirdonyadide/Documents/GitHub/IMGOFUP/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>map_only</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.378513</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.257236</td>\n",
       "      <td>/Users/amirdonyadide/Documents/GitHub/IMGOFUP/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           experiment   val_acc  val_f1_macro  test_acc  test_f1_macro  \\\n",
       "0  openai_prompt_only  0.964912      0.964730  0.912281       0.914519   \n",
       "1     use_prompt_only  0.947368      0.947169  0.877193       0.876250   \n",
       "2          openai_map  0.947368      0.944360  0.859649       0.866066   \n",
       "3             use_map  0.894737      0.889212  0.754386       0.766735   \n",
       "4            map_only  0.385965      0.378513  0.263158       0.257236   \n",
       "\n",
       "                                          model_path  \n",
       "0  /Users/amirdonyadide/Documents/GitHub/IMGOFUP/...  \n",
       "1  /Users/amirdonyadide/Documents/GitHub/IMGOFUP/...  \n",
       "2  /Users/amirdonyadide/Documents/GitHub/IMGOFUP/...  \n",
       "3  /Users/amirdonyadide/Documents/GitHub/IMGOFUP/...  \n",
       "4  /Users/amirdonyadide/Documents/GitHub/IMGOFUP/...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===================== 04_evaluate â€” CELL 3: Classifier comparison table =====================\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "rows = []\n",
    "\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "    meta_path = Path(cfg[\"model_out\"]).expanduser().resolve() / \"classifier_meta.json\"\n",
    "\n",
    "    if not meta_path.is_file():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing classifier_meta.json for experiment '{exp_name}' at:\\n  {meta_path}\\n\"\n",
    "            \"Run 03_train_models.ipynb (classifier training) first.\"\n",
    "        )\n",
    "\n",
    "    meta = json.loads(meta_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    rows.append({\n",
    "        \"experiment\": exp_name,\n",
    "        \"val_acc\": meta.get(\"best_val\", {}).get(\"acc\"),\n",
    "        \"val_f1_macro\": meta.get(\"best_val\", {}).get(\"macro_f1\"),\n",
    "        \"test_acc\": meta.get(\"test\", {}).get(\"acc\"),\n",
    "        \"test_f1_macro\": meta.get(\"test\", {}).get(\"macro_f1\"),\n",
    "        \"model_path\": meta.get(\"model_path\"),\n",
    "    })\n",
    "\n",
    "df_clf = pd.DataFrame(rows).sort_values(\n",
    "    by=\"test_f1_macro\",\n",
    "    ascending=False,\n",
    "    na_position=\"last\",\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Classifier comparison (sorted by TEST macro-F1) ===\")\n",
    "df_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb662efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RMSE (raw units; likely in [0,1] if param_norm) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simplify</th>\n",
       "      <th>select</th>\n",
       "      <th>aggregate</th>\n",
       "      <th>displace</th>\n",
       "      <th>mean_rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>map_only</th>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_map</th>\n",
       "      <td>0.004395</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.002916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_prompt_only</th>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.002969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai_prompt_only</th>\n",
       "      <td>0.004330</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.002991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai_map</th>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.003019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    simplify    select  aggregate  displace  mean_rmse\n",
       "experiment                                                            \n",
       "map_only            0.004217  0.000253   0.003658  0.003258   0.002847\n",
       "use_map             0.004395  0.000249   0.003710  0.003310   0.002916\n",
       "use_prompt_only     0.004347  0.000362   0.003499  0.003669   0.002969\n",
       "openai_prompt_only  0.004330  0.000359   0.003562  0.003713   0.002991\n",
       "openai_map          0.004640  0.000250   0.003801  0.003386   0.003019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RMSE as percent of [0,1] range ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simplify RMSE (%)</th>\n",
       "      <th>select RMSE (%)</th>\n",
       "      <th>aggregate RMSE (%)</th>\n",
       "      <th>displace RMSE (%)</th>\n",
       "      <th>Mean RMSE (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>map_only</th>\n",
       "      <td>0.422</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_map</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_prompt_only</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai_prompt_only</th>\n",
       "      <td>0.433</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai_map</th>\n",
       "      <td>0.464</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    simplify RMSE (%)  select RMSE (%)  aggregate RMSE (%)  \\\n",
       "experiment                                                                   \n",
       "map_only                        0.422            0.025               0.366   \n",
       "use_map                         0.440            0.025               0.371   \n",
       "use_prompt_only                 0.435            0.036               0.350   \n",
       "openai_prompt_only              0.433            0.036               0.356   \n",
       "openai_map                      0.464            0.025               0.380   \n",
       "\n",
       "                    displace RMSE (%)  Mean RMSE (%)  \n",
       "experiment                                            \n",
       "map_only                        0.326          0.285  \n",
       "use_map                         0.331          0.292  \n",
       "use_prompt_only                 0.367          0.297  \n",
       "openai_prompt_only              0.371          0.299  \n",
       "openai_map                      0.339          0.302  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================== 04_evaluate â€” CELL 4: Regressor comparison table (RMSE by operator) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "FIXED_CLASSES = [\"simplify\", \"select\", \"aggregate\", \"displace\"]\n",
    "ops = list(FIXED_CLASSES)\n",
    "\n",
    "bund_cv = {}\n",
    "\n",
    "for exp_name, ed in EVAL_DATA.items():\n",
    "    bundle_path = Path(ed[\"bundle_path\"]).expanduser().resolve()\n",
    "    pack = joblib.load(bundle_path)\n",
    "\n",
    "    # your bundle is produced by save_cls_plus_regressors_bundle â†’ cv_summary is top-level\n",
    "    cv_summary = pack.get(\"cv_summary\", None) if isinstance(pack, dict) else None\n",
    "\n",
    "    if cv_summary is None:\n",
    "        raise ValueError(\n",
    "            f\"{exp_name}: bundle has no cv_summary. \"\n",
    "            f\"Bundle type: {type(pack)} | keys: {list(pack.keys()) if isinstance(pack, dict) else 'n/a'}\"\n",
    "        )\n",
    "\n",
    "    bund_cv[exp_name] = cv_summary\n",
    "\n",
    "def get_rmse_param(cv_summary, op_name):\n",
    "    d = cv_summary.get(op_name, cv_summary.get(str(op_name), {}))\n",
    "    if not isinstance(d, dict):\n",
    "        return np.nan\n",
    "\n",
    "    for k in [\"rmse_param_norm\", \"rmse_param\", \"rmse_param_units\", \"rmse_param_norm_units\", \"rmse_param_norm_units_mean\"]:\n",
    "        if k in d and d[k] is not None:\n",
    "            return float(d[k])\n",
    "\n",
    "    # fallback: any rmse+param-ish\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, (int, float)) and (\"rmse\" in k.lower()) and (\"param\" in k.lower()):\n",
    "            return float(v)\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "rows = []\n",
    "for exp_name, cv_summary in bund_cv.items():\n",
    "    row = {\"experiment\": exp_name}\n",
    "    for op in ops:\n",
    "        row[op] = get_rmse_param(cv_summary, op)\n",
    "    rows.append(row)\n",
    "\n",
    "df_rmse = pd.DataFrame(rows).set_index(\"experiment\")\n",
    "df_rmse[\"mean_rmse\"] = df_rmse[ops].mean(axis=1)\n",
    "\n",
    "df_rmse_sorted = df_rmse.sort_values(\"mean_rmse\", ascending=True)\n",
    "\n",
    "df_pct = (df_rmse_sorted * 100).round(3)\n",
    "rename_ops = {op: f\"{op} RMSE (%)\" for op in ops}\n",
    "rename_ops[\"mean_rmse\"] = \"Mean RMSE (%)\"\n",
    "df_pct = df_pct.rename(columns=rename_ops)\n",
    "\n",
    "print(\"\\n=== RMSE (raw units; likely in [0,1] if param_norm) ===\")\n",
    "display(df_rmse_sorted.round(6))\n",
    "\n",
    "print(\"\\n=== RMSE as percent of [0,1] range ===\")\n",
    "display(df_pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69f5e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>op_acc</th>\n",
       "      <th>param_rmse_if_op_correct</th>\n",
       "      <th>param_mae_if_op_correct</th>\n",
       "      <th>joint_success@0.05</th>\n",
       "      <th>rmse_penalized_all</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_op_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai_prompt_only</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.296187</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use_prompt_only</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.350450</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai_map</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.374647</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>use_map</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.495603</td>\n",
       "      <td>57</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>map_only</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.858396</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           experiment    op_acc  param_rmse_if_op_correct  \\\n",
       "0  openai_prompt_only  0.912281                  0.002811   \n",
       "1     use_prompt_only  0.877193                  0.002993   \n",
       "2          openai_map  0.859649                  0.003280   \n",
       "3             use_map  0.754386                  0.003401   \n",
       "4            map_only  0.263158                  0.002274   \n",
       "\n",
       "   param_mae_if_op_correct  joint_success@0.05  rmse_penalized_all  n_test  \\\n",
       "0                 0.002044            0.912281            0.296187      57   \n",
       "1                 0.002168            0.877193            0.350450      57   \n",
       "2                 0.002322            0.859649            0.374647      57   \n",
       "3                 0.002483            0.754386            0.495603      57   \n",
       "4                 0.001652            0.263158            0.858396      57   \n",
       "\n",
       "   n_op_correct  \n",
       "0            52  \n",
       "1            50  \n",
       "2            49  \n",
       "3            43  \n",
       "4            15  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===================== 04_evaluate â€” CELL 5: End-to-end evaluation (TEST) =====================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from imgofup.config.constants import PARAM_TARGET_NAME\n",
    "\n",
    "TOL = 0.05  # tolerance in param_norm units (0..1)\n",
    "\n",
    "def _predict_param(reg_and_scaler, Xi):\n",
    "    if isinstance(reg_and_scaler, (tuple, list)):\n",
    "        reg = reg_and_scaler[0]\n",
    "        y_scaler = reg_and_scaler[1] if len(reg_and_scaler) > 1 else None\n",
    "    else:\n",
    "        reg = reg_and_scaler\n",
    "        y_scaler = None\n",
    "\n",
    "    y_hat = float(reg.predict(Xi)[0])\n",
    "\n",
    "    if y_scaler is not None:\n",
    "        try:\n",
    "            y_hat = float(y_scaler.inverse_transform(np.array([[y_hat]], dtype=float))[0, 0])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return y_hat\n",
    "\n",
    "def _safe_pack_get(pack, key, default=None):\n",
    "    if isinstance(pack, dict):\n",
    "        return pack.get(key, default)\n",
    "    return getattr(pack, key, default)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "    ed = EVAL_DATA[exp_name]\n",
    "    bundle = joblib.load(ed[\"bundle_path\"])\n",
    "\n",
    "    clf = _safe_pack_get(bundle, \"classifier\")\n",
    "    regs = _safe_pack_get(bundle, \"regressors_by_class\")\n",
    "    class_names = [str(x) for x in _safe_pack_get(bundle, \"class_names\", [])]\n",
    "\n",
    "    if clf is None or regs is None or not class_names:\n",
    "        raise ValueError(\n",
    "            f\"{exp_name}: bundle missing required keys. \"\n",
    "            f\"Have classifier={clf is not None}, regressors_by_class={regs is not None}, class_names={len(class_names)}\"\n",
    "        )\n",
    "\n",
    "    X_test = ed[\"X_test_s\"]\n",
    "    y_true_cls = ed[\"y_test_cls\"]\n",
    "    df_test = ed[\"df_test\"]\n",
    "\n",
    "    y_true_param = df_test[PARAM_TARGET_NAME].to_numpy(dtype=float)\n",
    "\n",
    "    # Predict operator\n",
    "    y_pred_cls = clf.predict(X_test)\n",
    "    op_acc = float((y_pred_cls == y_true_cls).mean())\n",
    "\n",
    "    pred_names = [class_names[int(i)] for i in y_pred_cls]\n",
    "    true_names = [class_names[int(i)] for i in y_true_cls]\n",
    "\n",
    "    # Predict param using regressor of predicted operator\n",
    "    y_pred_param = np.zeros_like(y_true_param, dtype=float)\n",
    "\n",
    "    regs_norm = {str(k).strip().lower(): v for k, v in regs.items()}\n",
    "\n",
    "    for i, op in enumerate(pred_names):\n",
    "        key = str(op).strip().lower()\n",
    "        if key not in regs_norm:\n",
    "            raise KeyError(\n",
    "                f\"{exp_name}: no regressor for predicted class '{op}'. \"\n",
    "                f\"Available keys: {list(regs_norm.keys())}\"\n",
    "            )\n",
    "        Xi = X_test[i:i+1]\n",
    "        y_pred_param[i] = _predict_param(regs_norm[key], Xi)\n",
    "\n",
    "    abs_err = np.abs(y_pred_param - y_true_param)\n",
    "    correct_mask = (np.array(pred_names) == np.array(true_names))\n",
    "\n",
    "    # Param RMSE/MAE only when operator correct\n",
    "    if correct_mask.any():\n",
    "        rmse_cond = float(np.sqrt(np.mean((y_pred_param[correct_mask] - y_true_param[correct_mask]) ** 2)))\n",
    "        mae_cond  = float(np.mean(abs_err[correct_mask]))\n",
    "    else:\n",
    "        rmse_cond, mae_cond = np.nan, np.nan\n",
    "\n",
    "    # Joint metric: operator correct AND parameter within tolerance\n",
    "    joint_success = float(np.mean(correct_mask & (abs_err <= TOL)))\n",
    "\n",
    "    # Penalized RMSE over all: if op wrong, set error=1 (max on [0,1])\n",
    "    penalized_err = abs_err.copy()\n",
    "    penalized_err[~correct_mask] = 1.0\n",
    "    rmse_penalized = float(np.sqrt(np.mean(penalized_err ** 2)))\n",
    "\n",
    "    rows.append({\n",
    "        \"experiment\": exp_name,\n",
    "        \"op_acc\": op_acc,\n",
    "        \"param_rmse_if_op_correct\": rmse_cond,\n",
    "        \"param_mae_if_op_correct\": mae_cond,\n",
    "        f\"joint_success@{TOL}\": joint_success,\n",
    "        \"rmse_penalized_all\": rmse_penalized,\n",
    "        \"n_test\": int(len(y_true_cls)),\n",
    "        \"n_op_correct\": int(correct_mask.sum()),\n",
    "    })\n",
    "\n",
    "df_e2e = pd.DataFrame(rows).sort_values(\"rmse_penalized_all\", ascending=True).reset_index(drop=True)\n",
    "df_e2e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7dbeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
