{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4d6c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved 450 rows to ../data/input/pairs.csv\n",
      "Columns: ['map_id', 'prompt_id', 'operator', 'param']\n",
      "Unique maps used: 242 / 300 available\n",
      "Unique prompts used: 450 (should be 450)\n",
      "  map_id prompt_id   operator    param\n",
      "0   1203      p386   displace    1.316\n",
      "1   0080      p203  aggregate    6.482\n",
      "2   0171      p096     select   80.931\n",
      "3   0523      p034  aggregate   11.525\n",
      "4   1579      p031     select  149.262\n",
      "5   0948      p411   displace    2.785\n",
      "6   1344      p199   simplify    6.198\n",
      "7   0867      p073  aggregate    8.208\n",
      "8   0469      p416   simplify    6.296\n",
      "9   0804      p413     select   77.560\n"
     ]
    }
   ],
   "source": [
    "# Create data/pairs.csv with 450 random (map_id, prompt_id,operator,param) rows.\n",
    "# - map_id values: subfolder names under data/samples/pairs/\n",
    "# - prompt_id values: from data/prompts.csv (column 'prompt_id' or 'id')\n",
    "# - Each prompt_id is used exactly once; map_id is sampled with replacement.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- paths (relative to the notebook) ---\n",
    "ROOT_DIR = \"../data/input/samples/pairs\"      # where map subfolders live\n",
    "PROMPTS_CSV = \"../data/input/prompts.csv\"     # your prompts table (must exist)\n",
    "META_CSV     = \"../data/input/samples/metadata/meta.csv\" # metadata with operator + param_value\n",
    "OUTPUT_DIR = \"../data/input\"\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_DIR, \"pairs.csv\")\n",
    "\n",
    "N_ROWS = 450        # total pairs\n",
    "SEED = 42           # set None for non-deterministic\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# --- 1. Collect map_ids from folder names ---\n",
    "if not os.path.isdir(ROOT_DIR):\n",
    "    raise FileNotFoundError(f\"Folder not found: {ROOT_DIR}\")\n",
    "\n",
    "map_ids = sorted([d for d in os.listdir(ROOT_DIR) if os.path.isdir(os.path.join(ROOT_DIR, d))])\n",
    "if not map_ids:\n",
    "    raise RuntimeError(f\"No subfolders found under {ROOT_DIR} (expected map_id folders).\")\n",
    "\n",
    "# Normalize map_ids (zero-padded 4 digits)\n",
    "map_ids = [str(m).zfill(4) for m in map_ids]\n",
    "\n",
    "# --- 2. Read prompt_ids from prompts.csv ---\n",
    "if not os.path.isfile(PROMPTS_CSV):\n",
    "    raise FileNotFoundError(f\"prompts.csv not found at: {PROMPTS_CSV}\")\n",
    "\n",
    "df_prompts = pd.read_csv(PROMPTS_CSV)\n",
    "if \"prompt_id\" in df_prompts.columns:\n",
    "    prompt_ids = df_prompts[\"prompt_id\"].astype(str).str.strip().tolist()\n",
    "elif \"id\" in df_prompts.columns:\n",
    "    prompt_ids = df_prompts[\"id\"].astype(str).str.strip().tolist()\n",
    "else:\n",
    "    raise ValueError(\"prompts.csv must have a 'prompt_id' or 'id' column.\")\n",
    "\n",
    "prompt_ids = [p for p in prompt_ids if p]  # drop blanks\n",
    "unique_prompts = sorted(set(prompt_ids))\n",
    "if len(unique_prompts) < N_ROWS:\n",
    "    raise ValueError(f\"Need {N_ROWS} unique prompts; found only {len(unique_prompts)}.\")\n",
    "\n",
    "prompt_ids = rng.choice(unique_prompts, size=N_ROWS, replace=False)\n",
    "chosen_maps = rng.choice(map_ids, size=N_ROWS, replace=True)\n",
    "\n",
    "pairs = pd.DataFrame({\"map_id\": chosen_maps, \"prompt_id\": prompt_ids})\n",
    "\n",
    "# --- 3. Load metadata (operator + param_value) ---\n",
    "if not os.path.isfile(META_CSV):\n",
    "    raise FileNotFoundError(f\"meta.csv not found at: {META_CSV}\")\n",
    "\n",
    "meta = pd.read_csv(META_CSV)\n",
    "\n",
    "# Derive map_id (4-digit) from sample_id or input paths\n",
    "if \"sample_id\" in meta.columns:\n",
    "    meta[\"map_id\"] = meta[\"sample_id\"].astype(str).str.extract(r\"(\\d+)\")[0].str.zfill(4)\n",
    "else:\n",
    "    # fallback: extract from input_geojson path\n",
    "    meta[\"map_id\"] = meta[\"input_geojson\"].astype(str).str.extract(r\"/(\\d{4})_input\\.geojson$\")[0]\n",
    "\n",
    "# Keep relevant columns\n",
    "meta_small = meta[[\"map_id\", \"operator\", \"param_value\"]].copy()\n",
    "meta_small = meta_small.rename(columns={\"param_value\": \"param\"})\n",
    "\n",
    "# --- 4. Merge operator + param into pairs ---\n",
    "pairs = pairs.merge(meta_small, on=\"map_id\", how=\"left\")\n",
    "\n",
    "missing_ops   = pairs[\"operator\"].isna().sum()\n",
    "missing_param = pairs[\"param\"].isna().sum()\n",
    "if missing_ops or missing_param:\n",
    "    raise ValueError(f\"Missing labels for some map_ids: operator={missing_ops}, param={missing_param}\")\n",
    "\n",
    "# --- 5. Save final CSV ---\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "pairs.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(f\"[OK] Saved {len(pairs)} rows to {OUTPUT_FILE}\")\n",
    "print(f\"Columns: {list(pairs.columns)}\")\n",
    "print(f\"Unique maps used: {pairs['map_id'].nunique()} / {len(map_ids)} available\")\n",
    "print(f\"Unique prompts used: {pairs['prompt_id'].nunique()} (should be {N_ROWS})\")\n",
    "print(pairs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4928190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
