{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ccd509",
   "metadata": {},
   "source": [
    "### Cell 0 â€” Repository Bootstrap & Experiment Registry (Required)\n",
    "\n",
    "This cell ensures that the project repository is discoverable by Python **and**\n",
    "defines the registry of experiments that will be executed in this notebook.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why this is needed\n",
    "\n",
    "- The notebook lives inside the `notebooks/` directory  \n",
    "- Python does not automatically know where the project root is  \n",
    "- All project code lives under the `src/` directory  \n",
    "- Multiple experimental configurations (prompt-only, USE + map, OpenAI + map)\n",
    "  must be executed in a single, reproducible workflow  \n",
    "\n",
    "---\n",
    "\n",
    "#### What this cell does\n",
    "\n",
    "- Walks up the directory tree starting from the current notebook location  \n",
    "- Finds the repository root (identified by the presence of a `src/` folder)  \n",
    "- Adds that directory to `sys.path` so imports such as  \n",
    "  `from src.config import ...` work correctly  \n",
    "- Defines a central **experiment registry** describing:\n",
    "  - which feature representation is used\n",
    "  - where training data is read from\n",
    "  - where trained models and metadata are saved  \n",
    "\n",
    "---\n",
    "\n",
    "#### Design principles\n",
    "\n",
    "- Executed once at the very top of the notebook  \n",
    "- Contains no learning or model-specific logic  \n",
    "- Provides a single source of truth for all experiment configurations  \n",
    "- Enables fair and controlled comparison between different feature setups  \n",
    "\n",
    "---\n",
    "\n",
    "This cell must be executed **before any imports from `src.*`**.  \n",
    "All subsequent cells rely on the repository path and experiment definitions\n",
    "established here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2152ca17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /Users/amirdonyadide/Documents/GitHub/Thesis\n",
      "ðŸ§ª Will run experiments: prompt_only, use_map, openai_map\n",
      " - prompt_only  | train_out=/Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out_prompt_only | model_out=/Users/amirdonyadide/Documents/GitHub/Thesis/data/output/models/exp_prompt_only\n",
      " - use_map      | train_out=/Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out_use | model_out=/Users/amirdonyadide/Documents/GitHub/Thesis/data/output/models/exp_use_map\n",
      " - openai_map   | train_out=/Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out_openai | model_out=/Users/amirdonyadide/Documents/GitHub/Thesis/data/output/models/exp_openai_map\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 0: bootstrap so \"src\" is importable + run-all-experiments config ---\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Make repo root importable (find folder containing \"src\")\n",
    "# -------------------------------------------------\n",
    "p = Path.cwd().resolve()\n",
    "for candidate in [p, *p.parents]:\n",
    "    if (candidate / \"src\").is_dir():\n",
    "        if str(candidate) not in sys.path:\n",
    "            sys.path.insert(0, str(candidate))\n",
    "        REPO_ROOT = candidate\n",
    "        print(\"Repo root:\", candidate)\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Could not find repo root (no 'src' folder found in parents).\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Experiment registry (ALL experiments will run)\n",
    "# -------------------------------------------------\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    \"prompt_only\": {\n",
    "        \"train_out\": DATA_DIR / \"output\" / \"train_out_prompt_only\",\n",
    "        \"model_out\": DATA_DIR / \"output\" / \"models\" / \"exp_prompt_only\",\n",
    "        \"feature_mode\": \"prompt_only\",  # use X_prompt.npy\n",
    "        \"prompt_encoder_kind\": \"dan\",\n",
    "    },\n",
    "    \"use_map\": {\n",
    "        \"train_out\": DATA_DIR / \"output\" / \"train_out_use\",\n",
    "        \"model_out\": DATA_DIR / \"output\" / \"models\" / \"exp_use_map\",\n",
    "        \"feature_mode\": \"fused\",        # use X_concat.npy\n",
    "        \"prompt_encoder_kind\": \"dan\",\n",
    "    },\n",
    "    \"openai_map\": {\n",
    "        \"train_out\": DATA_DIR / \"output\" / \"train_out_openai\",\n",
    "        \"model_out\": DATA_DIR / \"output\" / \"models\" / \"exp_openai_map\",\n",
    "        \"feature_mode\": \"fused\",        # use X_concat.npy\n",
    "        \"prompt_encoder_kind\": \"openai-small\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create output folders\n",
    "for k, cfg in EXPERIMENTS.items():\n",
    "    cfg[\"model_out\"].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ðŸ§ª Will run experiments:\", \", \".join(EXPERIMENTS.keys()))\n",
    "for k, cfg in EXPERIMENTS.items():\n",
    "    print(f\" - {k:12s} | train_out={cfg['train_out']} | model_out={cfg['model_out']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f56a2c",
   "metadata": {},
   "source": [
    "### Cell 1 â€” Experiment Setup & Global Configuration\n",
    "\n",
    "This cell initializes the experiment environment and loads the global configuration required\n",
    "for training and evaluation. It is designed so the notebook can run **all experiment\n",
    "configurations in one pass** (prompt-only, USE + map, OpenAI + map) without manual edits.\n",
    "\n",
    "**What this cell does:**\n",
    "\n",
    "- **Loads global project configuration**\n",
    "  - Paths (`PATHS`)\n",
    "  - Runtime settings (`CFG`)\n",
    "  - Operator groups (`DISTANCE_OPS`, `AREA_OPS`)\n",
    "  - Dynamic extent configuration flags (`USE_DYNAMIC_EXTENT_REFS`, `ALLOW_FALLBACK_EXTENT`)\n",
    "  - Extent reference column names (`EXTENT_DIAG_COL`, `EXTENT_AREA_COL`)\n",
    "\n",
    "- **Defines a central experiment registry**\n",
    "  - `EXPERIMENTS` â€” a dictionary where each experiment specifies:\n",
    "    - `feature_mode`:\n",
    "      - `prompt_only` (uses prompt embeddings only)\n",
    "      - `fused` (uses concatenated map + prompt embeddings)\n",
    "    - `train_out` â€” where the prepared matrices (`X_*`) and `train_pairs.parquet` are read from\n",
    "    - `model_out` â€” where trained artifacts are saved\n",
    "\n",
    "- **Sets embedding dimensions**\n",
    "  - `MAP_DIM`, `PROMPT_DIM`\n",
    "  - `FUSED_DIM = MAP_DIM + PROMPT_DIM`\n",
    "  - The effective input dimension is derived per experiment:\n",
    "    - `prompt_only` â†’ `PROMPT_DIM`\n",
    "    - `fused` â†’ `FUSED_DIM`\n",
    "\n",
    "- **Validates experiment folders**\n",
    "  - Ensures each experimentâ€™s `train_out` and `model_out` directories exist\n",
    "  - Performs basic schema checks (required keys, valid feature modes)\n",
    "\n",
    "**Design principles**\n",
    "\n",
    "- Executed once near the top of the notebook (before data loading/training)\n",
    "- Contains no model training logic\n",
    "- Provides a single source of truth for experiment configuration\n",
    "- Prevents accidental overwrites by saving each experiment into its own output folder\n",
    "\n",
    "This cell must be executed **before any training or evaluation cells**. All experiment\n",
    "comparisons depend on the consistent configuration established here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367f89f6ac45439b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T11:21:53.302406Z",
     "start_time": "2025-10-27T11:21:53.298709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONFIG SUMMARY ===\n",
      "PROJ_ROOT  : /Users/amirdonyadide/Documents/GitHub/Thesis\n",
      "DATA_DIR   : /Users/amirdonyadide/Documents/GitHub/Thesis/data\n",
      "INPUT_DIR  : /Users/amirdonyadide/Documents/GitHub/Thesis/data/input\n",
      "OUTPUT_DIR : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output\n",
      "MAPS_ROOT  : /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/samples/pairs\n",
      "INPUT PAT. : *_input.geojson\n",
      "--- User Study ---\n",
      "USER_STUDY_XLSX : /Users/amirdonyadide/Documents/GitHub/Thesis/data/userstudy/UserStudy.xlsx\n",
      "RESPONSES_SHEET : Responses\n",
      "TILE_ID_COL     : tile_id\n",
      "COMPLETE_COL    : complete\n",
      "REMOVE_COL      : remove\n",
      "TEXT_COL        : cleaned_text\n",
      "PARAM_VALUE_COL : param_value\n",
      "OPERATOR_COL    : operator\n",
      "INTENSITY_COL   : intensity\n",
      "--- Filters / IDs / Split ---\n",
      "ONLY_COMPLETE   : True\n",
      "EXCLUDE_REMOVED : True\n",
      "PROMPT_ID       : r{i:08d}\n",
      "SPLIT_BY        : tile\n",
      "--- Outputs ---\n",
      "PROMPT_OUT : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out\n",
      "MAP_OUT    : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out\n",
      "TRAIN_OUT  : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out\n",
      "MODEL_OUT  : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/models\n",
      "SPLIT_OUT  : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out/splits\n",
      "PRM_NPZ    : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/prompts_embeddings.npz\n",
      "MAPS_PQ    : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out/maps.parquet\n",
      "PAIRS_PQ   : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out/train_pairs.parquet\n",
      "--- Model ---\n",
      "PROMPT_ENCODER: openai-small\n",
      "MAP_DIM       : 165\n",
      "PROMPT_DIM    : 1536\n",
      "FUSED_DIM     : 1701\n",
      "BATCH_SIZE    : 512\n",
      "VAL/TEST      : 0.15 0.15\n",
      "SEED          : 42\n",
      "--- Normalization behavior ---\n",
      "USE_DYNAMIC_EXTENT_REFS : True\n",
      "ALLOW_FALLBACK_EXTENT   : True\n",
      "--- Fallback tile scale (ONLY if dynamic refs missing) ---\n",
      "DEFAULT_TILE_W/H (m) : 400.0 400.0\n",
      "DEFAULT_TILE_DIAG_M  : 565.685424949238\n",
      "DEFAULT_TILE_AREA_M2 : 160000.0\n",
      "--- Extent columns ---\n",
      "EXTENT_DIAG_COL : extent_diag_m\n",
      "EXTENT_AREA_COL : extent_area_m2\n",
      "--- Operator groups ---\n",
      "DISTANCE_OPS : ('aggregate', 'displace', 'simplify')\n",
      "AREA_OPS     : ('select',)\n",
      "--- Operator groups ---\n",
      "DISTANCE_OPS : ('aggregate', 'displace', 'simplify')\n",
      "AREA_OPS     : ('select',)\n",
      "--- Param estimation ---\n",
      "PARAM_STRATEGY : mlp\n",
      "QUAL_TO_QUANTILE: {'very_small': 0.1, 'small': 0.25, 'medium': 0.5, 'large': 0.75, 'very_large': 0.9}\n",
      "DEFAULT_PARAM_BY_OPERATOR: {'aggregate': 5.0, 'displace': 5.0, 'simplify': 5.0, 'select': 50.0}\n",
      "USE_DYNAMIC_EXTENT_REFS: True\n",
      "ALLOW_FALLBACK_EXTENT  : True\n",
      "EXTENT_DIAG_COL: extent_diag_m  EXTENT_AREA_COL: extent_area_m2\n",
      "MAP_DIM: 165\n",
      "PROMPT_DIM: 1536\n",
      "FUSED_DIM: 1701\n",
      "BATCH_SIZE: 512\n",
      "\n",
      "ðŸ§ª Experiments to be executed:\n",
      " - prompt_only  | feature_mode=prompt_only  | train_out=train_out_prompt_only | model_out=exp_prompt_only\n",
      " - use_map      | feature_mode=fused        | train_out=train_out_use | model_out=exp_use_map\n",
      " - openai_map   | feature_mode=fused        | train_out=train_out_openai | model_out=exp_openai_map\n"
     ]
    }
   ],
   "source": [
    "# ===================== CELL 1 â€” PARAMETERS =====================\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from src.config import (\n",
    "    PATHS, CFG, print_summary,\n",
    "    DISTANCE_OPS, AREA_OPS,\n",
    "    USE_DYNAMIC_EXTENT_REFS, ALLOW_FALLBACK_EXTENT,\n",
    "    EXTENT_DIAG_COL, EXTENT_AREA_COL,\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Global config overview (same for all experiments)\n",
    "# -------------------------------------------------\n",
    "print_summary()\n",
    "print(\"USE_DYNAMIC_EXTENT_REFS:\", USE_DYNAMIC_EXTENT_REFS)\n",
    "print(\"ALLOW_FALLBACK_EXTENT  :\", ALLOW_FALLBACK_EXTENT)\n",
    "print(\"EXTENT_DIAG_COL:\", EXTENT_DIAG_COL, \" EXTENT_AREA_COL:\", EXTENT_AREA_COL)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Dimensions from config (authoritative)\n",
    "# -------------------------------------------------\n",
    "MAP_DIM = int(CFG.MAP_DIM)\n",
    "PROMPT_DIM = int(CFG.PROMPT_DIM)\n",
    "FUSED_DIM = MAP_DIM + PROMPT_DIM\n",
    "BATCH_SIZE = int(CFG.BATCH_SIZE)\n",
    "\n",
    "print(\"MAP_DIM:\", MAP_DIM)\n",
    "print(\"PROMPT_DIM:\", PROMPT_DIM)\n",
    "print(\"FUSED_DIM:\", FUSED_DIM)\n",
    "print(\"BATCH_SIZE:\", BATCH_SIZE)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Validate experiment registry (from Cell 0)\n",
    "# -------------------------------------------------\n",
    "required_keys = {\"train_out\", \"model_out\", \"feature_mode\"}\n",
    "\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "    missing = required_keys - set(cfg.keys())\n",
    "    if missing:\n",
    "        raise ValueError(f\"Experiment '{exp_name}' is missing keys: {missing}\")\n",
    "\n",
    "    cfg[\"train_out\"] = Path(cfg[\"train_out\"])\n",
    "    cfg[\"model_out\"] = Path(cfg[\"model_out\"])\n",
    "\n",
    "    cfg[\"train_out\"].mkdir(parents=True, exist_ok=True)\n",
    "    cfg[\"model_out\"].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\nðŸ§ª Experiments to be executed:\")\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "    print(\n",
    "        f\" - {exp_name:12s} | \"\n",
    "        f\"feature_mode={cfg['feature_mode']:12s} | \"\n",
    "        f\"train_out={cfg['train_out'].name} | \"\n",
    "        f\"model_out={cfg['model_out'].name}\"\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Helper: feature dimensions per experiment\n",
    "# -------------------------------------------------\n",
    "def get_feature_dims(feature_mode: str):\n",
    "    \"\"\"\n",
    "    Returns (map_dim, prompt_dim, fused_dim) for a given feature mode.\n",
    "    \"\"\"\n",
    "    if feature_mode == \"prompt_only\":\n",
    "        return 0, PROMPT_DIM, PROMPT_DIM\n",
    "    if feature_mode == \"fused\":\n",
    "        return MAP_DIM, PROMPT_DIM, FUSED_DIM\n",
    "    raise ValueError(f\"Unknown feature_mode: {feature_mode}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2350e",
   "metadata": {},
   "source": [
    "## Step 2 â€” Prompt Embedding Generation (All Experiments)\n",
    "\n",
    "In this step, we generate vector embeddings for all user prompts for **each experiment\n",
    "configuration** (e.g., prompt-only, USE + map, OpenAI + map). The embedding backend is\n",
    "selected per experiment via `PROMPT_ENCODER` (e.g., **USE-DAN/Transformer** or **OpenAI\n",
    "text-embedding-3-* models**).\n",
    "\n",
    "### What happens here?\n",
    "\n",
    "For each entry in the experiment registry:\n",
    "\n",
    "- Prompts are loaded from the user study source file.\n",
    "- Only valid prompts are kept (`complete == True`, `remove == False`).\n",
    "- The prompt embedding model is selected from the experiment configuration\n",
    "  (mapped to `CFG.PROMPT_ENCODER`).\n",
    "- All prompts are embedded in batches (with optional L2 normalization).\n",
    "- The resulting embeddings and metadata are saved to an **experiment-specific folder**\n",
    "  so no configuration overwrites another.\n",
    "\n",
    "**Outputs per experiment** (written under `PATHS.PROMPT_OUT/<experiment_name>/`):\n",
    "\n",
    "- `prompts_embeddings.npz` â€” matrix `E` and `ids`\n",
    "- `prompts.parquet` â€” prompt_id, text, tile_id\n",
    "- `meta.json` â€” model label, dimensionality, and export info\n",
    "\n",
    "### Why this is encapsulated in a helper\n",
    "\n",
    "To keep the notebook clean and reproducible, all logic related to:\n",
    "\n",
    "- loading and filtering prompts,\n",
    "- selecting the embedding backend,\n",
    "- batching and normalization,\n",
    "- saving outputs in a consistent format,\n",
    "\n",
    "is encapsulated in `src/train/run_prompt_embeddings.py`.\n",
    "\n",
    "The notebook only *orchestrates* experiments by calling this helper with an\n",
    "experiment-specific configuration.\n",
    "\n",
    "This design ensures:\n",
    "\n",
    "- consistent prompt embeddings across training and evaluation,\n",
    "- easy comparison between USE and OpenAI backends,\n",
    "- clean separation between experiment orchestration (notebook) and implementation (src),\n",
    "- safe parallel storage of artifacts for multiple experiment runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed0df45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T11:21:55.572701Z",
     "start_time": "2025-10-27T11:21:55.570071Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 22:03:51 | INFO | Reading Excel: /Users/amirdonyadide/Documents/GitHub/Thesis/data/userstudy/UserStudy.xlsx (sheet=Responses)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running prompt embeddings for all experiments ===\n",
      "\n",
      "ðŸ§ª Experiment: prompt_only\n",
      "   PROMPT_ENCODER: dan\n",
      "   Output dir    : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/prompt_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 22:03:51 | INFO | Filtered Excel rows: 786 â†’ 562 (only_complete=True, exclude_removed=True)\n",
      "2026-01-28 22:03:51 | INFO | Using local USE-dan at /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/model_dan\n",
      "2026-01-28 22:03:51 | INFO | Loading USE-dan from local path: /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/model_dan â€¦\n",
      "2026-01-28 22:03:54 | INFO | Fingerprint not found. Saved model loading will continue.\n",
      "2026-01-28 22:03:54 | INFO | path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
      "2026-01-28 22:03:54 | INFO | USE model loaded in 2.96s\n",
      "2026-01-28 22:03:54 | INFO | Embedding 562 prompts with USE (batch_size=512, l2=True)â€¦\n",
      "2026-01-28 22:03:54 | INFO | Done USE embedding in 0.14s (dim=512).\n",
      "2026-01-28 22:03:54 | INFO | Writing outputs to /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/prompt_only\n",
      "2026-01-28 22:03:54 | INFO |   saved prompts_embeddings.npz (shape=(562, 512))\n",
      "2026-01-28 22:03:54 | INFO |   saved prompts.parquet (rows=562)\n",
      "2026-01-28 22:03:54 | INFO |   saved meta.json\n",
      "2026-01-28 22:03:54 | INFO | Reading Excel: /Users/amirdonyadide/Documents/GitHub/Thesis/data/userstudy/UserStudy.xlsx (sheet=Responses)\n",
      "2026-01-28 22:03:54 | INFO | Filtered Excel rows: 786 â†’ 562 (only_complete=True, exclude_removed=True)\n",
      "2026-01-28 22:03:54 | INFO | Using local USE-dan at /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/model_dan\n",
      "2026-01-28 22:03:54 | INFO | Loading USE-dan from local path: /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/model_dan â€¦\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Prompt embeddings completed.\n",
      "\n",
      "ðŸ§ª Experiment: use_map\n",
      "   PROMPT_ENCODER: dan\n",
      "   Output dir    : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/use_map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 22:03:58 | INFO | Fingerprint not found. Saved model loading will continue.\n",
      "2026-01-28 22:03:58 | INFO | path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
      "2026-01-28 22:03:58 | INFO | USE model loaded in 3.57s\n",
      "2026-01-28 22:03:58 | INFO | Embedding 562 prompts with USE (batch_size=512, l2=True)â€¦\n",
      "2026-01-28 22:03:58 | INFO | Done USE embedding in 0.15s (dim=512).\n",
      "2026-01-28 22:03:58 | INFO | Writing outputs to /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/use_map\n",
      "2026-01-28 22:03:58 | INFO |   saved prompts_embeddings.npz (shape=(562, 512))\n",
      "2026-01-28 22:03:58 | INFO |   saved prompts.parquet (rows=562)\n",
      "2026-01-28 22:03:58 | INFO |   saved meta.json\n",
      "2026-01-28 22:03:58 | INFO | Reading Excel: /Users/amirdonyadide/Documents/GitHub/Thesis/data/userstudy/UserStudy.xlsx (sheet=Responses)\n",
      "2026-01-28 22:03:58 | INFO | Filtered Excel rows: 786 â†’ 562 (only_complete=True, exclude_removed=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Prompt embeddings completed.\n",
      "\n",
      "ðŸ§ª Experiment: openai_map\n",
      "   PROMPT_ENCODER: openai-small\n",
      "   Output dir    : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/openai_map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 22:03:59 | INFO | Embedding 562 prompts with OpenAI model=text-embedding-3-small (batch_size=512, l2=True)â€¦\n",
      "2026-01-28 22:04:01 | INFO | HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 22:04:03 | INFO | HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 22:04:03 | INFO | Done OpenAI embedding in 4.75s (dim=1536).\n",
      "2026-01-28 22:04:03 | INFO | Writing outputs to /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/openai_map\n",
      "2026-01-28 22:04:03 | INFO |   saved prompts_embeddings.npz (shape=(562, 1536))\n",
      "2026-01-28 22:04:03 | INFO |   saved prompts.parquet (rows=562)\n",
      "2026-01-28 22:04:03 | INFO |   saved meta.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Prompt embeddings completed.\n",
      "\n",
      "âœ… All prompt embeddings finished.\n"
     ]
    }
   ],
   "source": [
    "# ===================== CELL 2 â€” Prompt embeddings (experiment-scoped) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import replace\n",
    "\n",
    "from src.train.run_prompt_embeddings import run_prompt_embeddings_from_config\n",
    "\n",
    "print(\"\\n=== Running prompt embeddings for all experiments ===\")\n",
    "\n",
    "prompt_meta_by_experiment = {}\n",
    "\n",
    "for exp_name, cfg_exp in EXPERIMENTS.items():\n",
    "\n",
    "    # IMPORTANT: cfg.PROMPT_ENCODER must be one of:\n",
    "    #   \"dan\", \"transformer\", \"openai-small\", \"openai-large\"\n",
    "    # (matches src/mapvec/prompts/prompt_embeddings.py)\n",
    "    prompt_encoder_kind = cfg_exp.get(\"prompt_encoder_kind\", CFG.PROMPT_ENCODER)\n",
    "\n",
    "    # Create an experiment-specific cfg (CFG is frozen â†’ use replace)\n",
    "    CFG_EXP = replace(CFG, PROMPT_ENCODER=prompt_encoder_kind)\n",
    "\n",
    "    prompt_out_dir = Path(PATHS.PROMPT_OUT) / exp_name\n",
    "    prompt_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nðŸ§ª Experiment: {exp_name}\")\n",
    "    print(f\"   PROMPT_ENCODER: {CFG_EXP.PROMPT_ENCODER}\")\n",
    "    print(f\"   Output dir    : {prompt_out_dir}\")\n",
    "\n",
    "    meta = run_prompt_embeddings_from_config(\n",
    "        input_path=Path(PATHS.USER_STUDY_XLSX),\n",
    "        out_dir=prompt_out_dir,\n",
    "        cfg=CFG_EXP,\n",
    "        paths=PATHS,\n",
    "        verbosity=1,\n",
    "        l2_normalize=True,\n",
    "        also_save_embeddings_csv=False,\n",
    "    )\n",
    "\n",
    "    prompt_meta_by_experiment[exp_name] = meta\n",
    "    print(\"   âœ… Prompt embeddings completed.\")\n",
    "\n",
    "print(\"\\nâœ… All prompt embeddings finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c0b51",
   "metadata": {},
   "source": [
    "## Step 3 â€” Map Embeddings (Dynamic, Shared Across Experiments)\n",
    "\n",
    "In this step, we compute **map embeddings** for all GeoJSON tiles that are eligible for the user study.  \n",
    "Because map embeddings depend only on the input map data (not on the prompt encoder), they are computed **once** and stored in a **shared output folder**, then reused across all experiments.\n",
    "\n",
    "### What this step does\n",
    "\n",
    "1. **Filters tiles using the user study Excel**\n",
    "   - Keeps only rows marked as *complete*\n",
    "   - Excludes rows marked as *removed*\n",
    "   - Extracts the set of allowed `tile_id`s (used to select which map folders to embed)\n",
    "\n",
    "2. **Discovers and embeds GeoJSON maps**\n",
    "   - Finds all GeoJSON files under `PATHS.MAPS_ROOT`\n",
    "   - Keeps only those whose `map_id` is in the allowed set\n",
    "   - Counts valid polygons per map to determine a dataset-wide `max_polygons`\n",
    "     (used to normalize the `poly_count` feature safely)\n",
    "\n",
    "3. **Computes map embeddings**\n",
    "   - Uses `norm=\"extent\"` for **dynamic per-map normalization**\n",
    "   - Ensures all vectors have consistent dimensionality\n",
    "   - Skips maps with invalid geometries or degenerate extents\n",
    "\n",
    "4. **Stores dynamic extent references (required for parameter scaling)**\n",
    "   - `extent_diag_m`\n",
    "   - `extent_area_m2`\n",
    "\n",
    "   These are saved alongside embeddings and are later used to convert\n",
    "   normalized parameters (`param_norm`) into real-world units:\n",
    "   - distance operators â†’ meters via `extent_diag_m`\n",
    "   - area operators â†’ mÂ² via `extent_area_m2`\n",
    "\n",
    "5. **Writes outputs once to a shared directory**\n",
    "   - Prevents redundant computation across experiments\n",
    "   - Guarantees every experiment uses the **same map representation**\n",
    "   - Avoids accidental overwrites while keeping artifacts reusable\n",
    "\n",
    "### Why this is important\n",
    "\n",
    "- Ensures **consistent normalization** between training and evaluation  \n",
    "- Provides the necessary per-map reference scales for parameter un-normalization  \n",
    "- Improves reproducibility and efficiency by reusing identical map embeddings  \n",
    "- Supports fair comparison between:\n",
    "  - prompt-only baselines (which ignore map embeddings)\n",
    "  - fused prompt + map hybrids\n",
    "  - different prompt backends (USE vs OpenAI)\n",
    "\n",
    "At the end of this step, the repository contains a self-contained set of map embeddings\n",
    "ready to be concatenated with prompt embeddings in the next stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ca0c3d8b71fc70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T11:26:59.687350Z",
     "start_time": "2025-10-27T11:26:19.901557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running map embeddings once (shared) ===\n",
      "Output dir: /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out/shared_extent\n",
      "âœ… Map embeddings completed.\n",
      "MapEmbeddingRunMeta(n_tiles_allowed=399, n_maps_found=824, n_maps_used=399, max_polygons=653, out_dir='/Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out/shared_extent', embeddings_path='/Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out/shared_extent/maps_embeddings.npz', maps_parquet_path='/Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out/shared_extent/maps.parquet')\n",
      "MAP_EMB_DIR: /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out/shared_extent\n"
     ]
    }
   ],
   "source": [
    "# ===================== CELL 3 â€” Map embeddings (shared) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "from src.train.run_map_embeddings import run_map_embeddings_from_config\n",
    "\n",
    "# Map embeddings do NOT depend on the prompt backend, so we compute them once and reuse.\n",
    "MAP_EMB_DIR = Path(PATHS.MAP_OUT) / \"shared_extent\"\n",
    "MAP_EMB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Expected outputs (based on map_embeddings writer)\n",
    "maps_npz = MAP_EMB_DIR / \"maps_embeddings.npz\"\n",
    "maps_pq  = MAP_EMB_DIR / \"maps.parquet\"\n",
    "\n",
    "if maps_npz.exists() and maps_pq.exists():\n",
    "    print(\"âœ… Map embeddings already exist â€” skipping recomputation.\")\n",
    "    print(\"   Using:\", MAP_EMB_DIR)\n",
    "    map_meta = {\"out_dir\": str(MAP_EMB_DIR), \"skipped\": True}\n",
    "else:\n",
    "    print(\"=== Running map embeddings once (shared) ===\")\n",
    "    print(\"Output dir:\", MAP_EMB_DIR)\n",
    "\n",
    "    map_meta = run_map_embeddings_from_config(\n",
    "        maps_root=Path(PATHS.MAPS_ROOT),\n",
    "        input_pattern=PATHS.INPUT_MAPS_PATTERN,\n",
    "        user_study_xlsx=Path(PATHS.USER_STUDY_XLSX),\n",
    "        responses_sheet=PATHS.RESPONSES_SHEET,\n",
    "        tile_id_col=PATHS.TILE_ID_COL,\n",
    "        complete_col=PATHS.COMPLETE_COL,\n",
    "        remove_col=PATHS.REMOVE_COL,\n",
    "        only_complete=bool(PATHS.ONLY_COMPLETE),\n",
    "        exclude_removed=bool(PATHS.EXCLUDE_REMOVED),\n",
    "        out_dir=MAP_EMB_DIR,\n",
    "        verbosity=1,\n",
    "        norm=\"extent\",  # dynamic per-map normalization\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Map embeddings completed.\")\n",
    "\n",
    "print(map_meta)\n",
    "\n",
    "# Expose shared map embedding dir for later cells (concat / training)\n",
    "print(\"MAP_EMB_DIR:\", MAP_EMB_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf32c5",
   "metadata": {},
   "source": [
    "### ðŸ”¢ Inferring Embedding Dimensions (Experiment-Aware)\n",
    "\n",
    "In this step, we **infer embedding dimensionalities directly from the saved embedding files**\n",
    "rather than relying on configuration defaults. Dimensions are inferred **per experiment** to\n",
    "account for different prompt embedding backends (e.g., USE vs OpenAI), while map embeddings\n",
    "are shared across experiments.\n",
    "\n",
    "This ensures:\n",
    "- A **single source of truth** for feature dimensions\n",
    "- **Consistency** between training and evaluation pipelines\n",
    "- Robustness to changes in embedding models or backend configurations\n",
    "- Correct handling of mixed feature modes (prompt-only vs. fused prompt + map)\n",
    "\n",
    "Specifically, we:\n",
    "\n",
    "- Load **prompt embeddings** from  \n",
    "  `PATHS.PROMPT_OUT/<experiment_name>/prompts_embeddings.npz`\n",
    "- Load **map embeddings** from the shared map embedding directory  \n",
    "  `PATHS.MAP_OUT/<shared_folder>/maps_embeddings.npz`\n",
    "- Infer dimensions as follows:\n",
    "  - `PROMPT_DIM` â€” from prompt embeddings (per experiment)\n",
    "  - `MAP_DIM` â€” from map embeddings (shared)\n",
    "  - `FUSED_DIM` â€” computed per experiment:\n",
    "    - `prompt_only` â†’ `PROMPT_DIM`\n",
    "    - `fused` â†’ `MAP_DIM + PROMPT_DIM`\n",
    "\n",
    "If inferred dimensions differ from those defined in the global configuration (`CFG`),\n",
    "the inferred values take precedence for all downstream processing.\n",
    "\n",
    "The inferred dimensions are stored in the experiment registry and used consistently by:\n",
    "- feature preprocessing\n",
    "- operator classification\n",
    "- parameter regression\n",
    "- evaluation and inference\n",
    "\n",
    "This guarantees that all downstream models operate on **correctly shaped feature vectors**\n",
    "and that comparisons between experiments remain valid and reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8cdf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Inferred MAP_DIM from shared maps: 165\n",
      "\n",
      "âœ… Inferred dims per experiment:\n",
      " - prompt_only  | mode=prompt_only | MAP_DIM=   0 | PROMPT_DIM= 512 | FUSED_DIM= 512\n",
      " - use_map      | mode=fused      | MAP_DIM= 165 | PROMPT_DIM= 512 | FUSED_DIM= 677\n",
      " - openai_map   | mode=fused      | MAP_DIM= 165 | PROMPT_DIM=1536 | FUSED_DIM=1701\n"
     ]
    }
   ],
   "source": [
    "# ===================== CELL 4 â€” Infer embedding dimensions (multi-experiment) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def _infer_dim_from_npz(npz_path: Path) -> int:\n",
    "    if not npz_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing embeddings file: {npz_path}\")\n",
    "    z = np.load(npz_path, allow_pickle=True)\n",
    "    if \"E\" not in z:\n",
    "        raise ValueError(f\"{npz_path} missing array 'E'\")\n",
    "    E = z[\"E\"]\n",
    "    if E.ndim != 2 or E.shape[1] <= 0:\n",
    "        raise ValueError(f\"Invalid embedding matrix in {npz_path}: shape={E.shape}\")\n",
    "    return int(E.shape[1])\n",
    "\n",
    "# -------------------------------\n",
    "# Map dim (shared across all experiments)\n",
    "# -------------------------------\n",
    "maps_npz = Path(MAP_EMB_DIR) / \"maps_embeddings.npz\"\n",
    "MAP_DIM_INF = _infer_dim_from_npz(maps_npz)\n",
    "\n",
    "print(\"âœ… Inferred MAP_DIM from shared maps:\", MAP_DIM_INF)\n",
    "\n",
    "# -------------------------------\n",
    "# Prompt dim per experiment + fused dim per experiment\n",
    "# -------------------------------\n",
    "dims_by_experiment = {}\n",
    "\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "    prm_npz = Path(PATHS.PROMPT_OUT) / exp_name / \"prompts_embeddings.npz\"\n",
    "    PROMPT_DIM_INF = _infer_dim_from_npz(prm_npz)\n",
    "\n",
    "    feature_mode = cfg[\"feature_mode\"]\n",
    "    if feature_mode == \"prompt_only\":\n",
    "        fused_dim = PROMPT_DIM_INF\n",
    "        map_dim = 0\n",
    "    elif feature_mode == \"fused\":\n",
    "        fused_dim = MAP_DIM_INF + PROMPT_DIM_INF\n",
    "        map_dim = MAP_DIM_INF\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown feature_mode for {exp_name}: {feature_mode}\")\n",
    "\n",
    "    # store into cfg for later cells\n",
    "    cfg[\"map_dim\"] = int(map_dim)\n",
    "    cfg[\"prompt_dim\"] = int(PROMPT_DIM_INF)\n",
    "    cfg[\"fused_dim\"] = int(fused_dim)\n",
    "\n",
    "    dims_by_experiment[exp_name] = {\n",
    "        \"feature_mode\": feature_mode,\n",
    "        \"MAP_DIM\": int(map_dim),\n",
    "        \"PROMPT_DIM\": int(PROMPT_DIM_INF),\n",
    "        \"FUSED_DIM\": int(fused_dim),\n",
    "    }\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nâœ… Inferred dims per experiment:\")\n",
    "for exp_name, d in dims_by_experiment.items():\n",
    "    print(f\" - {exp_name:12s} | mode={d['feature_mode']:10s} | MAP_DIM={d['MAP_DIM']:4d} | PROMPT_DIM={d['PROMPT_DIM']:4d} | FUSED_DIM={d['FUSED_DIM']:4d}\")\n",
    "\n",
    "# Optional: warn if global CFG is stale (informational only)\n",
    "if MAP_DIM_INF != int(CFG.MAP_DIM):\n",
    "    print(\"\\nâš ï¸ CFG.MAP_DIM differs from inferred MAP_DIM (using inferred for experiments).\")\n",
    "    print(f\"   inferred MAP_DIM={MAP_DIM_INF} vs CFG.MAP_DIM={CFG.MAP_DIM}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd186319e89f445",
   "metadata": {},
   "source": [
    "### ðŸ”— Feature Construction (Prompt-Only vs. Fused Map + Prompt Embeddings)\n",
    "\n",
    "In this step, we construct the final feature matrices used for training and evaluation by\n",
    "aligning prompt embeddings with map embeddings and exporting **experiment-scoped** artifacts.\n",
    "\n",
    "#### What this step does (per experiment)\n",
    "\n",
    "- Loads **prompt embeddings** from  \n",
    "  `PATHS.PROMPT_OUT/<experiment_name>/prompts_embeddings.npz`\n",
    "- Loads **map embeddings** from the shared map embedding directory  \n",
    "  `PATHS.MAP_OUT/<shared_folder>/maps_embeddings.npz`\n",
    "- Aligns samples via the authoritative pairing table (`prompts.parquet` â†’ `map_id/tile_id` + `prompt_id`)\n",
    "- Merges **dynamic map extent metadata** (e.g., `extent_diag_m`, `extent_area_m2`) from `maps.parquet`\n",
    "  so downstream regression can convert normalized parameters into real-world units.\n",
    "\n",
    "#### Feature modes supported\n",
    "\n",
    "- **`prompt_only`**  \n",
    "  Uses only prompt vectors:  \n",
    "  `X = prompt_embedding`\n",
    "\n",
    "- **`fused`**  \n",
    "  Concatenates map and prompt vectors:  \n",
    "  `X = [map_embedding | prompt_embedding]`\n",
    "\n",
    "#### Outputs written per experiment\n",
    "\n",
    "All artifacts are saved into the experimentâ€™s `train_out` directory (to prevent overwrites):\n",
    "\n",
    "- `X_prompt.npy` or `X_concat.npy` â€” final feature matrix (depending on feature mode)\n",
    "- `train_pairs.parquet` â€” aligned metadata (including `operator`, `param_value`, and extent references)\n",
    "- `meta.json` â€” provenance (sources, options) and shape information\n",
    "\n",
    "#### Why this design\n",
    "\n",
    "- Keeps **training and evaluation perfectly aligned** by exporting a single, consistent pairing table\n",
    "- Avoids hard-coded dimensions by relying on the saved embedding files\n",
    "- Supports **multiple experiments side-by-side** without overwriting artifacts\n",
    "- Enables **dynamic extent-aware** parameter regression (meters / mÂ² scaling) downstream\n",
    "- Ensures fair comparison: prompt-only baselines vs. fused map+prompt models\n",
    "\n",
    "After this step, each experiment has a complete, self-contained dataset ready for:\n",
    "1. Operator classification  \n",
    "2. Per-operator parameter regression  \n",
    "3. End-to-end evaluation in the evaluation notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2b07a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Concatenating features for all experiments ===\n",
      "\n",
      "ðŸ§ª Experiment: prompt_only\n",
      "   Feature mode (cfg)   : prompt_only\n",
      "   Feature mode (concat): prompt_only\n",
      "   Prompt out dir       : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/prompt_only\n",
      "   Map out dir          : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out/shared_extent\n",
      "   Train out dir        : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out_prompt_only\n",
      "   âœ… Concatenation completed.\n",
      "\n",
      "ðŸ§ª Experiment: use_map\n",
      "   Feature mode (cfg)   : fused\n",
      "   Feature mode (concat): prompt_plus_map\n",
      "   Prompt out dir       : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/use_map\n",
      "   Map out dir          : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out/shared_extent\n",
      "   Train out dir        : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out_use\n",
      "   âœ… Concatenation completed.\n",
      "\n",
      "ðŸ§ª Experiment: openai_map\n",
      "   Feature mode (cfg)   : fused\n",
      "   Feature mode (concat): prompt_plus_map\n",
      "   Prompt out dir       : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/openai_map\n",
      "   Map out dir          : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out/shared_extent\n",
      "   Train out dir        : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out_openai\n",
      "   âœ… Concatenation completed.\n",
      "\n",
      "âœ… All concatenations finished.\n"
     ]
    }
   ],
   "source": [
    "# ===================== CELL 5 â€” Concatenate embeddings (multi-experiment) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "from src.train.run_concat_features import run_concat_features_from_dirs\n",
    "\n",
    "print(\"\\n=== Concatenating features for all experiments ===\")\n",
    "\n",
    "concat_meta_by_experiment = {}\n",
    "\n",
    "def _to_concat_mode(feature_mode: str) -> str:\n",
    "    \"\"\"\n",
    "    Map our notebook naming to what run_concat_features_from_dirs expects.\n",
    "    \"\"\"\n",
    "    fm = str(feature_mode).strip().lower()\n",
    "    if fm in {\"prompt_only\"}:\n",
    "        return \"prompt_only\"\n",
    "    if fm in {\"fused\", \"prompt_plus_map\"}:\n",
    "        return \"prompt_plus_map\"\n",
    "    raise ValueError(f\"Unsupported feature_mode in EXPERIMENTS: {feature_mode}\")\n",
    "\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "\n",
    "    feature_mode = cfg[\"feature_mode\"]\n",
    "    mode_for_concat = _to_concat_mode(feature_mode)\n",
    "\n",
    "    train_out_dir = Path(cfg[\"train_out\"])\n",
    "    train_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Experiment-specific prompt embeddings\n",
    "    prompt_out_dir = Path(PATHS.PROMPT_OUT) / exp_name\n",
    "\n",
    "    # Shared map embeddings (from Cell 3)\n",
    "    map_out_dir = MAP_EMB_DIR\n",
    "\n",
    "    print(f\"\\nðŸ§ª Experiment: {exp_name}\")\n",
    "    print(f\"   Feature mode (cfg)   : {feature_mode}\")\n",
    "    print(f\"   Feature mode (concat): {mode_for_concat}\")\n",
    "    print(f\"   Prompt out dir       : {prompt_out_dir}\")\n",
    "    print(f\"   Map out dir          : {map_out_dir}\")\n",
    "    print(f\"   Train out dir        : {train_out_dir}\")\n",
    "\n",
    "    meta = run_concat_features_from_dirs(\n",
    "        prompt_out_dir=prompt_out_dir,\n",
    "        map_out_dir=map_out_dir,\n",
    "        out_dir=train_out_dir,\n",
    "        exp_name=exp_name,\n",
    "        feature_mode=mode_for_concat,   # must be \"prompt_only\" or \"prompt_plus_map\"\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    concat_meta_by_experiment[exp_name] = meta\n",
    "    print(\"   âœ… Concatenation completed.\")\n",
    "\n",
    "print(\"\\nâœ… All concatenations finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142d4b68c273d37",
   "metadata": {},
   "source": [
    "## Step 6 â€” Load Training Data and Build Normalized Regression Target (Experiment-Aware)\n",
    "\n",
    "In this step, we load the **experiment-specific training data** produced by the feature\n",
    "construction stage and build the final learning targets for both classification and regression.\n",
    "\n",
    "Because this notebook runs **multiple experiments**, the same procedure is applied\n",
    "**independently for each experiment**, using its own `train_out` directory.\n",
    "\n",
    "### What happens here (per experiment)\n",
    "\n",
    "1. **Load the feature matrix**\n",
    "   - `prompt_only` experiments load prompt-only features (e.g., `X_prompt.npy`)\n",
    "   - fused experiments load concatenated features (e.g., `X_concat.npy`)\n",
    "\n",
    "2. **Load the paired metadata table**\n",
    "   - `train_pairs.parquet` containing aligned `(map_id, prompt_id)` rows and dynamic extent references\n",
    "\n",
    "3. **Attach labels and apply consistent filtering**\n",
    "   - Ensures only valid user study rows are included (e.g., `complete == True`, `remove == False`)\n",
    "   - Ensures `operator` and `param_value` are present (and prompt text if required)\n",
    "\n",
    "4. **Validate dynamic extent references**\n",
    "   - Confirms the presence of per-map reference scales required for normalization:\n",
    "     - `extent_diag_m`\n",
    "     - `extent_area_m2`\n",
    "\n",
    "5. **Compute the normalized regression target `param_norm`**\n",
    "   Normalization depends on the operator group:\n",
    "\n",
    "   - **Distance-based operators** (`aggregate`, `displace`, `simplify`):  \n",
    "     `param_norm = param_value / extent_diag_m`\n",
    "\n",
    "   - **Area-based operators** (`select`):  \n",
    "     `param_norm = param_value / extent_area_m2`\n",
    "\n",
    "### Why this normalization is used\n",
    "\n",
    "This step converts parameters from heterogeneous, map-scale-dependent units into a\n",
    "scale-aware normalized target. It allows per-operator regressors to generalize across\n",
    "maps of different extents while preserving physical meaning during inference\n",
    "(when `param_norm` is converted back to meters or mÂ² using the same extent references).\n",
    "\n",
    "### Outputs\n",
    "\n",
    "For each experiment, we obtain:\n",
    "\n",
    "- `X` â€” feature matrix aligned with labels  \n",
    "- `df` â€” cleaned metadata table including `operator`, `param_value`, `param_norm`, and extent references  \n",
    "\n",
    "These outputs feed directly into the subsequent training stages:\n",
    "1. Operator classification  \n",
    "2. Per-operator parameter regression  \n",
    "3. End-to-end evaluation across experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a494fd27dfe7681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading training data for all experiments ===\n",
      "\n",
      "ðŸ§ª Experiment: prompt_only\n",
      "   train_out : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out_prompt_only\n",
      "   mode      : prompt_only  -> loader mode: prompt_only\n",
      "   âœ… Loaded: X=(562, 512) | df=(562, 15)\n",
      "   Operators: ['aggregate', 'displace', 'select', 'simplify']\n",
      "\n",
      "ðŸ§ª Experiment: use_map\n",
      "   train_out : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out_use\n",
      "   mode      : fused  -> loader mode: prompt_plus_map\n",
      "   âœ… Loaded: X=(562, 677) | df=(562, 15)\n",
      "   Operators: ['aggregate', 'displace', 'select', 'simplify']\n",
      "\n",
      "ðŸ§ª Experiment: openai_map\n",
      "   train_out : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out_openai\n",
      "   mode      : fused  -> loader mode: prompt_plus_map\n",
      "   âœ… Loaded: X=(562, 1701) | df=(562, 15)\n",
      "   Operators: ['aggregate', 'displace', 'select', 'simplify']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>extent_diag_m</th>\n",
       "      <th>extent_area_m2</th>\n",
       "      <th>extent_width_m</th>\n",
       "      <th>extent_height_m</th>\n",
       "      <th>extent_minx</th>\n",
       "      <th>extent_miny</th>\n",
       "      <th>extent_maxx</th>\n",
       "      <th>extent_maxy</th>\n",
       "      <th>operator</th>\n",
       "      <th>param_value</th>\n",
       "      <th>intensity</th>\n",
       "      <th>param_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1304</td>\n",
       "      <td>r00000000</td>\n",
       "      <td>Union few of the buildings.</td>\n",
       "      <td>582.418016</td>\n",
       "      <td>169604.830164</td>\n",
       "      <td>412.352091</td>\n",
       "      <td>411.310707</td>\n",
       "      <td>369009.126498</td>\n",
       "      <td>5.624443e+06</td>\n",
       "      <td>369421.478589</td>\n",
       "      <td>5.624855e+06</td>\n",
       "      <td>aggregate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1457</td>\n",
       "      <td>r00000002</td>\n",
       "      <td>Remove small buildings and eliminate narrow an...</td>\n",
       "      <td>496.278103</td>\n",
       "      <td>116190.319796</td>\n",
       "      <td>404.903965</td>\n",
       "      <td>286.957723</td>\n",
       "      <td>370209.074685</td>\n",
       "      <td>5.626969e+06</td>\n",
       "      <td>370613.978650</td>\n",
       "      <td>5.627256e+06</td>\n",
       "      <td>select</td>\n",
       "      <td>17.805</td>\n",
       "      <td>low</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1663</td>\n",
       "      <td>r00000005</td>\n",
       "      <td>Bundle nearby buildings into larger blocks.</td>\n",
       "      <td>533.109561</td>\n",
       "      <td>138157.356917</td>\n",
       "      <td>329.923688</td>\n",
       "      <td>418.755494</td>\n",
       "      <td>371811.357509</td>\n",
       "      <td>5.630840e+06</td>\n",
       "      <td>372141.281197</td>\n",
       "      <td>5.631259e+06</td>\n",
       "      <td>aggregate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1122</td>\n",
       "      <td>r00000006</td>\n",
       "      <td>Simplify small geometric details below a speci...</td>\n",
       "      <td>597.176996</td>\n",
       "      <td>178021.909966</td>\n",
       "      <td>434.102877</td>\n",
       "      <td>410.091523</td>\n",
       "      <td>367409.757832</td>\n",
       "      <td>5.630048e+06</td>\n",
       "      <td>367843.860710</td>\n",
       "      <td>5.630458e+06</td>\n",
       "      <td>simplify</td>\n",
       "      <td>1.000</td>\n",
       "      <td>low</td>\n",
       "      <td>0.001675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1706</td>\n",
       "      <td>r00000009</td>\n",
       "      <td>Eliminate repeated blocks.</td>\n",
       "      <td>465.952069</td>\n",
       "      <td>108172.503069</td>\n",
       "      <td>315.345720</td>\n",
       "      <td>343.028290</td>\n",
       "      <td>372305.411445</td>\n",
       "      <td>5.628541e+06</td>\n",
       "      <td>372620.757165</td>\n",
       "      <td>5.628884e+06</td>\n",
       "      <td>select</td>\n",
       "      <td>18.226</td>\n",
       "      <td>low</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1174</td>\n",
       "      <td>r00000010</td>\n",
       "      <td>Make a space between the polygons.</td>\n",
       "      <td>485.597704</td>\n",
       "      <td>105023.121090</td>\n",
       "      <td>414.108392</td>\n",
       "      <td>253.612636</td>\n",
       "      <td>367806.423992</td>\n",
       "      <td>5.631230e+06</td>\n",
       "      <td>368220.532385</td>\n",
       "      <td>5.631484e+06</td>\n",
       "      <td>displace</td>\n",
       "      <td>1.975</td>\n",
       "      <td>low</td>\n",
       "      <td>0.004067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0116</td>\n",
       "      <td>r00000011</td>\n",
       "      <td>Aggregate some of the buildings.</td>\n",
       "      <td>577.475387</td>\n",
       "      <td>166688.512862</td>\n",
       "      <td>403.286009</td>\n",
       "      <td>413.325801</td>\n",
       "      <td>359417.860505</td>\n",
       "      <td>5.619642e+06</td>\n",
       "      <td>359821.146514</td>\n",
       "      <td>5.620056e+06</td>\n",
       "      <td>aggregate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0417</td>\n",
       "      <td>r00000013</td>\n",
       "      <td>Exclude shapes with an area less than 20 squar...</td>\n",
       "      <td>571.706715</td>\n",
       "      <td>163423.957488</td>\n",
       "      <td>404.661369</td>\n",
       "      <td>403.853617</td>\n",
       "      <td>361813.128457</td>\n",
       "      <td>5.622451e+06</td>\n",
       "      <td>362217.789827</td>\n",
       "      <td>5.622855e+06</td>\n",
       "      <td>select</td>\n",
       "      <td>20.000</td>\n",
       "      <td>low</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1488</td>\n",
       "      <td>r00000014</td>\n",
       "      <td>Aggregate the blocks.</td>\n",
       "      <td>500.054694</td>\n",
       "      <td>115279.716486</td>\n",
       "      <td>276.818974</td>\n",
       "      <td>416.444418</td>\n",
       "      <td>370607.033823</td>\n",
       "      <td>5.619641e+06</td>\n",
       "      <td>370883.852797</td>\n",
       "      <td>5.620058e+06</td>\n",
       "      <td>aggregate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0175</td>\n",
       "      <td>r00000015</td>\n",
       "      <td>Simplify the shapes of the small buildings by ...</td>\n",
       "      <td>503.061104</td>\n",
       "      <td>119618.905293</td>\n",
       "      <td>409.629591</td>\n",
       "      <td>292.017247</td>\n",
       "      <td>359816.877837</td>\n",
       "      <td>5.623767e+06</td>\n",
       "      <td>360226.507427</td>\n",
       "      <td>5.624059e+06</td>\n",
       "      <td>aggregate</td>\n",
       "      <td>0.000</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  map_id  prompt_id                                               text  \\\n",
       "0   1304  r00000000                        Union few of the buildings.   \n",
       "1   1457  r00000002  Remove small buildings and eliminate narrow an...   \n",
       "2   1663  r00000005        Bundle nearby buildings into larger blocks.   \n",
       "3   1122  r00000006  Simplify small geometric details below a speci...   \n",
       "4   1706  r00000009                         Eliminate repeated blocks.   \n",
       "5   1174  r00000010                 Make a space between the polygons.   \n",
       "6   0116  r00000011                   Aggregate some of the buildings.   \n",
       "7   0417  r00000013  Exclude shapes with an area less than 20 squar...   \n",
       "8   1488  r00000014                              Aggregate the blocks.   \n",
       "9   0175  r00000015  Simplify the shapes of the small buildings by ...   \n",
       "\n",
       "   extent_diag_m  extent_area_m2  extent_width_m  extent_height_m  \\\n",
       "0     582.418016   169604.830164      412.352091       411.310707   \n",
       "1     496.278103   116190.319796      404.903965       286.957723   \n",
       "2     533.109561   138157.356917      329.923688       418.755494   \n",
       "3     597.176996   178021.909966      434.102877       410.091523   \n",
       "4     465.952069   108172.503069      315.345720       343.028290   \n",
       "5     485.597704   105023.121090      414.108392       253.612636   \n",
       "6     577.475387   166688.512862      403.286009       413.325801   \n",
       "7     571.706715   163423.957488      404.661369       403.853617   \n",
       "8     500.054694   115279.716486      276.818974       416.444418   \n",
       "9     503.061104   119618.905293      409.629591       292.017247   \n",
       "\n",
       "     extent_minx   extent_miny    extent_maxx   extent_maxy   operator  \\\n",
       "0  369009.126498  5.624443e+06  369421.478589  5.624855e+06  aggregate   \n",
       "1  370209.074685  5.626969e+06  370613.978650  5.627256e+06     select   \n",
       "2  371811.357509  5.630840e+06  372141.281197  5.631259e+06  aggregate   \n",
       "3  367409.757832  5.630048e+06  367843.860710  5.630458e+06   simplify   \n",
       "4  372305.411445  5.628541e+06  372620.757165  5.628884e+06     select   \n",
       "5  367806.423992  5.631230e+06  368220.532385  5.631484e+06   displace   \n",
       "6  359417.860505  5.619642e+06  359821.146514  5.620056e+06  aggregate   \n",
       "7  361813.128457  5.622451e+06  362217.789827  5.622855e+06     select   \n",
       "8  370607.033823  5.619641e+06  370883.852797  5.620058e+06  aggregate   \n",
       "9  359816.877837  5.623767e+06  360226.507427  5.624059e+06  aggregate   \n",
       "\n",
       "   param_value intensity  param_norm  \n",
       "0        0.000    medium    0.000000  \n",
       "1       17.805       low    0.000153  \n",
       "2        0.000    medium    0.000000  \n",
       "3        1.000       low    0.001675  \n",
       "4       18.226       low    0.000168  \n",
       "5        1.975       low    0.004067  \n",
       "6        0.000    medium    0.000000  \n",
       "7       20.000       low    0.000122  \n",
       "8        0.000    medium    0.000000  \n",
       "9        0.000    medium    0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================== CELL 6 â€” Load training data + compute param_norm (multi-experiment) =====================\n",
    "\n",
    "from dataclasses import replace\n",
    "from pathlib import Path\n",
    "\n",
    "from src.train.load_training_data import load_training_data_with_dynamic_param_norm\n",
    "\n",
    "def _to_loader_mode(feature_mode: str) -> str:\n",
    "    \"\"\"\n",
    "    Map our notebook naming to what load_training_data_with_dynamic_param_norm expects.\n",
    "    \"\"\"\n",
    "    fm = str(feature_mode).strip().lower()\n",
    "    if fm == \"prompt_only\":\n",
    "        return \"prompt_only\"\n",
    "    if fm in {\"fused\", \"prompt_plus_map\"}:\n",
    "        return \"prompt_plus_map\"\n",
    "    raise ValueError(f\"Unsupported feature_mode in EXPERIMENTS: {feature_mode}\")\n",
    "\n",
    "TRAIN_DATA = {}\n",
    "\n",
    "print(\"\\n=== Loading training data for all experiments ===\")\n",
    "\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "    train_out_dir = Path(cfg[\"train_out\"])\n",
    "    if not train_out_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing train_out for {exp_name}: {train_out_dir}\")\n",
    "\n",
    "    feature_mode_loader = _to_loader_mode(cfg[\"feature_mode\"])\n",
    "\n",
    "    # Many of your helpers read from PATHS.TRAIN_OUT.\n",
    "    # So we create an experiment-scoped PATHS that points TRAIN_OUT to this experiment folder.\n",
    "    PATHS_EXP = replace(PATHS, TRAIN_OUT=train_out_dir)\n",
    "\n",
    "    print(f\"\\nðŸ§ª Experiment: {exp_name}\")\n",
    "    print(f\"   train_out : {train_out_dir}\")\n",
    "    print(f\"   mode      : {cfg['feature_mode']}  -> loader mode: {feature_mode_loader}\")\n",
    "\n",
    "    data = load_training_data_with_dynamic_param_norm(\n",
    "        exp_name=exp_name,\n",
    "        feature_mode=feature_mode_loader,\n",
    "        paths=PATHS_EXP,\n",
    "        cfg=CFG,\n",
    "        distance_ops=DISTANCE_OPS,\n",
    "        area_ops=AREA_OPS,\n",
    "        require_text=True,\n",
    "    )\n",
    "\n",
    "    X = data.X\n",
    "    df = data.df\n",
    "\n",
    "    print(f\"   âœ… Loaded: X={X.shape} | df={df.shape}\")\n",
    "    print(\"   Operators:\", sorted(df[PATHS.OPERATOR_COL].dropna().unique().tolist()))\n",
    "\n",
    "    TRAIN_DATA[exp_name] = {\"X\": X, \"df\": df, \"paths\": PATHS_EXP}\n",
    "\n",
    "# Quick preview (optional)\n",
    "first_key = next(iter(TRAIN_DATA.keys()))\n",
    "display(TRAIN_DATA[first_key][\"df\"].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b997cab7",
   "metadata": {},
   "source": [
    "## Step 7 â€” Train/Validation/Test Split (Shared, Leakage-Free by Map)\n",
    "\n",
    "In this step, we construct a **reproducible and fair** train/validation/test split that is\n",
    "**shared across all experiments** (prompt-only, USE + map, OpenAI + map).  \n",
    "The split is computed **once** and then applied to every experiment to ensure that\n",
    "performance differences are attributable solely to the feature representation.\n",
    "\n",
    "---\n",
    "\n",
    "### Constraints enforced\n",
    "\n",
    "- **No leakage by map**  \n",
    "  The same `map_id` never appears in more than one split (train / validation / test).\n",
    "\n",
    "- **Multi-prompt maps are forced into TRAIN**  \n",
    "  If a map has multiple prompts, *all* corresponding samples are assigned to the\n",
    "  training set.  \n",
    "  As a result, validation and test sets contain **single-prompt maps only**.\n",
    "\n",
    "- **Consistency across experiments**  \n",
    "  The exact same samples (identified by `(map_id, prompt_id)`) are used for\n",
    "  train/validation/test in every experiment.\n",
    "\n",
    "---\n",
    "\n",
    "### Stratification strategy\n",
    "\n",
    "To obtain balanced splits while respecting the above constraints, stratification is applied as:\n",
    "\n",
    "- Primary: `operator Ã— intensity` (if sufficient samples exist), otherwise\n",
    "- Fallback: `operator` only (automatically selected if finer stratification is infeasible)\n",
    "\n",
    "---\n",
    "\n",
    "### Coverage requirement\n",
    "\n",
    "Each split is required to contain **all operators** in the fixed class set:\n",
    "\n",
    "- `simplify`\n",
    "- `select`\n",
    "- `aggregate`\n",
    "- `displace`\n",
    "\n",
    "This guarantees that classification and regression models can be trained and evaluated\n",
    "for every operator.\n",
    "\n",
    "---\n",
    "\n",
    "### Outputs\n",
    "\n",
    "- A single shared split definition is saved to disk as:  \n",
    "  `splits_shared.json`\n",
    "- For each experiment, the split is applied to slice:\n",
    "  - `X` â€” the feature matrix\n",
    "  - `df` â€” the aligned metadata table\n",
    "\n",
    "The resulting subsets (`train`, `val`, `test`) are then used in all downstream\n",
    "training and evaluation steps.\n",
    "\n",
    "---\n",
    "\n",
    "This design ensures:\n",
    "- **Leakage-free evaluation**\n",
    "- **Fair, apples-to-apples comparison** between experiments\n",
    "- **Reproducibility**, since the split is deterministic and persisted to disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc0897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Computing shared split using reference experiment: prompt_only ===\n",
      "=== DATASET SUMMARY ===\n",
      "Total rows (prompts): 562\n",
      "Unique maps: 399\n",
      "Multi-prompt maps (>1 prompt): 22\n",
      "Single-prompt maps (=1 prompt): 377\n",
      "\n",
      "Top 10 maps by prompt count:\n",
      "map_id\n",
      "1646    30\n",
      "1304    29\n",
      "1755    26\n",
      "1532    13\n",
      "0127    10\n",
      "0168     8\n",
      "0142     7\n",
      "0078     6\n",
      "0080     6\n",
      "0001     6\n",
      "dtype: int64\n",
      "\n",
      "=== SPLIT SUMMARY ===\n",
      "âœ… Split found (seed=42)\n",
      "Train maps: 285  (includes multi-prompt maps: 22)\n",
      "Val maps:   57\n",
      "Test maps:  57\n",
      "âœ… Verified: no map_id leakage across splits.\n",
      "âœ… Verified: all multi-prompt maps are in TRAIN.\n",
      "\n",
      "TRAIN â€” Operator counts\n",
      "operator\n",
      "select       144\n",
      "aggregate    134\n",
      "simplify     109\n",
      "displace      61\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "VAL â€” Operator counts\n",
      "operator\n",
      "select       19\n",
      "aggregate    16\n",
      "simplify     13\n",
      "displace      9\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "TEST â€” Operator counts\n",
      "operator\n",
      "select       19\n",
      "aggregate    16\n",
      "simplify     13\n",
      "displace      9\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "TRAIN â€” Operator Ã— Intensity table (counts)\n",
      "intensity  high  low  medium\n",
      "operator                    \n",
      "aggregate    37   38      59\n",
      "displace     13   20      28\n",
      "select       34   34      76\n",
      "simplify     25   26      58\n",
      "\n",
      "VAL â€” Operator Ã— Intensity table (counts)\n",
      "intensity  high  low  medium\n",
      "operator                    \n",
      "aggregate     5    6       5\n",
      "displace      3    3       3\n",
      "select        5    7       7\n",
      "simplify      4    4       5\n",
      "\n",
      "TEST â€” Operator Ã— Intensity table (counts)\n",
      "intensity  high  low  medium\n",
      "operator                    \n",
      "aggregate     5    6       5\n",
      "displace      3    3       3\n",
      "select        6    6       7\n",
      "simplify      4    4       5\n",
      "\n",
      "âœ… Saved splits to /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out/splits/splits_shared.json\n",
      "\n",
      "âœ… Shared split created:\n",
      "   Train keys: 448 | Val keys: 57 | Test keys: 57\n",
      "   Saved to: /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out/splits/splits_shared.json\n",
      "\n",
      "ðŸ§ª prompt_only\n",
      "Rows -> Train: (448, 512) Val: (57, 512) Test: (57, 512)\n",
      "\n",
      "ðŸ§ª use_map\n",
      "Rows -> Train: (448, 677) Val: (57, 677) Test: (57, 677)\n",
      "\n",
      "ðŸ§ª openai_map\n",
      "Rows -> Train: (448, 1701) Val: (57, 1701) Test: (57, 1701)\n"
     ]
    }
   ],
   "source": [
    "# ===================== CELL 7 â€” Shared Train/Val/Test Split (fair across experiments) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from src.train.splitting import make_splits_multi_prompt_to_train\n",
    "\n",
    "FIXED_CLASSES = [\"simplify\", \"select\", \"aggregate\", \"displace\"]\n",
    "USE_INTENSITY_FOR_STRAT = True\n",
    "\n",
    "OP_COL  = PATHS.OPERATOR_COL\n",
    "INT_COL = PATHS.INTENSITY_COL\n",
    "\n",
    "# Where to save ONE shared split (used by all experiments)\n",
    "SPLITS_DIR = Path(PATHS.SPLIT_OUT)\n",
    "SPLITS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "split_path = SPLITS_DIR / \"splits_shared.json\"\n",
    "\n",
    "# -------------------------------\n",
    "# Choose a reference experiment to compute the split once\n",
    "# (any experiment works as long as df has same rows)\n",
    "# -------------------------------\n",
    "ref_exp = next(iter(TRAIN_DATA.keys()))\n",
    "ref_df = TRAIN_DATA[ref_exp][\"df\"].copy()\n",
    "ref_X  = TRAIN_DATA[ref_exp][\"X\"]\n",
    "\n",
    "# Build a stable key per row for mapping splits across experiments\n",
    "# Assumes train_pairs.parquet contains map_id and prompt_id\n",
    "if not {\"map_id\", \"prompt_id\"}.issubset(ref_df.columns):\n",
    "    raise ValueError(\"Expected columns {'map_id','prompt_id'} in df (from train_pairs.parquet).\")\n",
    "\n",
    "ref_df[\"row_key\"] = ref_df[\"map_id\"].astype(str).str.zfill(4) + \"::\" + ref_df[\"prompt_id\"].astype(str)\n",
    "\n",
    "# Compute split ONCE\n",
    "print(f\"\\n=== Computing shared split using reference experiment: {ref_exp} ===\")\n",
    "\n",
    "split = make_splits_multi_prompt_to_train(\n",
    "    df=ref_df,\n",
    "    X=ref_X,\n",
    "    op_col=OP_COL,\n",
    "    intensity_col=INT_COL if INT_COL in ref_df.columns else None,\n",
    "    map_id_col=\"map_id\",\n",
    "    fixed_classes=FIXED_CLASSES,\n",
    "    use_intensity_for_strat=USE_INTENSITY_FOR_STRAT,\n",
    "    seed=int(CFG.SEED),\n",
    "    val_ratio=float(CFG.VAL_RATIO),\n",
    "    test_ratio=float(CFG.TEST_RATIO),\n",
    "    max_attempts=500,\n",
    "    save_splits_json=split_path,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "train_idx_ref, val_idx_ref, test_idx_ref = split.train_idx, split.val_idx, split.test_idx\n",
    "\n",
    "# Convert indices -> row_key sets (this is what we transfer across experiments)\n",
    "train_keys = set(ref_df.loc[train_idx_ref, \"row_key\"].tolist())\n",
    "val_keys   = set(ref_df.loc[val_idx_ref,   \"row_key\"].tolist())\n",
    "test_keys  = set(ref_df.loc[test_idx_ref,  \"row_key\"].tolist())\n",
    "\n",
    "# Sanity: no overlap\n",
    "assert train_keys.isdisjoint(val_keys) and train_keys.isdisjoint(test_keys) and val_keys.isdisjoint(test_keys)\n",
    "\n",
    "print(\"\\nâœ… Shared split created:\")\n",
    "print(f\"   Train keys: {len(train_keys)} | Val keys: {len(val_keys)} | Test keys: {len(test_keys)}\")\n",
    "print(f\"   Saved to: {split_path}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Apply the SAME split to every experiment by mapping row_key -> indices\n",
    "# -------------------------------\n",
    "SPLITS = {}  # exp_name -> dict with X_train/X_val/X_test and df_train/df_val/df_test\n",
    "\n",
    "for exp_name, pack in TRAIN_DATA.items():\n",
    "    df = pack[\"df\"].copy()\n",
    "    X  = pack[\"X\"]\n",
    "\n",
    "    df[\"row_key\"] = df[\"map_id\"].astype(str).str.zfill(4) + \"::\" + df[\"prompt_id\"].astype(str)\n",
    "\n",
    "    # Build index arrays in the current df order\n",
    "    train_idx = df.index[df[\"row_key\"].isin(train_keys)].to_numpy()\n",
    "    val_idx   = df.index[df[\"row_key\"].isin(val_keys)].to_numpy()\n",
    "    test_idx  = df.index[df[\"row_key\"].isin(test_keys)].to_numpy()\n",
    "\n",
    "    # Check that every key exists in this experiment (should be identical)\n",
    "    missing = (train_keys | val_keys | test_keys) - set(df[\"row_key\"].tolist())\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"Experiment '{exp_name}' is missing {len(missing)} rows from the shared split \"\n",
    "            f\"(first few: {list(sorted(missing))[:5]}). \"\n",
    "            \"This usually means train_pairs.parquet differs between experiments.\"\n",
    "        )\n",
    "\n",
    "    X_train, X_val, X_test = X[train_idx], X[val_idx], X[test_idx]\n",
    "    df_train = df.loc[train_idx].reset_index(drop=True)\n",
    "    df_val   = df.loc[val_idx].reset_index(drop=True)\n",
    "    df_test  = df.loc[test_idx].reset_index(drop=True)\n",
    "\n",
    "    SPLITS[exp_name] = {\n",
    "        \"train_idx\": train_idx,\n",
    "        \"val_idx\": val_idx,\n",
    "        \"test_idx\": test_idx,\n",
    "        \"X_train\": X_train, \"X_val\": X_val, \"X_test\": X_test,\n",
    "        \"df_train\": df_train, \"df_val\": df_val, \"df_test\": df_test,\n",
    "    }\n",
    "\n",
    "    print(f\"\\nðŸ§ª {exp_name}\")\n",
    "    print(\"Rows -> Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d187473d",
   "metadata": {},
   "source": [
    "## Step 8 â€” Modality-Aware Preprocessing (Experiment-Aware)\n",
    "\n",
    "This step applies preprocessing tailored to the input modalities **separately for each\n",
    "experiment**, using **training data only** to fit preprocessing parameters.  \n",
    "A preprocessing bundle is saved per experiment so the exact same transformations can be\n",
    "reused during evaluation and inference.\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt embeddings (all feature modes)\n",
    "\n",
    "Prompt vectors are normalized using **row-wise L2 normalization** to ensure consistent scale\n",
    "across samples and embedding backends (e.g., USE vs OpenAI).\n",
    "\n",
    "---\n",
    "\n",
    "### Map embeddings (only for fused prompt + map experiments)\n",
    "\n",
    "When the feature mode includes map vectors (`prompt_plus_map` / fused), the map block is\n",
    "processed using a robust pipeline:\n",
    "\n",
    "1. Replace non-finite values (`Â±inf`) with `NaN`\n",
    "2. Impute missing values using the **median** (fit on training data only)\n",
    "3. Clip each feature to training-set **5thâ€“95th percentiles** to reduce outlier impact\n",
    "4. Drop zero-variance (or near-constant) features based on training data\n",
    "5. Apply **RobustScaler** using quantile range **(5, 95)**\n",
    "\n",
    "The prompt block remains L2-normalized and is concatenated with the processed map block.\n",
    "\n",
    "---\n",
    "\n",
    "### Outputs (per experiment)\n",
    "\n",
    "For each experiment we obtain:\n",
    "\n",
    "- `X_train_s`, `X_val_s`, `X_test_s` â€” preprocessed matrices ready for training\n",
    "\n",
    "A preprocessing bundle is saved into the experimentâ€™s model output folder as:\n",
    "\n",
    "- `preproc.joblib`\n",
    "\n",
    "This ensures the exact same preprocessing can be reused for:\n",
    "- reproducible training\n",
    "- consistent evaluation across experiments\n",
    "- deployment-time inference (operator + parameter prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41942b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fitting modality-aware preprocessing per experiment ===\n",
      "\n",
      "ðŸ§ª Experiment: prompt_only\n",
      "   Feature mode : prompt_only -> prompt_only\n",
      "   map_dim      : 0\n",
      "   prompt_dim   : 512\n",
      "   Save preproc : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/models/exp_prompt_only/preproc.joblib\n",
      "   âœ… Preprocessing complete.\n",
      "   Shapes: (448, 512) (57, 512) (57, 512)\n",
      "\n",
      "ðŸ§ª Experiment: use_map\n",
      "   Feature mode : fused -> prompt_plus_map\n",
      "   map_dim      : 165\n",
      "   prompt_dim   : 512\n",
      "   Save preproc : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/models/exp_use_map/preproc.joblib\n",
      "   âœ… Preprocessing complete.\n",
      "   Shapes: (448, 677) (57, 677) (57, 677)\n",
      "\n",
      "ðŸ§ª Experiment: openai_map\n",
      "   Feature mode : fused -> prompt_plus_map\n",
      "   map_dim      : 165\n",
      "   prompt_dim   : 1536\n",
      "   Save preproc : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/models/exp_openai_map/preproc.joblib\n",
      "   âœ… Preprocessing complete.\n",
      "   Shapes: (448, 1701) (57, 1701) (57, 1701)\n",
      "\n",
      "âœ… All preprocessing finished.\n"
     ]
    }
   ],
   "source": [
    "# ===================== CELL 8 â€” Modality-aware preprocessing (per experiment) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "from src.train.preprocessing import fit_transform_modality_preproc\n",
    "\n",
    "PREPROC = {}  # exp_name -> dict with scaled arrays + bundle path\n",
    "\n",
    "print(\"\\n=== Fitting modality-aware preprocessing per experiment ===\")\n",
    "\n",
    "def _to_preproc_mode(feature_mode: str) -> str:\n",
    "    \"\"\"\n",
    "    Map notebook feature naming to preprocessing expectations.\n",
    "    \"\"\"\n",
    "    fm = str(feature_mode).strip().lower()\n",
    "    if fm == \"prompt_only\":\n",
    "        return \"prompt_only\"\n",
    "    if fm in {\"fused\", \"prompt_plus_map\"}:\n",
    "        return \"prompt_plus_map\"\n",
    "    raise ValueError(f\"Unsupported feature_mode for preprocessing: {feature_mode}\")\n",
    "\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "\n",
    "    split = SPLITS[exp_name]\n",
    "    feature_mode = cfg[\"feature_mode\"]\n",
    "    preproc_mode = _to_preproc_mode(feature_mode)\n",
    "\n",
    "    map_dim    = cfg[\"map_dim\"]\n",
    "    prompt_dim = cfg[\"prompt_dim\"]\n",
    "\n",
    "    model_out_dir = Path(cfg[\"model_out\"])\n",
    "    model_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    preproc_path = model_out_dir / \"preproc.joblib\"\n",
    "\n",
    "    print(f\"\\nðŸ§ª Experiment: {exp_name}\")\n",
    "    print(f\"   Feature mode : {feature_mode} -> {preproc_mode}\")\n",
    "    print(f\"   map_dim      : {map_dim}\")\n",
    "    print(f\"   prompt_dim   : {prompt_dim}\")\n",
    "    print(f\"   Save preproc : {preproc_path}\")\n",
    "\n",
    "    res = fit_transform_modality_preproc(\n",
    "        X_train=split[\"X_train\"],\n",
    "        X_val=split[\"X_val\"],\n",
    "        X_test=split[\"X_test\"],\n",
    "        feature_mode=preproc_mode,   # \"prompt_only\" or \"prompt_plus_map\"\n",
    "        map_dim=map_dim,\n",
    "        prompt_dim=prompt_dim,\n",
    "        eps=1e-12,\n",
    "        clip_q=(5, 95),\n",
    "        impute_strategy=\"median\",\n",
    "        robust_qrange=(5, 95),\n",
    "        save_path=preproc_path,\n",
    "    )\n",
    "\n",
    "    PREPROC[exp_name] = {\n",
    "        \"X_train_s\": res.X_train_s,\n",
    "        \"X_val_s\":   res.X_val_s,\n",
    "        \"X_test_s\":  res.X_test_s,\n",
    "        \"bundle_path\": res.bundle_path,\n",
    "    }\n",
    "\n",
    "    print(\"   âœ… Preprocessing complete.\")\n",
    "    print(\"   Shapes:\",\n",
    "          res.X_train_s.shape,\n",
    "          res.X_val_s.shape,\n",
    "          res.X_test_s.shape)\n",
    "\n",
    "print(\"\\nâœ… All preprocessing finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c32c2",
   "metadata": {},
   "source": [
    "## Step 9 â€” Build Class Labels and Sample Weights (Experiment-Aware)\n",
    "\n",
    "In this step, we construct the classification labels and training sample weights **for each\n",
    "experiment**, using the same fixed class order and the same split definition. This guarantees\n",
    "that differences in performance across experiments are due to the feature representation,\n",
    "not label encoding or sampling artifacts.\n",
    "\n",
    "---\n",
    "\n",
    "### Fixed class encoding\n",
    "\n",
    "Operator labels are encoded using a fixed global class order:\n",
    "\n",
    "`[simplify, select, aggregate, displace]`\n",
    "\n",
    "This guarantees consistent label indices across:\n",
    "- training\n",
    "- saved model bundles\n",
    "- evaluation and inference code\n",
    "\n",
    "Because the split is shared across experiments, this encoding remains stable and comparable.\n",
    "\n",
    "---\n",
    "\n",
    "### Sample weighting\n",
    "\n",
    "Training samples are weighted to address two common sources of bias:\n",
    "\n",
    "1. **Class imbalance**\n",
    "   - Balanced class weights are computed from the training distribution to prevent majority\n",
    "     classes from dominating learning.\n",
    "\n",
    "2. **Map-level prompt multiplicity**\n",
    "   - Some `map_id`s have multiple prompts.\n",
    "   - To prevent such maps from contributing disproportionately, each map contributes\n",
    "     approximately equal total weight by assigning each prompt a map-weight of:\n",
    "\n",
    "   `map_weight = 1 / (#prompts for that map_id)`\n",
    "\n",
    "---\n",
    "\n",
    "### Final weight definition\n",
    "\n",
    "The final per-sample weight used during training is:\n",
    "\n",
    "`sample_w = class_weight(operator) Ã— map_weight(map_id)`\n",
    "\n",
    "These weights are used during classifier training (and optionally regression training)\n",
    "to improve robustness and ensure fair learning across operators and maps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0df2b2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Building labels and sample weights per experiment ===\n",
      "\n",
      "ðŸ§ª prompt_only\n",
      "Classes (fixed order): [np.str_('simplify'), np.str_('select'), np.str_('aggregate'), np.str_('displace')]\n",
      "Class weights: {'simplify': 1.0275229357798166, 'select': 0.7777777777777778, 'aggregate': 0.835820895522388, 'displace': 1.8360655737704918}\n",
      "y_train/y_val/y_test shapes: (448,) (57,) (57,)\n",
      "Sample weight summary: {'min': 0.025925925925925925, 'max': 1.8360655737704918, 'mean': 0.6487687942076353}\n",
      "\n",
      "ðŸ§ª use_map\n",
      "Classes (fixed order): [np.str_('simplify'), np.str_('select'), np.str_('aggregate'), np.str_('displace')]\n",
      "Class weights: {'simplify': 1.0275229357798166, 'select': 0.7777777777777778, 'aggregate': 0.835820895522388, 'displace': 1.8360655737704918}\n",
      "y_train/y_val/y_test shapes: (448,) (57,) (57,)\n",
      "Sample weight summary: {'min': 0.025925925925925925, 'max': 1.8360655737704918, 'mean': 0.6487687942076353}\n",
      "\n",
      "ðŸ§ª openai_map\n",
      "Classes (fixed order): [np.str_('simplify'), np.str_('select'), np.str_('aggregate'), np.str_('displace')]\n",
      "Class weights: {'simplify': 1.0275229357798166, 'select': 0.7777777777777778, 'aggregate': 0.835820895522388, 'displace': 1.8360655737704918}\n",
      "y_train/y_val/y_test shapes: (448,) (57,) (57,)\n",
      "Sample weight summary: {'min': 0.025925925925925925, 'max': 1.8360655737704918, 'mean': 0.6487687942076353}\n",
      "\n",
      "âœ… Label build complete for all experiments (class order consistent).\n"
     ]
    }
   ],
   "source": [
    "# ===================== CELL 9 â€” Build labels + sample weights (per experiment) =====================\n",
    "\n",
    "import numpy as np\n",
    "from src.train.labels_and_weights import build_labels_and_sample_weights\n",
    "\n",
    "OP_COL = PATHS.OPERATOR_COL  # usually \"operator\"\n",
    "\n",
    "LABELS = {}  # exp_name -> labels, weights, class_names, etc.\n",
    "\n",
    "print(\"\\n=== Building labels and sample weights per experiment ===\")\n",
    "\n",
    "for exp_name, split in SPLITS.items():\n",
    "\n",
    "    df_train = split[\"df_train\"]\n",
    "    df_val   = split[\"df_val\"]\n",
    "    df_test  = split[\"df_test\"]\n",
    "\n",
    "    lab = build_labels_and_sample_weights(\n",
    "        df_train=df_train,\n",
    "        df_val=df_val,\n",
    "        df_test=df_test,\n",
    "        op_col=OP_COL,\n",
    "        map_id_col=\"map_id\",\n",
    "        fixed_classes=FIXED_CLASSES,\n",
    "        use_map_weight=True,\n",
    "        class_weight_mode=\"balanced\",\n",
    "    )\n",
    "\n",
    "    class_names = np.array(lab.class_names)\n",
    "\n",
    "    LABELS[exp_name] = {\n",
    "        \"class_names\": class_names,\n",
    "        \"y_train_cls\": lab.y_train,\n",
    "        \"y_val_cls\":   lab.y_val,\n",
    "        \"y_test_cls\":  lab.y_test,\n",
    "        \"sample_w\":    lab.sample_w,\n",
    "        \"class_weight_map\": lab.class_weight_map,\n",
    "    }\n",
    "\n",
    "    print(f\"\\nðŸ§ª {exp_name}\")\n",
    "    print(\"Classes (fixed order):\", list(class_names))\n",
    "    print(\"Class weights:\", lab.class_weight_map)\n",
    "    print(\n",
    "        \"y_train/y_val/y_test shapes:\",\n",
    "        lab.y_train.shape, lab.y_val.shape, lab.y_test.shape\n",
    "    )\n",
    "    sw = lab.sample_w\n",
    "    print(\"Sample weight summary:\", {\"min\": float(sw.min()), \"max\": float(sw.max()), \"mean\": float(sw.mean())})\n",
    "\n",
    "# Optional: sanity check that class order is identical across experiments\n",
    "first = next(iter(LABELS.keys()))\n",
    "base_classes = LABELS[first][\"class_names\"].tolist()\n",
    "for exp_name in LABELS.keys():\n",
    "    if LABELS[exp_name][\"class_names\"].tolist() != base_classes:\n",
    "        raise ValueError(f\"Class order differs in experiment {exp_name}. This would break fair comparison.\")\n",
    "print(\"\\nâœ… Label build complete for all experiments (class order consistent).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988f274",
   "metadata": {},
   "source": [
    "## Step 10 â€” Operator Classification Model (MLP, Experiment-Aware)\n",
    "\n",
    "This step trains the operator classifier that predicts one of the four map generalization\n",
    "operators:\n",
    "\n",
    "`{simplify, select, aggregate, displace}`\n",
    "\n",
    "The same training protocol is applied **independently for each experiment** (prompt-only,\n",
    "USE + map, OpenAI + map) using the **shared split**. This ensures that differences in\n",
    "performance across experiments are attributable to the feature representation rather than\n",
    "changes in training procedure.\n",
    "\n",
    "---\n",
    "\n",
    "### Model and training strategy\n",
    "\n",
    "- We use an **MLPClassifier** (multi-layer perceptron).\n",
    "- Hyperparameters are explored via a lightweight random search over:\n",
    "  - hidden layer sizes\n",
    "  - weight decay (`alpha`)\n",
    "  - learning rate schedule\n",
    "  - batch size / optimization settings (as implemented in the helper)\n",
    "\n",
    "---\n",
    "\n",
    "### Validation protocol (leakage-free)\n",
    "\n",
    "To prevent leakage, we perform **grouped cross-validation** using `map_id`:\n",
    "\n",
    "- prompts from the same map are never split across folds\n",
    "\n",
    "This is critical because multiple prompts may refer to the same map and would otherwise\n",
    "inflate performance due to memorization.\n",
    "\n",
    "---\n",
    "\n",
    "### Model selection and evaluation\n",
    "\n",
    "The best configuration is selected using validation performance (with grouped CV used for\n",
    "reliable hyperparameter tuning). The selected model is then retrained on the full training\n",
    "split and evaluated on validation and test splits.\n",
    "\n",
    "---\n",
    "\n",
    "### Outputs (per experiment)\n",
    "\n",
    "For each experiment, the trained classifier is saved into the experimentâ€™s model folder as:\n",
    "\n",
    "- `classifier.joblib`\n",
    "\n",
    "This classifier is later used to:\n",
    "1. predict the operator class\n",
    "2. route each sample to the correct operator-specific parameter regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95133825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training operator classifiers for all experiments ===\n",
      "\n",
      "ðŸ§ª Experiment: prompt_only\n",
      "   Classes   : ['simplify', 'select', 'aggregate', 'displace']\n",
      "   Train X   : (448, 512)\n",
      "   Val X     : (57, 512)\n",
      "   Test X    : (57, 512)\n",
      "   Model out : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/models/exp_prompt_only\n",
      "\n",
      "Searching 50 MLP configs...\n",
      "[01/50] cvF1=0.809Â±0.048 | VAL F1=0.944 acc=0.947 | (128, 64), Î±=2.02e-02, lr=1.2e-03, bs=16\n",
      "[02/50] cvF1=0.813Â±0.059 | VAL F1=0.944 acc=0.947 | (256, 128), Î±=3.49e-05, lr=1.7e-04, bs=64\n",
      "[03/50] cvF1=0.808Â±0.064 | VAL F1=0.944 acc=0.947 | (256,), Î±=1.03e-02, lr=7.7e-04, bs=128\n",
      "[04/50] cvF1=0.804Â±0.066 | VAL F1=0.944 acc=0.947 | (256,), Î±=1.18e-05, lr=2.7e-03, bs=128\n",
      "[05/50] cvF1=0.806Â±0.058 | VAL F1=0.944 acc=0.947 | (256, 128, 64), Î±=5.47e-05, lr=1.9e-04, bs=16\n",
      "[06/50] cvF1=0.804Â±0.066 | VAL F1=0.944 acc=0.947 | (64,), Î±=1.14e-04, lr=6.0e-04, bs=128\n",
      "[07/50] cvF1=0.800Â±0.062 | VAL F1=0.944 acc=0.947 | (64,), Î±=1.03e-04, lr=8.0e-04, bs=32\n",
      "[08/50] cvF1=0.803Â±0.062 | VAL F1=0.944 acc=0.947 | (128, 64), Î±=2.43e-02, lr=2.2e-04, bs=32\n",
      "[09/50] cvF1=0.805Â±0.060 | VAL F1=0.944 acc=0.947 | (256, 128, 64), Î±=4.95e-05, lr=5.7e-04, bs=128\n",
      "[10/50] cvF1=0.802Â±0.065 | VAL F1=0.947 acc=0.947 | (64,), Î±=1.45e-05, lr=7.9e-04, bs=16\n",
      "[11/50] cvF1=0.802Â±0.060 | VAL F1=0.944 acc=0.947 | (64,), Î±=1.68e-05, lr=2.5e-03, bs=128\n",
      "[12/50] cvF1=0.809Â±0.072 | VAL F1=0.944 acc=0.947 | (256, 128, 64), Î±=6.47e-03, lr=2.8e-04, bs=16\n",
      "[13/50] cvF1=0.806Â±0.056 | VAL F1=0.944 acc=0.947 | (128,), Î±=2.39e-03, lr=4.5e-04, bs=64\n",
      "[14/50] cvF1=0.812Â±0.052 | VAL F1=0.944 acc=0.947 | (128, 64), Î±=5.27e-04, lr=1.1e-04, bs=32\n",
      "[15/50] cvF1=0.799Â±0.062 | VAL F1=0.944 acc=0.947 | (64,), Î±=7.94e-05, lr=9.5e-04, bs=32\n",
      "[16/50] cvF1=0.811Â±0.052 | VAL F1=0.944 acc=0.947 | (256, 128, 64), Î±=6.43e-04, lr=6.4e-04, bs=32\n",
      "[17/50] cvF1=0.790Â±0.053 | VAL F1=0.944 acc=0.947 | (256, 128), Î±=2.35e-02, lr=1.4e-03, bs=32\n",
      "[18/50] cvF1=0.807Â±0.058 | VAL F1=0.944 acc=0.947 | (128,), Î±=1.29e-02, lr=7.6e-04, bs=128\n",
      "[19/50] cvF1=0.819Â±0.062 | VAL F1=0.944 acc=0.947 | (256, 128, 64), Î±=4.80e-05, lr=1.2e-04, bs=128\n",
      "[20/50] cvF1=0.814Â±0.064 | VAL F1=0.947 acc=0.947 | (256, 128), Î±=2.25e-04, lr=2.5e-04, bs=16\n",
      "[21/50] cvF1=0.814Â±0.051 | VAL F1=0.944 acc=0.947 | (128,), Î±=2.27e-02, lr=7.9e-04, bs=16\n",
      "[22/50] cvF1=0.801Â±0.060 | VAL F1=0.944 acc=0.947 | (64,), Î±=1.07e-04, lr=1.8e-04, bs=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/thesis/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/50] cvF1=0.817Â±0.054 | VAL F1=0.944 acc=0.947 | (64,), Î±=4.84e-03, lr=2.0e-04, bs=128\n",
      "[24/50] cvF1=0.804Â±0.066 | VAL F1=0.944 acc=0.947 | (256,), Î±=4.91e-05, lr=1.1e-03, bs=64\n",
      "[25/50] cvF1=0.806Â±0.061 | VAL F1=0.944 acc=0.947 | (64,), Î±=1.28e-03, lr=2.3e-03, bs=32\n",
      "[26/50] cvF1=0.808Â±0.061 | VAL F1=0.944 acc=0.947 | (64,), Î±=1.52e-02, lr=1.8e-03, bs=128\n",
      "[27/50] cvF1=0.801Â±0.060 | VAL F1=0.944 acc=0.947 | (128,), Î±=2.15e-05, lr=3.5e-04, bs=32\n",
      "[28/50] cvF1=0.799Â±0.066 | VAL F1=0.944 acc=0.947 | (256, 128), Î±=3.44e-03, lr=8.7e-04, bs=64\n"
     ]
    }
   ],
   "source": [
    "# ===================== CELL 10 â€” Train classifier (per experiment, MLP search + final fit) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from dataclasses import asdict, is_dataclass\n",
    "\n",
    "from src.train.train_classifier import train_mlp_classifier_with_search\n",
    "\n",
    "CLF_RESULTS = {}  # exp_name -> ClassifierTrainResult\n",
    "\n",
    "def _safe_get(obj, *names, default=None):\n",
    "    for n in names:\n",
    "        if hasattr(obj, n):\n",
    "            return getattr(obj, n)\n",
    "    return default\n",
    "\n",
    "print(\"\\n=== Training operator classifiers for all experiments ===\")\n",
    "\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "\n",
    "    split = SPLITS[exp_name]\n",
    "    pre   = PREPROC[exp_name]\n",
    "    lab   = LABELS[exp_name]\n",
    "\n",
    "    X_train_s = pre[\"X_train_s\"]\n",
    "    X_val_s   = pre[\"X_val_s\"]\n",
    "    X_test_s  = pre[\"X_test_s\"]\n",
    "\n",
    "    y_train = lab[\"y_train_cls\"]\n",
    "    y_val   = lab[\"y_val_cls\"]\n",
    "    y_test  = lab[\"y_test_cls\"]\n",
    "    sample_w = lab[\"sample_w\"]\n",
    "\n",
    "    class_names = [str(x) for x in lab[\"class_names\"]]\n",
    "\n",
    "    # Grouped CV: group by map_id to avoid leakage across folds\n",
    "    groups_tr = split[\"df_train\"][\"map_id\"].astype(str).to_numpy()\n",
    "\n",
    "    model_out_dir = Path(cfg[\"model_out\"])\n",
    "    model_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nðŸ§ª Experiment: {exp_name}\")\n",
    "    print(f\"   Classes   : {class_names}\")\n",
    "    print(f\"   Train X   : {X_train_s.shape}\")\n",
    "    print(f\"   Val X     : {X_val_s.shape}\")\n",
    "    print(f\"   Test X    : {X_test_s.shape}\")\n",
    "    print(f\"   Model out : {model_out_dir}\")\n",
    "\n",
    "    res_clf = train_mlp_classifier_with_search(\n",
    "        exp_name=exp_name,\n",
    "        X_train=X_train_s,\n",
    "        y_train=y_train,\n",
    "        groups_train=groups_tr,\n",
    "        sample_w=sample_w,\n",
    "        X_val=X_val_s,\n",
    "        y_val=y_val,\n",
    "        X_test=X_test_s,\n",
    "        y_test=y_test,\n",
    "        class_names=class_names,\n",
    "        out_dir=model_out_dir,\n",
    "        n_iter=50,\n",
    "        n_splits=5,\n",
    "        seed=int(CFG.SEED),\n",
    "        verbose=True,\n",
    "        save_name=\"classifier.joblib\",\n",
    "    )\n",
    "\n",
    "    CLF_RESULTS[exp_name] = res_clf\n",
    "\n",
    "    # ---- robust reporting (no assumptions about field names) ----\n",
    "    model_path = _safe_get(res_clf, \"model_path\", \"path\", default=str(model_out_dir / \"classifier.joblib\"))\n",
    "    best_val_f1 = _safe_get(res_clf, \"best_val_f1\", \"val_f1\", \"best_f1\", default=None)\n",
    "    best_val_acc = _safe_get(res_clf, \"best_val_acc\", \"val_acc\", \"best_accuracy\", default=None)\n",
    "    test_f1 = _safe_get(res_clf, \"test_f1\", default=None)\n",
    "    test_acc = _safe_get(res_clf, \"test_acc\", \"accuracy_test\", default=None)\n",
    "\n",
    "    print(\"   âœ… Classifier training done.\")\n",
    "    print(\"   Saved to:\", model_path)\n",
    "    if best_val_f1 is not None or best_val_acc is not None:\n",
    "        print(\"   Best VAL:\", {\"macro_f1\": best_val_f1, \"acc\": best_val_acc})\n",
    "    if test_f1 is not None or test_acc is not None:\n",
    "        print(\"   TEST     :\", {\"macro_f1\": test_f1, \"acc\": test_acc})\n",
    "\n",
    "    # Optional: print available fields once for debugging\n",
    "    if exp_name == next(iter(EXPERIMENTS.keys())):\n",
    "        if is_dataclass(res_clf):\n",
    "            print(\"   (debug) Result fields:\", list(asdict(res_clf).keys()))\n",
    "        else:\n",
    "            print(\"   (debug) Result attrs :\", [a for a in dir(res_clf) if not a.startswith(\"_\")])\n",
    "\n",
    "print(\"\\nâœ… All classifiers trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f878f54",
   "metadata": {},
   "source": [
    "## Step 11 â€” Parameter Regression (Per-Operator) and Final Model Bundle (Experiment-Aware)\n",
    "\n",
    "This step trains **operator-specific regressors** to predict the generalization parameter in a\n",
    "**scale-independent form**, and then packages all trained components into a single,\n",
    "experiment-scoped model bundle.\n",
    "\n",
    "The same procedure is applied **independently for each experiment** (prompt-only,\n",
    "USE + map, OpenAI + map), using the shared data split and preprocessing pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### Regression target\n",
    "\n",
    "Regressors are trained on the normalized target `param_norm`, defined as:\n",
    "\n",
    "- **Distance-based operators** (`simplify`, `aggregate`, `displace`):  \n",
    "  `param_norm = param_value / extent_diag_m`\n",
    "\n",
    "- **Area-based operators** (`select`):  \n",
    "  `param_norm = param_value / extent_area_m2`\n",
    "\n",
    "This normalization allows each regressor to generalize across maps of different spatial\n",
    "extent while preserving physical meaning. During inference, predictions are converted back\n",
    "to real-world units using the same per-map extent references.\n",
    "\n",
    "---\n",
    "\n",
    "### Training strategy\n",
    "\n",
    "- One **MLPRegressor per operator**\n",
    "- Training data restricted to samples of the corresponding operator\n",
    "- **Grouped cross-validation** (`GroupKFold`) by `map_id` to prevent spatial leakage\n",
    "- Hyperparameter optimization via `RandomizedSearchCV` for each operator independently\n",
    "\n",
    "---\n",
    "\n",
    "### Final model bundle\n",
    "\n",
    "For each experiment, the trained components are stored together in a single bundle:\n",
    "\n",
    "- `cls_plus_regressors.joblib`\n",
    "\n",
    "This bundle contains:\n",
    "- the trained operator classifier\n",
    "- the dictionary of operator-specific regressors\n",
    "- the fixed class order\n",
    "- normalization metadata (operator groups and extent columns)\n",
    "\n",
    "Along with the experimentâ€™s `preproc.joblib`, this bundle is sufficient for the evaluation\n",
    "notebook to compute:\n",
    "\n",
    "1. **Classifier-only metrics**  \n",
    "2. **Regressor-only metrics** (oracle operator routing)  \n",
    "3. **End-to-end pipeline metrics** (predicted operator routing)\n",
    "\n",
    "This design keeps evaluation simple, reproducible, and fully decoupled from the training\n",
    "notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7905b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== CELL 11 â€” Train per-operator regressors + save final bundle (per experiment) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "from src.train.train_regressors import train_regressors_per_operator\n",
    "from src.train.save_bundle import save_cls_plus_regressors_bundle\n",
    "\n",
    "BUNDLES = {}     # exp_name -> bundle path\n",
    "REG_RESULTS = {} # exp_name -> regressor training result\n",
    "\n",
    "print(\"\\n=== Training per-operator regressors and saving final bundles ===\")\n",
    "\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "\n",
    "    split = SPLITS[exp_name]\n",
    "    pre   = PREPROC[exp_name]\n",
    "    lab   = LABELS[exp_name]\n",
    "    res_clf = CLF_RESULTS[exp_name]\n",
    "\n",
    "    X_train_s = pre[\"X_train_s\"]\n",
    "    df_train  = split[\"df_train\"]\n",
    "    y_train_cls = lab[\"y_train_cls\"]\n",
    "    sample_w = lab[\"sample_w\"]\n",
    "\n",
    "    # Make sure class_names is list[str] (stable ordering)\n",
    "    cn = [str(x) for x in lab[\"class_names\"]]\n",
    "\n",
    "    model_out_dir = Path(cfg[\"model_out\"])\n",
    "    model_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nðŸ§ª Experiment: {exp_name}\")\n",
    "    print(f\"   Model out: {model_out_dir}\")\n",
    "    print(f\"   Train X  : {X_train_s.shape} | df_train: {df_train.shape}\")\n",
    "\n",
    "    # ---- (1) Train per-operator regressors on TRAIN only ----\n",
    "    reg_res = train_regressors_per_operator(\n",
    "        X_train_s=X_train_s,\n",
    "        df_train=df_train,\n",
    "        y_train_cls=y_train_cls,\n",
    "        class_names=cn,\n",
    "        sample_w=sample_w,\n",
    "        group_col=\"map_id\",\n",
    "        target_col=\"param_norm\",\n",
    "        use_log1p=False,\n",
    "        n_splits=5,\n",
    "        n_iter=40,\n",
    "        random_state=int(CFG.SEED),\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    REG_RESULTS[exp_name] = reg_res\n",
    "\n",
    "    # ---- (2) Load the trained classifier model (from Cell 10 output) ----\n",
    "    clf_pack = joblib.load(Path(res_clf.model_path))\n",
    "    final_clf = clf_pack[\"model\"]\n",
    "\n",
    "    # ---- (3) Save combined bundle for evaluation notebook ----\n",
    "    bundle_res = save_cls_plus_regressors_bundle(\n",
    "        exp_name=exp_name,\n",
    "        out_dir=model_out_dir,\n",
    "        classifier=final_clf,\n",
    "        regressors_by_class=reg_res.regressors_by_class,\n",
    "        class_names=cn,\n",
    "        use_log1p=reg_res.use_log1p,\n",
    "        cv_summary=reg_res.cv_summary,\n",
    "        distance_ops=DISTANCE_OPS,\n",
    "        area_ops=AREA_OPS,\n",
    "        diag_col=\"extent_diag_m\",\n",
    "        area_col=\"extent_area_m2\",\n",
    "        save_name=\"cls_plus_regressors.joblib\",  # fixed name inside each experiment folder\n",
    "    )\n",
    "\n",
    "    BUNDLES[exp_name] = bundle_res.bundle_path\n",
    "\n",
    "    print(\"   âœ… Saved bundle:\", bundle_res.bundle_path)\n",
    "    print(\"   âœ… Regressors trained for:\", sorted(list(reg_res.regressors_by_class.keys())))\n",
    "\n",
    "print(\"\\nâœ… All bundles saved.\")\n",
    "for k, v in BUNDLES.items():\n",
    "    print(f\" - {k:12s}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b0428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
