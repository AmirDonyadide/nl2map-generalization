{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f56a2c",
   "metadata": {},
   "source": [
    "## üß© 0) Setup & Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "367f89f6ac45439b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T11:21:53.302406Z",
     "start_time": "2025-10-27T11:21:53.298709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONFIG SUMMARY ===\n",
      "PROJ_ROOT  : /Users/amirdonyadide/Documents/GitHub/Thesis\n",
      "DATA_DIR   : /Users/amirdonyadide/Documents/GitHub/Thesis/data\n",
      "INPUT_DIR  : /Users/amirdonyadide/Documents/GitHub/Thesis/data/input\n",
      "OUTPUT_DIR : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output\n",
      "MAPS_ROOT  : /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/samples/pairs\n",
      "INPUT PAT. : *_input.geojson\n",
      "PROMPTS_CSV: /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/prompts.csv\n",
      "PAIRS_CSV  : /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/pairs.csv\n",
      "PROMPT_OUT : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out\n",
      "MAP_OUT    : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out\n",
      "TRAIN_OUT  : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out\n",
      "MODEL_OUT  : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/models\n",
      "SPLIT_OUT  : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out/splits\n",
      "PRM_NPZ    : /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/prompts_embeddings.npz\n",
      "--- Model ---\n",
      "USE_MODEL  : dan\n",
      "MAP_DIM    : 165\n",
      "PROMPT_DIM : 512\n",
      "FUSED_DIM  : 677\n",
      "BATCH_SIZE : 512\n",
      "VAL/TEST   : 0.15 0.15\n",
      "SEED       : 42\n",
      "üßπ Removing old directory: /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out\n",
      "üßπ Removing old directory: /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out\n",
      "üßπ Removing old directory: /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out\n",
      "üßπ Removing old directory: /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/models\n",
      "‚úÖ All output folders cleaned and recreated fresh.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===================== PARAMETERS / IMPORTS =====================\n",
    "from pathlib import Path\n",
    "import sys, subprocess, numpy as np, pandas as pd, joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Project config\n",
    "PROJ_ROOT = Path(\"../\").resolve()\n",
    "SRC_DIR   = PROJ_ROOT / \"src\"\n",
    "if str(PROJ_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJ_ROOT))\n",
    "\n",
    "from src.config import PATHS, CFG, print_summary\n",
    "print_summary()\n",
    "\n",
    "# Dims (fallbacks if CFG unset)\n",
    "MAP_DIM     = CFG.MAP_DIM or 165\n",
    "PROMPT_DIM  = CFG.PROMPT_DIM or 512\n",
    "FUSED_DIM   = CFG.FUSED_DIM or (MAP_DIM + PROMPT_DIM)\n",
    "BATCH_SIZE  = CFG.BATCH_SIZE\n",
    "\n",
    "# Clean outputs for a fresh run\n",
    "PATHS.clean_outputs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2350e",
   "metadata": {},
   "source": [
    "## üìö 1) Build Prompt Embeddings (USE) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ed0df45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T11:21:55.572701Z",
     "start_time": "2025-10-27T11:21:55.570071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMD: /opt/anaconda3/envs/thesis/bin/python -m src.mapvec.prompts.prompt_embeddings --input /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/prompts.csv --model dan --l2 --out_dir /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:06:32 | DEBUG | FILE_DIR=/Users/amirdonyadide/Documents/GitHub/Thesis/src/mapvec/prompts\n",
      "17:06:32 | DEBUG | PROJECT_ROOT=/Users/amirdonyadide/Documents/GitHub/Thesis\n",
      "17:06:32 | DEBUG | DEFAULT_DATA_DIR=/Users/amirdonyadide/Documents/GitHub/Thesis/data\n",
      "17:06:32 | INFO | DATA_DIR=/Users/amirdonyadide/Documents/GitHub/Thesis/data\n",
      "17:06:32 | INFO | INPUT=/Users/amirdonyadide/Documents/GitHub/Thesis/data/input/prompts.csv\n",
      "17:06:32 | INFO | OUT_DIR=/Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out\n",
      "17:06:32 | INFO | Reading CSV: /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/prompts.csv\n",
      "17:06:32 | INFO | Loaded 500 prompts (id_col=prompt_id). Sample IDs: p001, p002, p003‚Ä¶\n",
      "17:06:32 | INFO | Using local USE-dan at /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/model_dan\n",
      "17:06:32 | INFO | Loading USE-dan from local path: /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/model_dan ‚Ä¶\n",
      "17:06:36 | INFO | Fingerprint not found. Saved model loading will continue.\n",
      "17:06:36 | INFO | path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
      "17:06:36 | INFO | Model loaded in 3.48s\n",
      "17:06:36 | INFO | Embedding 500 prompts (batch_size=512, l2=True)‚Ä¶\n",
      "17:06:36 | DEBUG |   embedded rows [1:500)\n",
      "17:06:36 | INFO | Done embedding in 0.14s (dim=512).\n",
      "17:06:36 | INFO | Writing outputs to /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out\n",
      "17:06:36 | INFO |   saved prompts_embeddings.npz (shape=(500, 512))\n",
      "17:06:36 | INFO |   saved prompts.parquet (rows=500)\n",
      "17:06:36 | INFO |   saved meta.json\n",
      "17:06:36 | INFO | All done ‚úÖ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prompt embeddings completed.\n"
     ]
    }
   ],
   "source": [
    "# === PROMPT EMBEDDINGS ===\n",
    "cmd = [\n",
    "    sys.executable, \"-m\", \"src.mapvec.prompts.prompt_embeddings\",\n",
    "    \"--input\",    str(PATHS.PROMPTS_CSV),\n",
    "    \"--model\",    str(CFG.USE_MODEL),\n",
    "    \"--l2\",\n",
    "    \"--out_dir\",  str(PATHS.PROMPT_OUT),\n",
    "    \"-v\",\n",
    "]\n",
    "print(\"CMD:\", \" \".join(cmd))\n",
    "res = subprocess.run(cmd, cwd=str(PATHS.PROJ_ROOT))\n",
    "if res.returncode != 0:\n",
    "    raise SystemExit(\"Prompt embedding step failed.\")\n",
    "print(\"‚úÖ Prompt embeddings completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c0b51",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è 2) Build Map Embeddings (geometric) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9ca0c3d8b71fc70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T11:26:59.687350Z",
     "start_time": "2025-10-27T11:26:19.901557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMD: /opt/anaconda3/envs/thesis/bin/python -m src.mapvec.maps.map_embeddings --root /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/samples/pairs --pattern *_input.geojson --out_dir /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out --norm fixed --norm-wh 400x400 -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:07:06 | DEBUG | PROJECT_ROOT=/Users/amirdonyadide/Documents/GitHub/Thesis\n",
      "17:07:06 | DEBUG | DATA_DIR=/Users/amirdonyadide/Documents/GitHub/Thesis/data\n",
      "17:07:06 | INFO | Scanning /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/samples/pairs (pattern=*_input.geojson)‚Ä¶\n",
      "17:07:06 | INFO | First pass: counting polygons to normalize poly_count‚Ä¶\n",
      "17:07:11 | INFO | Max polygons across dataset: 789\n",
      "17:07:12 | INFO | OK  map_id=0073  -> vector[165]\n",
      "17:07:14 | INFO | OK  map_id=0080  -> vector[165]\n",
      "17:07:14 | INFO | OK  map_id=0093  -> vector[165]\n",
      "17:07:18 | INFO | OK  map_id=0122  -> vector[165]\n",
      "17:07:19 | INFO | OK  map_id=0123  -> vector[165]\n",
      "17:07:20 | INFO | OK  map_id=0127  -> vector[165]\n",
      "17:07:21 | INFO | OK  map_id=0158  -> vector[165]\n",
      "17:07:23 | INFO | OK  map_id=0159  -> vector[165]\n",
      "17:07:24 | INFO | OK  map_id=0160  -> vector[165]\n",
      "17:07:25 | INFO | OK  map_id=0165  -> vector[165]\n",
      "17:07:26 | INFO | OK  map_id=0167  -> vector[165]\n",
      "17:07:27 | INFO | OK  map_id=0168  -> vector[165]\n",
      "17:07:28 | INFO | OK  map_id=0171  -> vector[165]\n",
      "17:07:31 | INFO | OK  map_id=0208  -> vector[165]\n",
      "17:07:34 | INFO | OK  map_id=0209  -> vector[165]\n",
      "17:07:35 | INFO | OK  map_id=0215  -> vector[165]\n",
      "17:07:36 | INFO | OK  map_id=0240  -> vector[165]\n",
      "17:07:37 | INFO | OK  map_id=0256  -> vector[165]\n",
      "17:07:38 | INFO | OK  map_id=0257  -> vector[165]\n",
      "17:07:39 | INFO | OK  map_id=0262  -> vector[165]\n",
      "17:07:41 | INFO | OK  map_id=0285  -> vector[165]\n",
      "17:07:42 | INFO | OK  map_id=0286  -> vector[165]\n",
      "17:07:46 | INFO | OK  map_id=0288  -> vector[165]\n",
      "17:07:48 | INFO | OK  map_id=0289  -> vector[165]\n",
      "17:07:49 | INFO | OK  map_id=0313  -> vector[165]\n",
      "17:07:50 | INFO | OK  map_id=0341  -> vector[165]\n",
      "17:07:51 | INFO | OK  map_id=0362  -> vector[165]\n",
      "17:07:53 | INFO | OK  map_id=0363  -> vector[165]\n",
      "17:07:55 | INFO | OK  map_id=0364  -> vector[165]\n",
      "17:07:56 | INFO | OK  map_id=0379  -> vector[165]\n",
      "17:07:57 | INFO | OK  map_id=0389  -> vector[165]\n",
      "17:07:59 | INFO | OK  map_id=0390  -> vector[165]\n",
      "17:08:00 | INFO | OK  map_id=0409  -> vector[165]\n",
      "17:08:02 | INFO | OK  map_id=0410  -> vector[165]\n",
      "17:08:03 | INFO | OK  map_id=0412  -> vector[165]\n",
      "17:08:04 | INFO | OK  map_id=0413  -> vector[165]\n",
      "17:08:06 | INFO | OK  map_id=0414  -> vector[165]\n",
      "17:08:07 | INFO | OK  map_id=0417  -> vector[165]\n",
      "17:08:08 | INFO | OK  map_id=0421  -> vector[165]\n",
      "17:08:09 | INFO | OK  map_id=0426  -> vector[165]\n",
      "17:08:10 | INFO | OK  map_id=0427  -> vector[165]\n",
      "17:08:11 | INFO | OK  map_id=0432  -> vector[165]\n",
      "17:08:12 | INFO | OK  map_id=0433  -> vector[165]\n",
      "17:08:13 | INFO | OK  map_id=0437  -> vector[165]\n",
      "17:08:16 | INFO | OK  map_id=0438  -> vector[165]\n",
      "17:08:17 | INFO | OK  map_id=0439  -> vector[165]\n",
      "17:08:19 | INFO | OK  map_id=0454  -> vector[165]\n",
      "17:08:20 | INFO | OK  map_id=0458  -> vector[165]\n",
      "17:08:21 | INFO | OK  map_id=0459  -> vector[165]\n",
      "17:08:23 | INFO | OK  map_id=0460  -> vector[165]\n",
      "17:08:24 | INFO | OK  map_id=0466  -> vector[165]\n",
      "17:08:25 | INFO | OK  map_id=0469  -> vector[165]\n",
      "17:08:27 | INFO | OK  map_id=0471  -> vector[165]\n",
      "17:08:29 | INFO | OK  map_id=0472  -> vector[165]\n",
      "17:08:32 | INFO | OK  map_id=0474  -> vector[165]\n",
      "17:08:33 | INFO | OK  map_id=0475  -> vector[165]\n",
      "17:08:35 | INFO | OK  map_id=0479  -> vector[165]\n",
      "17:08:36 | INFO | OK  map_id=0480  -> vector[165]\n",
      "17:08:37 | INFO | OK  map_id=0481  -> vector[165]\n",
      "17:08:37 | INFO | OK  map_id=0482  -> vector[165]\n",
      "17:08:38 | INFO | OK  map_id=0508  -> vector[165]\n",
      "17:08:39 | INFO | OK  map_id=0509  -> vector[165]\n",
      "17:08:41 | INFO | OK  map_id=0518  -> vector[165]\n",
      "17:08:47 | INFO | OK  map_id=0520  -> vector[165]\n",
      "17:08:48 | INFO | OK  map_id=0521  -> vector[165]\n",
      "17:08:50 | INFO | OK  map_id=0523  -> vector[165]\n",
      "17:08:52 | INFO | OK  map_id=0527  -> vector[165]\n",
      "17:08:53 | INFO | OK  map_id=0528  -> vector[165]\n",
      "17:08:54 | INFO | OK  map_id=0529  -> vector[165]\n",
      "17:08:56 | INFO | OK  map_id=0530  -> vector[165]\n",
      "17:08:56 | INFO | OK  map_id=0553  -> vector[165]\n",
      "17:08:57 | INFO | OK  map_id=0557  -> vector[165]\n",
      "17:08:58 | INFO | OK  map_id=0575  -> vector[165]\n",
      "17:08:59 | INFO | OK  map_id=0576  -> vector[165]\n",
      "17:09:01 | INFO | OK  map_id=0594  -> vector[165]\n",
      "17:09:02 | INFO | OK  map_id=0595  -> vector[165]\n",
      "17:09:03 | INFO | OK  map_id=0600  -> vector[165]\n",
      "17:09:05 | INFO | OK  map_id=0605  -> vector[165]\n",
      "17:09:06 | INFO | OK  map_id=0606  -> vector[165]\n",
      "17:09:07 | INFO | OK  map_id=0608  -> vector[165]\n",
      "17:09:09 | INFO | OK  map_id=0609  -> vector[165]\n",
      "17:09:10 | INFO | OK  map_id=0611  -> vector[165]\n",
      "17:09:12 | INFO | OK  map_id=0614  -> vector[165]\n",
      "17:09:13 | INFO | OK  map_id=0615  -> vector[165]\n",
      "17:09:14 | INFO | OK  map_id=0618  -> vector[165]\n",
      "17:09:15 | INFO | OK  map_id=0623  -> vector[165]\n",
      "17:09:16 | INFO | OK  map_id=0624  -> vector[165]\n",
      "17:09:17 | INFO | OK  map_id=0645  -> vector[165]\n",
      "17:09:18 | INFO | OK  map_id=0646  -> vector[165]\n",
      "17:09:19 | INFO | OK  map_id=0655  -> vector[165]\n",
      "17:09:20 | INFO | OK  map_id=0656  -> vector[165]\n",
      "17:09:21 | INFO | OK  map_id=0657  -> vector[165]\n",
      "17:09:22 | INFO | OK  map_id=0658  -> vector[165]\n",
      "17:09:24 | INFO | OK  map_id=0659  -> vector[165]\n",
      "17:09:25 | INFO | OK  map_id=0667  -> vector[165]\n",
      "17:09:26 | INFO | OK  map_id=0672  -> vector[165]\n",
      "17:09:27 | INFO | OK  map_id=0699  -> vector[165]\n",
      "17:09:29 | INFO | OK  map_id=0700  -> vector[165]\n",
      "17:09:30 | INFO | OK  map_id=0701  -> vector[165]\n",
      "17:09:32 | INFO | OK  map_id=0706  -> vector[165]\n",
      "17:09:33 | INFO | OK  map_id=0707  -> vector[165]\n",
      "17:09:34 | INFO | OK  map_id=0715  -> vector[165]\n",
      "17:09:35 | INFO | OK  map_id=0721  -> vector[165]\n",
      "17:09:36 | INFO | OK  map_id=0747  -> vector[165]\n",
      "17:09:38 | INFO | OK  map_id=0748  -> vector[165]\n",
      "17:09:39 | INFO | OK  map_id=0749  -> vector[165]\n",
      "17:09:40 | INFO | OK  map_id=0755  -> vector[165]\n",
      "17:09:41 | INFO | OK  map_id=0758  -> vector[165]\n",
      "17:09:42 | INFO | OK  map_id=0759  -> vector[165]\n",
      "17:09:43 | INFO | OK  map_id=0762  -> vector[165]\n",
      "17:09:44 | INFO | OK  map_id=0770  -> vector[165]\n",
      "17:09:46 | INFO | OK  map_id=0804  -> vector[165]\n",
      "17:09:47 | INFO | OK  map_id=0807  -> vector[165]\n",
      "17:09:48 | INFO | OK  map_id=0808  -> vector[165]\n",
      "17:09:50 | INFO | OK  map_id=0809  -> vector[165]\n",
      "17:09:52 | INFO | OK  map_id=0819  -> vector[165]\n",
      "17:09:53 | INFO | OK  map_id=0848  -> vector[165]\n",
      "17:09:55 | INFO | OK  map_id=0853  -> vector[165]\n",
      "17:09:57 | INFO | OK  map_id=0854  -> vector[165]\n",
      "17:09:58 | INFO | OK  map_id=0856  -> vector[165]\n",
      "17:09:59 | INFO | OK  map_id=0857  -> vector[165]\n",
      "17:10:05 | INFO | OK  map_id=0858  -> vector[165]\n",
      "17:10:06 | INFO | OK  map_id=0859  -> vector[165]\n",
      "17:10:07 | INFO | OK  map_id=0867  -> vector[165]\n",
      "17:10:11 | INFO | OK  map_id=0868  -> vector[165]\n",
      "17:10:11 | INFO | OK  map_id=0869  -> vector[165]\n",
      "17:10:12 | INFO | OK  map_id=0901  -> vector[165]\n",
      "17:10:14 | INFO | OK  map_id=0903  -> vector[165]\n",
      "17:10:15 | INFO | OK  map_id=0904  -> vector[165]\n",
      "17:10:16 | INFO | OK  map_id=0905  -> vector[165]\n",
      "17:10:22 | INFO | OK  map_id=0906  -> vector[165]\n",
      "17:10:23 | INFO | OK  map_id=0907  -> vector[165]\n",
      "17:10:25 | INFO | OK  map_id=0908  -> vector[165]\n",
      "17:10:28 | INFO | OK  map_id=0917  -> vector[165]\n",
      "17:10:29 | INFO | OK  map_id=0918  -> vector[165]\n",
      "17:10:32 | INFO | OK  map_id=0926  -> vector[165]\n",
      "17:10:33 | INFO | OK  map_id=0947  -> vector[165]\n",
      "17:10:35 | INFO | OK  map_id=0948  -> vector[165]\n",
      "17:10:38 | INFO | OK  map_id=0949  -> vector[165]\n",
      "17:10:39 | INFO | OK  map_id=0950  -> vector[165]\n",
      "17:10:40 | INFO | OK  map_id=0951  -> vector[165]\n",
      "17:10:41 | INFO | OK  map_id=0952  -> vector[165]\n",
      "17:10:43 | INFO | OK  map_id=0966  -> vector[165]\n",
      "17:10:46 | INFO | OK  map_id=0967  -> vector[165]\n",
      "17:10:47 | INFO | OK  map_id=0970  -> vector[165]\n",
      "17:10:48 | INFO | OK  map_id=0971  -> vector[165]\n",
      "17:10:50 | INFO | OK  map_id=0974  -> vector[165]\n",
      "17:10:51 | INFO | OK  map_id=0975  -> vector[165]\n",
      "17:10:52 | INFO | OK  map_id=0976  -> vector[165]\n",
      "17:10:53 | INFO | OK  map_id=0994  -> vector[165]\n",
      "17:10:55 | INFO | OK  map_id=0995  -> vector[165]\n",
      "17:10:56 | INFO | OK  map_id=0997  -> vector[165]\n",
      "17:10:58 | INFO | OK  map_id=0998  -> vector[165]\n",
      "17:11:00 | INFO | OK  map_id=1019  -> vector[165]\n",
      "17:11:03 | INFO | OK  map_id=1020  -> vector[165]\n",
      "17:11:05 | INFO | OK  map_id=1052  -> vector[165]\n",
      "17:11:07 | INFO | OK  map_id=1053  -> vector[165]\n",
      "17:11:08 | INFO | OK  map_id=1054  -> vector[165]\n",
      "17:11:09 | INFO | OK  map_id=1055  -> vector[165]\n",
      "17:11:11 | INFO | OK  map_id=1056  -> vector[165]\n",
      "17:11:12 | INFO | OK  map_id=1057  -> vector[165]\n",
      "17:11:14 | INFO | OK  map_id=1069  -> vector[165]\n",
      "17:11:15 | INFO | OK  map_id=1070  -> vector[165]\n",
      "17:11:17 | INFO | OK  map_id=1090  -> vector[165]\n",
      "17:11:18 | INFO | OK  map_id=1091  -> vector[165]\n",
      "17:11:19 | INFO | OK  map_id=1092  -> vector[165]\n",
      "17:11:20 | INFO | OK  map_id=1100  -> vector[165]\n",
      "17:11:21 | INFO | OK  map_id=1103  -> vector[165]\n",
      "17:11:22 | INFO | OK  map_id=1105  -> vector[165]\n",
      "17:11:24 | INFO | OK  map_id=1106  -> vector[165]\n",
      "17:11:25 | INFO | OK  map_id=1118  -> vector[165]\n",
      "17:11:27 | INFO | OK  map_id=1119  -> vector[165]\n",
      "17:11:29 | INFO | OK  map_id=1120  -> vector[165]\n",
      "17:11:31 | INFO | OK  map_id=1139  -> vector[165]\n",
      "17:11:33 | INFO | OK  map_id=1140  -> vector[165]\n",
      "17:11:33 | INFO | OK  map_id=1148  -> vector[165]\n",
      "17:11:34 | INFO | OK  map_id=1155  -> vector[165]\n",
      "17:11:36 | INFO | OK  map_id=1157  -> vector[165]\n",
      "17:11:38 | INFO | OK  map_id=1168  -> vector[165]\n",
      "17:11:40 | INFO | OK  map_id=1169  -> vector[165]\n",
      "17:11:42 | INFO | OK  map_id=1170  -> vector[165]\n",
      "17:11:43 | INFO | OK  map_id=1197  -> vector[165]\n",
      "17:11:45 | INFO | OK  map_id=1198  -> vector[165]\n",
      "17:11:46 | INFO | OK  map_id=1202  -> vector[165]\n",
      "17:11:49 | INFO | OK  map_id=1203  -> vector[165]\n",
      "17:11:51 | INFO | OK  map_id=1204  -> vector[165]\n",
      "17:11:52 | INFO | OK  map_id=1217  -> vector[165]\n",
      "17:11:54 | INFO | OK  map_id=1218  -> vector[165]\n",
      "17:11:55 | INFO | OK  map_id=1219  -> vector[165]\n",
      "17:11:56 | INFO | OK  map_id=1221  -> vector[165]\n",
      "17:11:58 | INFO | OK  map_id=1222  -> vector[165]\n",
      "17:11:58 | INFO | OK  map_id=1231  -> vector[165]\n",
      "17:12:00 | INFO | OK  map_id=1233  -> vector[165]\n",
      "17:12:01 | INFO | OK  map_id=1234  -> vector[165]\n",
      "17:12:03 | INFO | OK  map_id=1261  -> vector[165]\n",
      "17:12:04 | INFO | OK  map_id=1269  -> vector[165]\n",
      "17:12:08 | INFO | OK  map_id=1270  -> vector[165]\n",
      "17:12:09 | INFO | OK  map_id=1271  -> vector[165]\n",
      "17:12:10 | INFO | OK  map_id=1276  -> vector[165]\n",
      "17:12:12 | INFO | OK  map_id=1277  -> vector[165]\n",
      "17:12:13 | INFO | OK  map_id=1283  -> vector[165]\n",
      "17:12:14 | INFO | OK  map_id=1284  -> vector[165]\n",
      "17:12:15 | INFO | OK  map_id=1285  -> vector[165]\n",
      "17:12:17 | INFO | OK  map_id=1295  -> vector[165]\n",
      "17:12:20 | INFO | OK  map_id=1296  -> vector[165]\n",
      "17:12:21 | INFO | OK  map_id=1297  -> vector[165]\n",
      "17:12:22 | INFO | OK  map_id=1303  -> vector[165]\n",
      "17:12:24 | INFO | OK  map_id=1304  -> vector[165]\n",
      "17:12:25 | INFO | OK  map_id=1310  -> vector[165]\n",
      "17:12:28 | INFO | OK  map_id=1319  -> vector[165]\n",
      "17:12:29 | INFO | OK  map_id=1333  -> vector[165]\n",
      "17:12:30 | INFO | OK  map_id=1334  -> vector[165]\n",
      "17:12:33 | INFO | OK  map_id=1344  -> vector[165]\n",
      "17:12:33 | INFO | OK  map_id=1349  -> vector[165]\n",
      "17:12:35 | INFO | OK  map_id=1364  -> vector[165]\n",
      "17:12:38 | INFO | OK  map_id=1365  -> vector[165]\n",
      "17:12:41 | INFO | OK  map_id=1366  -> vector[165]\n",
      "17:12:45 | INFO | OK  map_id=1367  -> vector[165]\n",
      "17:12:46 | INFO | OK  map_id=1368  -> vector[165]\n",
      "17:12:47 | INFO | OK  map_id=1369  -> vector[165]\n",
      "17:12:48 | INFO | OK  map_id=1377  -> vector[165]\n",
      "17:12:49 | INFO | OK  map_id=1378  -> vector[165]\n",
      "17:12:50 | INFO | OK  map_id=1385  -> vector[165]\n",
      "17:12:52 | INFO | OK  map_id=1386  -> vector[165]\n",
      "17:12:53 | INFO | OK  map_id=1399  -> vector[165]\n",
      "17:12:54 | INFO | OK  map_id=1401  -> vector[165]\n",
      "17:12:55 | INFO | OK  map_id=1408  -> vector[165]\n",
      "17:12:58 | INFO | OK  map_id=1409  -> vector[165]\n",
      "17:13:01 | INFO | OK  map_id=1410  -> vector[165]\n",
      "17:13:02 | INFO | OK  map_id=1413  -> vector[165]\n",
      "17:13:04 | INFO | OK  map_id=1414  -> vector[165]\n",
      "17:13:06 | INFO | OK  map_id=1415  -> vector[165]\n",
      "17:13:08 | INFO | OK  map_id=1416  -> vector[165]\n",
      "17:13:09 | INFO | OK  map_id=1417  -> vector[165]\n",
      "17:13:11 | INFO | OK  map_id=1418  -> vector[165]\n",
      "17:13:12 | INFO | OK  map_id=1434  -> vector[165]\n",
      "17:13:13 | INFO | OK  map_id=1438  -> vector[165]\n",
      "17:13:15 | INFO | OK  map_id=1439  -> vector[165]\n",
      "17:13:16 | INFO | OK  map_id=1450  -> vector[165]\n",
      "17:13:18 | INFO | OK  map_id=1451  -> vector[165]\n",
      "17:13:21 | INFO | OK  map_id=1458  -> vector[165]\n",
      "17:13:22 | INFO | OK  map_id=1459  -> vector[165]\n",
      "17:13:24 | INFO | OK  map_id=1460  -> vector[165]\n",
      "17:13:25 | INFO | OK  map_id=1465  -> vector[165]\n",
      "17:13:27 | INFO | OK  map_id=1466  -> vector[165]\n",
      "17:13:29 | INFO | OK  map_id=1467  -> vector[165]\n",
      "17:13:32 | INFO | OK  map_id=1473  -> vector[165]\n",
      "17:13:32 | INFO | OK  map_id=1474  -> vector[165]\n",
      "17:13:33 | INFO | OK  map_id=1476  -> vector[165]\n",
      "17:13:35 | INFO | OK  map_id=1479  -> vector[165]\n",
      "17:13:36 | INFO | OK  map_id=1486  -> vector[165]\n",
      "17:13:38 | INFO | OK  map_id=1487  -> vector[165]\n",
      "17:13:39 | INFO | OK  map_id=1496  -> vector[165]\n",
      "17:13:41 | INFO | OK  map_id=1500  -> vector[165]\n",
      "17:13:42 | INFO | OK  map_id=1501  -> vector[165]\n",
      "17:13:44 | INFO | OK  map_id=1507  -> vector[165]\n",
      "17:13:45 | INFO | OK  map_id=1508  -> vector[165]\n",
      "17:13:47 | INFO | OK  map_id=1509  -> vector[165]\n",
      "17:13:49 | INFO | OK  map_id=1514  -> vector[165]\n",
      "17:13:51 | INFO | OK  map_id=1515  -> vector[165]\n",
      "17:13:51 | INFO | OK  map_id=1557  -> vector[165]\n",
      "17:13:53 | INFO | OK  map_id=1563  -> vector[165]\n",
      "17:13:55 | INFO | OK  map_id=1564  -> vector[165]\n",
      "17:13:57 | INFO | OK  map_id=1565  -> vector[165]\n",
      "17:13:58 | INFO | OK  map_id=1570  -> vector[165]\n",
      "17:13:59 | INFO | OK  map_id=1579  -> vector[165]\n",
      "17:14:00 | INFO | OK  map_id=1580  -> vector[165]\n",
      "17:14:01 | INFO | OK  map_id=1583  -> vector[165]\n",
      "17:14:02 | INFO | OK  map_id=1584  -> vector[165]\n",
      "17:14:03 | INFO | OK  map_id=1598  -> vector[165]\n",
      "17:14:05 | INFO | OK  map_id=1613  -> vector[165]\n",
      "17:14:06 | INFO | OK  map_id=1614  -> vector[165]\n",
      "17:14:07 | INFO | OK  map_id=1618  -> vector[165]\n",
      "17:14:08 | INFO | OK  map_id=1619  -> vector[165]\n",
      "17:14:09 | INFO | OK  map_id=1629  -> vector[165]\n",
      "17:14:12 | INFO | OK  map_id=1630  -> vector[165]\n",
      "17:14:13 | INFO | OK  map_id=1631  -> vector[165]\n",
      "17:14:14 | INFO | OK  map_id=1647  -> vector[165]\n",
      "17:14:15 | INFO | OK  map_id=1649  -> vector[165]\n",
      "17:14:16 | INFO | OK  map_id=1650  -> vector[165]\n",
      "17:14:17 | INFO | OK  map_id=1653  -> vector[165]\n",
      "17:14:18 | INFO | OK  map_id=1666  -> vector[165]\n",
      "17:14:19 | INFO | OK  map_id=1667  -> vector[165]\n",
      "17:14:22 | INFO | OK  map_id=1672  -> vector[165]\n",
      "17:14:23 | INFO | OK  map_id=1673  -> vector[165]\n",
      "17:14:24 | INFO | OK  map_id=1679  -> vector[165]\n",
      "17:14:25 | INFO | OK  map_id=1691  -> vector[165]\n",
      "17:14:27 | INFO | OK  map_id=1696  -> vector[165]\n",
      "17:14:30 | INFO | OK  map_id=1700  -> vector[165]\n",
      "17:14:32 | INFO | OK  map_id=1702  -> vector[165]\n",
      "17:14:35 | INFO | OK  map_id=1703  -> vector[165]\n",
      "17:14:36 | INFO | OK  map_id=1709  -> vector[165]\n",
      "17:14:37 | INFO | OK  map_id=1710  -> vector[165]\n",
      "17:14:39 | INFO | OK  map_id=1748  -> vector[165]\n",
      "17:14:41 | INFO | OK  map_id=1749  -> vector[165]\n",
      "17:14:43 | INFO | OK  map_id=1750  -> vector[165]\n",
      "17:14:44 | INFO | OK  map_id=1751  -> vector[165]\n",
      "17:14:45 | INFO | OK  map_id=1752  -> vector[165]\n",
      "17:14:46 | INFO | OK  map_id=1755  -> vector[165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Map embeddings completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:14:47 | INFO | OK  map_id=1757  -> vector[165]\n",
      "17:14:47 | INFO | Saved 300 vectors (failed=0) to /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out\n"
     ]
    }
   ],
   "source": [
    "# === MAP EMBEDDINGS ===\n",
    "cmd = [\n",
    "    sys.executable, \"-m\", \"src.mapvec.maps.map_embeddings\",\n",
    "    \"--root\", str(PATHS.MAPS_ROOT),\n",
    "    \"--pattern\", PATHS.INPUT_MAPS_PATTERN,\n",
    "    \"--out_dir\", str(PATHS.MAP_OUT),\n",
    "    \"--norm\", \"fixed\",\n",
    "    \"--norm-wh\", \"400x400\",\n",
    "    \"-v\",\n",
    "]\n",
    "print(\"CMD:\", \" \".join(cmd))\n",
    "res = subprocess.run(cmd, cwd=str(PATHS.PROJ_ROOT))\n",
    "if res.returncode != 0:\n",
    "    raise SystemExit(\"Map embedding step failed.\")\n",
    "print(\"‚úÖ Map embeddings completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd186319e89f445",
   "metadata": {},
   "source": [
    "## üîó 3) Concatenate (pairs ‚Üí fused rows) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa2b07a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMD: /opt/anaconda3/envs/thesis/bin/python -m src.mapvec.concat.concat_embeddings --pairs /Users/amirdonyadide/Documents/GitHub/Thesis/data/input/pairs.csv --map_npz /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out/maps_embeddings.npz --prompt_npz /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/prompts_embeddings.npz --out_dir /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out --drop_dupes\n",
      "‚úÖ Concatenation completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:15:10 | INFO | Map  embeddings: (300, 165) from /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/map_out/maps_embeddings.npz\n",
      "17:15:10 | INFO | Prompt embeddings: (500, 512) from /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/prompt_out/prompts_embeddings.npz\n",
      "17:15:10 | INFO | X shape = (450, 677)  (map_dim=165, prompt_dim=512)\n",
      "17:15:10 | INFO | Saved to /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out in 0.02s\n"
     ]
    }
   ],
   "source": [
    "# === CONCATENATION ===\n",
    "cmd = [\n",
    "    sys.executable, \"-m\", \"src.mapvec.concat.concat_embeddings\",\n",
    "    \"--pairs\",      str(PATHS.PAIRS_CSV),\n",
    "    \"--map_npz\",    str(PATHS.MAP_OUT / \"maps_embeddings.npz\"),\n",
    "    \"--prompt_npz\", str(PATHS.PROMPT_OUT / \"prompts_embeddings.npz\"),\n",
    "    \"--out_dir\",    str(PATHS.TRAIN_OUT),\n",
    "    \"--drop_dupes\",\n",
    "    # \"--l2-prompt\",     # safety net if you want L2 here as well\n",
    "    # \"--fail_on_missing\"\n",
    "    # \"--save-blocks\"\n",
    "]\n",
    "print(\"CMD:\", \" \".join(cmd))\n",
    "res = subprocess.run(cmd, cwd=str(PATHS.PROJ_ROOT))\n",
    "if res.returncode != 0:\n",
    "    raise SystemExit(\"Concatenation step failed.\")\n",
    "print(\"‚úÖ Concatenation completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142d4b68c273d37",
   "metadata": {},
   "source": [
    "## üì• 4) Load & Basic Cleaning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a494fd27dfe7681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X: (450, 677), pairs: (450, 4)\n",
      "After cleaning: X=(450, 677), df=(450, 4), ops=['aggregate', 'displace', 'select', 'simplify']\n"
     ]
    }
   ],
   "source": [
    "# === LOAD FUSED DATA ===\n",
    "X = np.load(PATHS.TRAIN_OUT / \"X_concat.npy\")\n",
    "pairs_df = pd.read_parquet(PATHS.TRAIN_OUT / \"train_pairs.parquet\")\n",
    "print(f\"Loaded X: {X.shape}, pairs: {pairs_df.shape}\")\n",
    "\n",
    "OP_COL = \"operator\"\n",
    "PARAM_COLS = [\"param\"]\n",
    "\n",
    "df = pairs_df.copy()\n",
    "df[OP_COL] = df[OP_COL].astype(str).str.strip().str.lower()\n",
    "\n",
    "mask = df[OP_COL].notna()\n",
    "for c in PARAM_COLS:\n",
    "    mask &= df[c].notna()\n",
    "\n",
    "X  = X[mask.values].astype(\"float64\", copy=False)\n",
    "df = df.loc[mask].reset_index(drop=True)\n",
    "print(f\"After cleaning: X={X.shape}, df={df.shape}, ops={sorted(df[OP_COL].unique())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b997cab7",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è 5) Split & Targets ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3bc0897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (315, 677), Val: (67, 677), Test: (68, 677)\n"
     ]
    }
   ],
   "source": [
    "# === SPLIT ===\n",
    "FIXED_CLASSES = [\"simplify\", \"select\", \"aggregate\", \"displace\"]\n",
    "\n",
    "X_train, X_temp, df_train, df_temp = train_test_split(\n",
    "    X, df,\n",
    "    test_size=CFG.VAL_RATIO + CFG.TEST_RATIO,\n",
    "    random_state=CFG.SEED,\n",
    "    shuffle=True,\n",
    "    stratify=df[OP_COL] if df[OP_COL].nunique() > 1 else None\n",
    ")\n",
    "rel_test = CFG.TEST_RATIO / (CFG.VAL_RATIO + CFG.TEST_RATIO)\n",
    "X_val, X_test, df_val, df_test = train_test_split(\n",
    "    X_temp, df_temp,\n",
    "    test_size=rel_test,\n",
    "    random_state=CFG.SEED,\n",
    "    shuffle=True,\n",
    "    stratify=df_temp[OP_COL] if df_temp[OP_COL].nunique() > 1 else None\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# === TARGETS ===\n",
    "le = LabelEncoder().fit(FIXED_CLASSES)\n",
    "y_train_cls = le.transform(df_train[OP_COL])\n",
    "y_val_cls   = le.transform(df_val[OP_COL])\n",
    "y_test_cls  = le.transform(df_test[OP_COL])\n",
    "\n",
    "y_train_reg = df_train[PARAM_COLS].to_numpy(dtype=\"float64\")\n",
    "y_val_reg   = df_val[PARAM_COLS].to_numpy(dtype=\"float64\")\n",
    "y_test_reg  = df_test[PARAM_COLS].to_numpy(dtype=\"float64\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d187473d",
   "metadata": {},
   "source": [
    "## üßº 6) Modality-Aware Preprocessing (map only) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41942b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modality-aware preprocessing complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out/preproc.joblib']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === MODALITY-AWARE PREPROCESSING ===\n",
    "MAP_DIM     = CFG.MAP_DIM or 165       # set to true map dim\n",
    "PROMPT_DIM  = CFG.PROMPT_DIM or 512\n",
    "\n",
    "def split_blocks(X):\n",
    "    X_map    = X[:, :MAP_DIM].astype(np.float64, copy=True)\n",
    "    X_prompt = X[:, MAP_DIM:MAP_DIM+PROMPT_DIM].astype(np.float64, copy=True)\n",
    "    return X_map, X_prompt\n",
    "\n",
    "def l2_normalize_rows(A, eps=1e-12):\n",
    "    nrm = np.sqrt((A * A).sum(axis=1, keepdims=True))\n",
    "    return A / np.maximum(nrm, eps)\n",
    "\n",
    "# split\n",
    "Xm_tr, Xp_tr = split_blocks(X_train)\n",
    "Xm_va, Xp_va = split_blocks(X_val)\n",
    "Xm_te, Xp_te = split_blocks(X_test)\n",
    "\n",
    "# prompts: L2 only\n",
    "Xp_tr = l2_normalize_rows(Xp_tr)\n",
    "Xp_va = l2_normalize_rows(Xp_va)\n",
    "Xp_te = l2_normalize_rows(Xp_te)\n",
    "\n",
    "# maps: inf‚ÜíNaN\n",
    "for A in (Xm_tr, Xm_va, Xm_te):\n",
    "    A[~np.isfinite(A)] = np.nan\n",
    "\n",
    "# impute (train)\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "Xm_tr_imp = imp.fit_transform(Xm_tr)\n",
    "Xm_va_imp = imp.transform(Xm_va)\n",
    "Xm_te_imp = imp.transform(Xm_te)\n",
    "\n",
    "# clip (5‚Äì95%) train thresholds\n",
    "q_lo = np.nanpercentile(Xm_tr_imp, 5, axis=0)\n",
    "q_hi = np.nanpercentile(Xm_tr_imp, 95, axis=0)\n",
    "def clip_to_q(A, lo, hi): return np.clip(A, lo, hi)\n",
    "\n",
    "Xm_tr_imp = clip_to_q(Xm_tr_imp, q_lo, q_hi)\n",
    "Xm_va_imp = clip_to_q(Xm_va_imp, q_lo, q_hi)\n",
    "Xm_te_imp = clip_to_q(Xm_te_imp, q_lo, q_hi)\n",
    "\n",
    "# drop zero-variance cols on train\n",
    "stds = np.nanstd(Xm_tr_imp, axis=0)\n",
    "keep_mask = stds > 1e-12\n",
    "\n",
    "# scale kept columns (train fit)\n",
    "scaler = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5, 95))\n",
    "Xm_tr_kept = scaler.fit_transform(Xm_tr_imp[:, keep_mask])\n",
    "Xm_va_kept = scaler.transform(Xm_va_imp[:, keep_mask])\n",
    "Xm_te_kept = scaler.transform(Xm_te_imp[:, keep_mask])\n",
    "\n",
    "# rebuild full map dim (dropped cols = 0)\n",
    "Xm_tr_s = np.zeros_like(Xm_tr_imp, dtype=np.float64)\n",
    "Xm_va_s = np.zeros_like(Xm_va_imp, dtype=np.float64)\n",
    "Xm_te_s = np.zeros_like(Xm_te_imp, dtype=np.float64)\n",
    "Xm_tr_s[:, keep_mask] = Xm_tr_kept.astype(np.float64)\n",
    "Xm_va_s[:, keep_mask] = Xm_va_kept.astype(np.float64)\n",
    "Xm_te_s[:, keep_mask] = Xm_te_kept.astype(np.float64)\n",
    "\n",
    "# fuse back\n",
    "X_train_s = np.concatenate([Xm_tr_s, Xp_tr], axis=1).astype(np.float64)\n",
    "X_val_s   = np.concatenate([Xm_va_s, Xp_va], axis=1).astype(np.float64)\n",
    "X_test_s  = np.concatenate([Xm_te_s, Xp_te], axis=1).astype(np.float64)\n",
    "\n",
    "assert np.isfinite(X_train_s).all() and np.isfinite(X_val_s).all() and np.isfinite(X_test_s).all(), \"Non-finite after preprocessing.\"\n",
    "print(\"‚úÖ Modality-aware preprocessing complete.\")\n",
    "\n",
    "# save preprocessing bundle\n",
    "joblib.dump({\n",
    "    \"imp\": imp, \"q_lo\": q_lo, \"q_hi\": q_hi,\n",
    "    \"keep_mask\": keep_mask, \"scaler\": scaler,\n",
    "    \"map_dim\": MAP_DIM, \"prompt_dim\": PROMPT_DIM\n",
    "}, PATHS.TRAIN_OUT / \"preproc.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c32c2",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è 7) Class Weights ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0df2b2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {np.str_('aggregate'): np.float64(0.9264705882352942), np.str_('displace'): np.float64(1.0361842105263157), np.str_('select'): np.float64(0.984375), np.str_('simplify'): np.float64(1.0641891891891893)}\n"
     ]
    }
   ],
   "source": [
    "classes  = list(le.classes_)\n",
    "n_classes = len(classes)\n",
    "cls_w    = compute_class_weight(class_weight=\"balanced\",\n",
    "                                classes=np.arange(n_classes),\n",
    "                                y=y_train_cls)\n",
    "sample_w = np.array([cls_w[c] for c in y_train_cls], dtype=\"float64\")\n",
    "print(\"Class weights:\", dict(zip(classes, cls_w)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988f274",
   "metadata": {},
   "source": [
    "## üß† 8) Train MLP ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95133825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.41214983\n",
      "Validation score: 0.241153\n",
      "Iteration 2, loss = 1.36736985\n",
      "Validation score: 0.339898\n",
      "Iteration 3, loss = 1.33796033\n",
      "Validation score: 0.400060\n",
      "Iteration 4, loss = 1.31140983\n",
      "Validation score: 0.342056\n",
      "Iteration 5, loss = 1.28854323\n",
      "Validation score: 0.323970\n",
      "Iteration 6, loss = 1.26417428\n",
      "Validation score: 0.323843\n",
      "Iteration 7, loss = 1.24033505\n",
      "Validation score: 0.326127\n",
      "Iteration 8, loss = 1.21717250\n",
      "Validation score: 0.327333\n",
      "Iteration 9, loss = 1.19265797\n",
      "Validation score: 0.328412\n",
      "Iteration 10, loss = 1.16645913\n",
      "Validation score: 0.348910\n",
      "Iteration 11, loss = 1.14003958\n",
      "Validation score: 0.390362\n",
      "Iteration 12, loss = 1.11029039\n",
      "Validation score: 0.394396\n",
      "Iteration 13, loss = 1.08064897\n",
      "Validation score: 0.481870\n",
      "Iteration 14, loss = 1.04801767\n",
      "Validation score: 0.479585\n",
      "Iteration 15, loss = 1.01718578\n",
      "Validation score: 0.456219\n",
      "Iteration 16, loss = 0.98559875\n",
      "Validation score: 0.476717\n",
      "Iteration 17, loss = 0.95087554\n",
      "Validation score: 0.476717\n",
      "Iteration 18, loss = 0.91579947\n",
      "Validation score: 0.498294\n",
      "Iteration 19, loss = 0.88004431\n",
      "Validation score: 0.456219\n",
      "Iteration 20, loss = 0.84372663\n",
      "Validation score: 0.435721\n",
      "Iteration 21, loss = 0.80633411\n",
      "Validation score: 0.456219\n",
      "Iteration 22, loss = 0.77154084\n",
      "Validation score: 0.475639\n",
      "Iteration 23, loss = 0.73452873\n",
      "Validation score: 0.456803\n",
      "Iteration 24, loss = 0.69514064\n",
      "Validation score: 0.500539\n",
      "Iteration 25, loss = 0.66143607\n",
      "Validation score: 0.498877\n",
      "Iteration 26, loss = 0.62456697\n",
      "Validation score: 0.497799\n",
      "Iteration 27, loss = 0.58820254\n",
      "Validation score: 0.498877\n",
      "Iteration 28, loss = 0.55320215\n",
      "Validation score: 0.498877\n",
      "Iteration 29, loss = 0.52055916\n",
      "Validation score: 0.497799\n",
      "Iteration 30, loss = 0.48844303\n",
      "Validation score: 0.498877\n",
      "Iteration 31, loss = 0.45757379\n",
      "Validation score: 0.498877\n",
      "Iteration 32, loss = 0.42824943\n",
      "Validation score: 0.498877\n",
      "Iteration 33, loss = 0.39758394\n",
      "Validation score: 0.521037\n",
      "Iteration 34, loss = 0.37195033\n",
      "Validation score: 0.518170\n",
      "Iteration 35, loss = 0.34818157\n",
      "Validation score: 0.498877\n",
      "Iteration 36, loss = 0.32216850\n",
      "Validation score: 0.565357\n",
      "Iteration 37, loss = 0.30003714\n",
      "Validation score: 0.565357\n",
      "Iteration 38, loss = 0.27762818\n",
      "Validation score: 0.565357\n",
      "Iteration 39, loss = 0.25839856\n",
      "Validation score: 0.565357\n",
      "Iteration 40, loss = 0.23977177\n",
      "Validation score: 0.587517\n",
      "Iteration 41, loss = 0.22240310\n",
      "Validation score: 0.562490\n",
      "Iteration 42, loss = 0.20687017\n",
      "Validation score: 0.606810\n",
      "Iteration 43, loss = 0.19049754\n",
      "Validation score: 0.584650\n",
      "Iteration 44, loss = 0.17668590\n",
      "Validation score: 0.584650\n",
      "Iteration 45, loss = 0.16437589\n",
      "Validation score: 0.584650\n",
      "Iteration 46, loss = 0.15232939\n",
      "Validation score: 0.584650\n",
      "Iteration 47, loss = 0.14174703\n",
      "Validation score: 0.587517\n",
      "Iteration 48, loss = 0.13281863\n",
      "Validation score: 0.584650\n",
      "Iteration 49, loss = 0.12339735\n",
      "Validation score: 0.606810\n",
      "Iteration 50, loss = 0.11479958\n",
      "Validation score: 0.606226\n",
      "Iteration 51, loss = 0.10724787\n",
      "Validation score: 0.606810\n",
      "Iteration 52, loss = 0.10026818\n",
      "Validation score: 0.603942\n",
      "Iteration 53, loss = 0.09383222\n",
      "Validation score: 0.606810\n",
      "Iteration 54, loss = 0.08812819\n",
      "Validation score: 0.586934\n",
      "Iteration 55, loss = 0.08309714\n",
      "Validation score: 0.584650\n",
      "Iteration 56, loss = 0.07802997\n",
      "Validation score: 0.584650\n",
      "Iteration 57, loss = 0.07368492\n",
      "Validation score: 0.603942\n",
      "Iteration 58, loss = 0.06926827\n",
      "Validation score: 0.603942\n",
      "Validation score did not improve more than tol=0.000100 for 15 consecutive epochs. Stopping.\n",
      "‚úÖ Training done.\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-3,\n",
    "    learning_rate_init=3e-4,\n",
    "    batch_size=32,\n",
    "    max_iter=300,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=15,\n",
    "    validation_fraction=0.15,\n",
    "    tol=1e-4,\n",
    "    random_state=CFG.SEED,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "try:\n",
    "    clf.fit(X_train_s, y_train_cls, sample_weight=sample_w)\n",
    "    print(\"‚úÖ Training done.\")\n",
    "except Exception as e:\n",
    "    raise SystemExit(f\"Training failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b52314",
   "metadata": {},
   "source": [
    "## üìä 9) Evaluate ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be650001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Validation =====\n",
      "\n",
      "VAL:  acc=0.6716  f1_macro=0.6625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   aggregate      0.786     0.611     0.688        18\n",
      "    displace      0.684     0.812     0.743        16\n",
      "      select      0.583     0.412     0.483        17\n",
      "    simplify      0.636     0.875     0.737        16\n",
      "\n",
      "    accuracy                          0.672        67\n",
      "   macro avg      0.672     0.678     0.662        67\n",
      "weighted avg      0.674     0.672     0.661        67\n",
      "\n",
      "\n",
      "===== Test =====\n",
      "\n",
      "TEST:  acc=0.5735  f1_macro=0.5552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   aggregate      0.471     0.444     0.457        18\n",
      "    displace      0.647     0.647     0.647        17\n",
      "      select      0.577     0.833     0.682        18\n",
      "    simplify      0.625     0.333     0.435        15\n",
      "\n",
      "    accuracy                          0.574        68\n",
      "   macro avg      0.580     0.565     0.555        68\n",
      "weighted avg      0.577     0.574     0.559        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_split(name, Xs, ys_true):\n",
    "    y_pred = clf.predict(Xs)\n",
    "    acc = accuracy_score(ys_true, y_pred)\n",
    "    f1m = f1_score(ys_true, y_pred, average=\"macro\")\n",
    "    print(f\"\\n{name}:  acc={acc:.4f}  f1_macro={f1m:.4f}\")\n",
    "    print(classification_report(ys_true, y_pred, target_names=classes, digits=3))\n",
    "    return y_pred\n",
    "\n",
    "print(\"\\n===== Validation =====\")\n",
    "_ = eval_split(\"VAL\", X_val_s, y_val_cls)\n",
    "\n",
    "print(\"\\n===== Test =====\")\n",
    "y_test_pred = eval_split(\"TEST\", X_test_s, y_test_cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff8286",
   "metadata": {},
   "source": [
    "## üîç 10) Sanity Checks ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "490ab6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- X_train_s ---\n",
      "shape: (315, 677) dtype: float64\n",
      "finite: True\n",
      "min/max: -1.0247816551742788 1.018822814058339\n",
      "mean/std: 0.004054013863573004 0.1420087591435738\n",
      "all-NaN cols: 0 zero-variance cols: 14\n",
      "\n",
      "--- X_val_s ---\n",
      "shape: (67, 677) dtype: float64\n",
      "finite: True\n",
      "min/max: -1.0247816551742788 1.018822814058339\n",
      "mean/std: 0.006080322384638744 0.13857571119504025\n",
      "all-NaN cols: 0 zero-variance cols: 14\n",
      "\n",
      "--- X_test_s ---\n",
      "shape: (68, 677) dtype: float64\n",
      "finite: True\n",
      "min/max: -1.0247816551742788 1.018822814058339\n",
      "mean/std: 0.005311595909093617 0.1433861362674472\n",
      "all-NaN cols: 0 zero-variance cols: 14\n",
      "classes present in train: ['aggregate', 'displace', 'select', 'simplify']\n"
     ]
    }
   ],
   "source": [
    "def check_matrix(name, X):\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(\"shape:\", X.shape, \"dtype:\", X.dtype)\n",
    "    print(\"finite:\", np.isfinite(X).all())\n",
    "    print(\"min/max:\", np.nanmin(X), np.nanmax(X))\n",
    "    print(\"mean/std:\", np.nanmean(X), np.nanstd(X))\n",
    "    col_nan = np.isnan(X).all(axis=0).sum()\n",
    "    col_zero_var = (np.nanstd(X, axis=0) == 0).sum()\n",
    "    print(\"all-NaN cols:\", col_nan, \"zero-variance cols:\", col_zero_var)\n",
    "\n",
    "check_matrix(\"X_train_s\", X_train_s)\n",
    "check_matrix(\"X_val_s\",   X_val_s)\n",
    "check_matrix(\"X_test_s\",  X_test_s)\n",
    "print(\"classes present in train:\", sorted(set(df_train[OP_COL])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1075c4",
   "metadata": {},
   "source": [
    "## üíæ 11) Save Artifacts ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ee1eb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved model + label encoder to: /Users/amirdonyadide/Documents/GitHub/Thesis/data/output/train_out\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(clf, PATHS.TRAIN_OUT / \"mlp_classifier.joblib\")\n",
    "joblib.dump(le,  PATHS.TRAIN_OUT / \"label_encoder.joblib\")\n",
    "print(\"‚úÖ Saved model + label encoder to:\", PATHS.TRAIN_OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128cea6d",
   "metadata": {},
   "source": [
    "## üöÄ 12) Inference Helper ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7811fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline ready. Use apply_preproc_and_predict(...) for inference.\n"
     ]
    }
   ],
   "source": [
    "def apply_preproc_and_predict(X_concat: np.ndarray,\n",
    "                              preproc_path=PATHS.TRAIN_OUT / \"preproc.joblib\",\n",
    "                              model_path=PATHS.TRAIN_OUT / \"mlp_classifier.joblib\",\n",
    "                              le_path=PATHS.TRAIN_OUT / \"label_encoder.joblib\"):\n",
    "    \"\"\"\n",
    "    X_concat: (N, MAP_DIM + PROMPT_DIM). Prompts can be raw; they will be L2 here.\n",
    "    Returns: (labels_str, labels_idx)\n",
    "    \"\"\"\n",
    "    bundle = joblib.load(preproc_path)\n",
    "    imp, q_lo, q_hi = bundle[\"imp\"], bundle[\"q_lo\"], bundle[\"q_hi\"]\n",
    "    keep_mask, scaler = bundle[\"keep_mask\"], bundle[\"scaler\"]\n",
    "    map_dim, prompt_dim = bundle[\"map_dim\"], bundle[\"prompt_dim\"]\n",
    "\n",
    "    def l2_rows(A, eps=1e-12):\n",
    "        n = np.sqrt((A * A).sum(axis=1, keepdims=True))\n",
    "        return A / np.maximum(n, eps)\n",
    "\n",
    "    X_map    = X_concat[:, :map_dim].astype(np.float64, copy=True)\n",
    "    X_prompt = X_concat[:, map_dim:map_dim+prompt_dim].astype(np.float64, copy=True)\n",
    "    X_prompt = l2_rows(X_prompt)\n",
    "\n",
    "    X_map[~np.isfinite(X_map)] = np.nan\n",
    "    X_map_imp = imp.transform(X_map)\n",
    "    X_map_imp = np.clip(X_map_imp, q_lo, q_hi)\n",
    "\n",
    "    X_map_std = np.zeros_like(X_map_imp, dtype=np.float64)\n",
    "    X_map_std[:, keep_mask] = scaler.transform(X_map_imp[:, keep_mask]).astype(np.float64)\n",
    "\n",
    "    X_s = np.concatenate([X_map_std, X_prompt], axis=1).astype(np.float64)\n",
    "\n",
    "    clf_ = joblib.load(model_path)\n",
    "    le_  = joblib.load(le_path)\n",
    "    y_pred_idx = clf_.predict(X_s)\n",
    "    y_pred_lbl = le_.inverse_transform(y_pred_idx)\n",
    "    return y_pred_lbl, y_pred_idx\n",
    "\n",
    "print(\"‚úÖ Pipeline ready. Use apply_preproc_and_predict(...) for inference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7905b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
