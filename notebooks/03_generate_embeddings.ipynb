{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c593621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Repo root: /Users/amirdonyadide/Documents/GitHub/IMGOFUP\n",
      "ðŸ“¦ Using src from: /Users/amirdonyadide/Documents/GitHub/IMGOFUP/src\n",
      "ðŸ”§ PROJ_ROOT env set to: /Users/amirdonyadide/Documents/GitHub/IMGOFUP\n"
     ]
    }
   ],
   "source": [
    "# ===================== 01_generate_embeddings â€” CELL 0: Bootstrap =====================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find repo root (folder that contains \"src/imgofup\")\n",
    "p = Path.cwd().resolve()\n",
    "REPO_ROOT = None\n",
    "for candidate in [p, *p.parents]:\n",
    "    if (candidate / \"src\" / \"imgofup\").is_dir():\n",
    "        REPO_ROOT = candidate\n",
    "        break\n",
    "if REPO_ROOT is None:\n",
    "    raise RuntimeError(\"Could not find repo root (no 'src/imgofup' found).\")\n",
    "\n",
    "SRC_DIR = REPO_ROOT / \"src\"\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "# Make config stable\n",
    "os.environ[\"PROJ_ROOT\"] = str(REPO_ROOT)\n",
    "\n",
    "print(\"ðŸ“¦ Repo root:\", REPO_ROOT)\n",
    "print(\"ðŸ“¦ Using src from:\", SRC_DIR)\n",
    "print(\"ðŸ”§ PROJ_ROOT env set to:\", os.environ[\"PROJ_ROOT\"])\n",
    "\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5b544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Experiments:\n",
      " - openai_prompt_only | mode=prompt_only    | prompt=openai-small  \n",
      " - use_prompt_only    | mode=prompt_only    | prompt=dan           \n",
      " - map_only           | mode=map_only       | prompt=-             \n",
      " - use_map            | mode=prompt_plus_map | prompt=dan           \n",
      " - openai_map         | mode=prompt_plus_map | prompt=openai-small  \n"
     ]
    }
   ],
   "source": [
    "# ===================== 01_generate_embeddings â€” CELL 1: Experiment registry =====================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    \"openai_prompt_only\": {\n",
    "        \"train_out\": DATA_DIR / \"output\" / \"train_out_openai_prompt_only\",\n",
    "        \"model_out\": DATA_DIR / \"output\" / \"models\" / \"exp_openai_prompt_only\",\n",
    "        \"feature_mode\": \"prompt_only\",\n",
    "        \"prompt_encoder_kind\": \"openai-small\",\n",
    "    },\n",
    "    \"use_prompt_only\": {\n",
    "        \"train_out\": DATA_DIR / \"output\" / \"train_out_use_prompt_only\",\n",
    "        \"model_out\": DATA_DIR / \"output\" / \"models\" / \"exp_use_prompt_only\",\n",
    "        \"feature_mode\": \"prompt_only\",\n",
    "        \"prompt_encoder_kind\": \"dan\",\n",
    "    },\n",
    "    \"map_only\": {\n",
    "        \"train_out\": DATA_DIR / \"output\" / \"train_out_map_only\",\n",
    "        \"model_out\": DATA_DIR / \"output\" / \"models\" / \"exp_map_only\",\n",
    "        \"feature_mode\": \"map_only\",\n",
    "    },\n",
    "    \"use_map\": {\n",
    "        \"train_out\": DATA_DIR / \"output\" / \"train_out_use_map\",\n",
    "        \"model_out\": DATA_DIR / \"output\" / \"models\" / \"exp_use_map\",\n",
    "        \"feature_mode\": \"prompt_plus_map\",\n",
    "        \"prompt_encoder_kind\": \"dan\",\n",
    "    },\n",
    "    \"openai_map\": {\n",
    "        \"train_out\": DATA_DIR / \"output\" / \"train_out_openai_map\",\n",
    "        \"model_out\": DATA_DIR / \"output\" / \"models\" / \"exp_openai_map\",\n",
    "        \"feature_mode\": \"prompt_plus_map\",\n",
    "        \"prompt_encoder_kind\": \"openai-small\",\n",
    "    },\n",
    "}\n",
    "\n",
    "for exp_cfg in EXPERIMENTS.values():\n",
    "    exp_cfg[\"train_out\"] = Path(exp_cfg[\"train_out\"])\n",
    "    exp_cfg[\"model_out\"] = Path(exp_cfg[\"model_out\"])\n",
    "    exp_cfg[\"train_out\"].mkdir(parents=True, exist_ok=True)\n",
    "    exp_cfg[\"model_out\"].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ðŸ§ª Experiments:\")\n",
    "for exp_name, cfg in EXPERIMENTS.items():\n",
    "    pe = cfg.get(\"prompt_encoder_kind\", \"-\")\n",
    "    print(f\" - {exp_name:18s} | mode={cfg['feature_mode']:14s} | prompt={pe:14s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677d9090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running prompt embeddings for experiments that require prompts ===\n",
      "\n",
      "ðŸ“Œ USER_STUDY_XLSX = /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/userstudy/UserStudy.xlsx\n",
      "   is_file: True\n",
      "\n",
      "ðŸ§ª Experiment: openai_prompt_only\n",
      "   feature_mode   : prompt_only\n",
      "   PROMPT_ENCODER : openai-small\n",
      "   Output dir     : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_openai_prompt_only/prompt_out\n",
      "   âœ… Prompt embeddings already exist â€” skipping recomputation.\n",
      "\n",
      "ðŸ§ª Experiment: use_prompt_only\n",
      "   feature_mode   : prompt_only\n",
      "   PROMPT_ENCODER : dan\n",
      "   Output dir     : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_use_prompt_only/prompt_out\n",
      "   âœ… Prompt embeddings already exist â€” skipping recomputation.\n",
      "\n",
      "ðŸ§ª Experiment: map_only\n",
      "   (skip) feature_mode=map_only â†’ no prompt embeddings required.\n",
      "\n",
      "ðŸ§ª Experiment: use_map\n",
      "   feature_mode   : prompt_plus_map\n",
      "   PROMPT_ENCODER : dan\n",
      "   Output dir     : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_use_map/prompt_out\n",
      "   âœ… Prompt embeddings already exist â€” skipping recomputation.\n",
      "\n",
      "ðŸ§ª Experiment: openai_map\n",
      "   feature_mode   : prompt_plus_map\n",
      "   PROMPT_ENCODER : openai-small\n",
      "   Output dir     : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_openai_map/prompt_out\n",
      "   âœ… Prompt embeddings already exist â€” skipping recomputation.\n",
      "\n",
      "âœ… Prompt embedding step finished.\n"
     ]
    }
   ],
   "source": [
    "# ===================== 01_generate_embeddings â€” CELL 2: Prompt embeddings (experiment-scoped) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import replace\n",
    "\n",
    "from imgofup.config import paths\n",
    "from imgofup.config.constants import (\n",
    "    PROMPT_EMBEDDINGS_NPZ_NAME,\n",
    "    PROMPTS_PARQUET_NAME,\n",
    "    PROMPT_EMBED_VERBOSITY_DEFAULT,\n",
    "    PROMPT_EMBED_L2_NORMALIZE_DEFAULT,\n",
    "    PROMPT_EMBED_SAVE_CSV_DEFAULT,\n",
    ")\n",
    "from imgofup.pipelines.run_prompt_embeddings import run_prompt_embeddings_from_config\n",
    "\n",
    "print(\"\\n=== Running prompt embeddings for experiments that require prompts ===\")\n",
    "\n",
    "prompt_meta_by_experiment = {}\n",
    "\n",
    "# IMPORTANT: because prompt_id is now read from Excel, old artifacts may be stale.\n",
    "FORCE_REBUILD_PROMPTS = False  # set True to recompute even if artifacts exist\n",
    "\n",
    "# Validate Excel input path early\n",
    "input_xlsx = Path(paths.PATHS.USER_STUDY_XLSX).expanduser().resolve()\n",
    "print(f\"\\nðŸ“Œ USER_STUDY_XLSX = {input_xlsx}\")\n",
    "print(\"   is_file:\", input_xlsx.is_file())\n",
    "\n",
    "if not input_xlsx.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        f\"USER_STUDY_XLSX is not a file: {input_xlsx}\\n\"\n",
    "        \"Fix: set PROJ_ROOT correctly in Cell 0 OR set USER_STUDY_XLSX env var.\"\n",
    "    )\n",
    "\n",
    "for exp_name, exp_cfg in EXPERIMENTS.items():\n",
    "    feature_mode = exp_cfg[\"feature_mode\"]\n",
    "\n",
    "    if feature_mode == \"map_only\":\n",
    "        print(f\"\\nðŸ§ª Experiment: {exp_name}\")\n",
    "        print(\"   (skip) feature_mode=map_only â†’ no prompt embeddings required.\")\n",
    "        continue\n",
    "\n",
    "    prompt_encoder_kind = exp_cfg.get(\"prompt_encoder_kind\", paths.CFG.PROMPT_ENCODER)\n",
    "    CFG_EXP = replace(paths.CFG, PROMPT_ENCODER=str(prompt_encoder_kind))\n",
    "\n",
    "    # Store prompt artifacts inside each experiment's train_out\n",
    "    prompt_out_dir = Path(exp_cfg[\"train_out\"]) / \"prompt_out\"\n",
    "    prompt_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    emb_npz = prompt_out_dir / PROMPT_EMBEDDINGS_NPZ_NAME\n",
    "    prm_pq  = prompt_out_dir / PROMPTS_PARQUET_NAME\n",
    "\n",
    "    print(f\"\\nðŸ§ª Experiment: {exp_name}\")\n",
    "    print(f\"   feature_mode   : {feature_mode}\")\n",
    "    print(f\"   PROMPT_ENCODER : {CFG_EXP.PROMPT_ENCODER}\")\n",
    "    print(f\"   Output dir     : {prompt_out_dir}\")\n",
    "\n",
    "    if (not FORCE_REBUILD_PROMPTS) and emb_npz.is_file() and prm_pq.is_file():\n",
    "        print(\"   âœ… Prompt embeddings already exist â€” skipping recomputation.\")\n",
    "        meta = {\n",
    "            \"out_dir\": str(prompt_out_dir),\n",
    "            \"embeddings_path\": str(emb_npz),\n",
    "            \"prompts_parquet_path\": str(prm_pq),\n",
    "            \"skipped\": True,\n",
    "        }\n",
    "    else:\n",
    "        meta = run_prompt_embeddings_from_config(\n",
    "            input_path=input_xlsx,\n",
    "            out_dir=prompt_out_dir,\n",
    "            cfg=CFG_EXP,\n",
    "            paths=paths.PATHS,\n",
    "            verbosity=PROMPT_EMBED_VERBOSITY_DEFAULT,\n",
    "            l2_normalize=PROMPT_EMBED_L2_NORMALIZE_DEFAULT,\n",
    "            also_save_embeddings_csv=PROMPT_EMBED_SAVE_CSV_DEFAULT,\n",
    "        )\n",
    "        print(\"   âœ… Prompt embeddings completed.\")\n",
    "\n",
    "    prompt_meta_by_experiment[exp_name] = meta\n",
    "\n",
    "print(\"\\nâœ… Prompt embedding step finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496ab21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Map embeddings (shared across all experiments) ===\n",
      "MAPS_ROOT      : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/input/samples/pairs\n",
      "  is_dir       : True\n",
      "USER_STUDY_XLSX: /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/userstudy/UserStudy.xlsx\n",
      "  is_file      : True\n",
      "Target dir: /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/map_out/shared_extent\n",
      "Artifacts : maps_embeddings.npz | maps.parquet\n",
      "âœ… Map embeddings already exist â€” skipping recomputation.\n",
      "âœ… Map embedding artifacts ready:\n",
      " - /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/map_out/shared_extent/maps_embeddings.npz\n",
      " - /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/map_out/shared_extent/maps.parquet\n"
     ]
    }
   ],
   "source": [
    "# ===================== 01_generate_embeddings â€” CELL 3: Map embeddings (shared) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from imgofup.config import paths\n",
    "from imgofup.config.constants import MAP_EMBEDDINGS_NPZ_NAME, MAPS_PARQUET_NAME\n",
    "from imgofup.pipelines.run_map_embeddings import run_map_embeddings_from_config\n",
    "\n",
    "print(\"\\n=== Map embeddings (shared across all experiments) ===\")\n",
    "\n",
    "maps_root = Path(paths.PATHS.MAPS_ROOT).expanduser().resolve()\n",
    "xlsx_path = Path(paths.PATHS.USER_STUDY_XLSX).expanduser().resolve()\n",
    "\n",
    "print(\"MAPS_ROOT      :\", maps_root)\n",
    "print(\"  is_dir       :\", maps_root.is_dir())\n",
    "print(\"USER_STUDY_XLSX:\", xlsx_path)\n",
    "print(\"  is_file      :\", xlsx_path.is_file())\n",
    "\n",
    "if not maps_root.is_dir():\n",
    "    raise NotADirectoryError(f\"MAPS_ROOT is not a directory: {maps_root}\")\n",
    "if not xlsx_path.is_file():\n",
    "    raise FileNotFoundError(f\"USER_STUDY_XLSX is not a file: {xlsx_path}\")\n",
    "\n",
    "# Compute once and reuse (map embeddings do not depend on prompt backend)\n",
    "MAP_EMB_DIR = Path(paths.PATHS.MAP_OUT) / \"shared_extent\"\n",
    "MAP_EMB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "maps_npz = MAP_EMB_DIR / MAP_EMBEDDINGS_NPZ_NAME\n",
    "maps_pq  = MAP_EMB_DIR / MAPS_PARQUET_NAME\n",
    "\n",
    "FORCE_REBUILD_MAPS = False\n",
    "\n",
    "print(\"Target dir:\", MAP_EMB_DIR)\n",
    "print(\"Artifacts :\", maps_npz.name, \"|\", maps_pq.name)\n",
    "\n",
    "if (not FORCE_REBUILD_MAPS) and maps_npz.is_file() and maps_pq.is_file():\n",
    "    print(\"âœ… Map embeddings already exist â€” skipping recomputation.\")\n",
    "    map_meta = {\"out_dir\": str(MAP_EMB_DIR), \"skipped\": True}\n",
    "else:\n",
    "    map_meta = run_map_embeddings_from_config(\n",
    "        maps_root=maps_root,\n",
    "        input_pattern=paths.PATHS.INPUT_MAPS_PATTERN,\n",
    "        user_study_xlsx=xlsx_path,\n",
    "        responses_sheet=paths.PATHS.RESPONSES_SHEET,\n",
    "        tile_id_col=paths.PATHS.TILE_ID_COL,\n",
    "        complete_col=paths.PATHS.COMPLETE_COL,\n",
    "        remove_col=paths.PATHS.REMOVE_COL,\n",
    "        # shared embeddings: no filtering here (keep stable dataset)\n",
    "        only_complete=False,\n",
    "        exclude_removed=False,\n",
    "        out_dir=MAP_EMB_DIR,\n",
    "        verbosity=1,\n",
    "        norm=\"extent\",\n",
    "    )\n",
    "    print(\"âœ… Map embeddings completed.\")\n",
    "\n",
    "if not maps_npz.is_file():\n",
    "    raise FileNotFoundError(f\"Missing {MAP_EMBEDDINGS_NPZ_NAME} at: {maps_npz}\")\n",
    "if not maps_pq.is_file():\n",
    "    raise FileNotFoundError(f\"Missing {MAPS_PARQUET_NAME} at: {maps_pq}\")\n",
    "\n",
    "print(\"âœ… Map embedding artifacts ready:\")\n",
    "print(\" -\", maps_npz)\n",
    "print(\" -\", maps_pq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc7a85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Inferred MAP_DIM from shared maps: 165\n",
      "\n",
      "âœ… Inferred dims per experiment:\n",
      " - openai_prompt_only | mode=prompt_only    | MAP_DIM=   0 | PROMPT_DIM=1536 | FUSED_DIM=1536\n",
      " - use_prompt_only    | mode=prompt_only    | MAP_DIM=   0 | PROMPT_DIM= 512 | FUSED_DIM= 512\n",
      " - map_only           | mode=map_only       | MAP_DIM= 165 | PROMPT_DIM=   0 | FUSED_DIM= 165\n",
      " - use_map            | mode=prompt_plus_map | MAP_DIM= 165 | PROMPT_DIM= 512 | FUSED_DIM= 677\n",
      " - openai_map         | mode=prompt_plus_map | MAP_DIM= 165 | PROMPT_DIM=1536 | FUSED_DIM=1701\n"
     ]
    }
   ],
   "source": [
    "# ===================== 01_generate_embeddings â€” CELL 4: Infer embedding dimensions =====================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from imgofup.config.constants import MAP_EMBEDDINGS_NPZ_NAME, PROMPT_EMBEDDINGS_NPZ_NAME\n",
    "\n",
    "def _infer_dim_from_npz(npz_path: Path) -> int:\n",
    "    npz_path = Path(npz_path).expanduser().resolve()\n",
    "    if not npz_path.is_file():\n",
    "        raise FileNotFoundError(f\"Missing embeddings file: {npz_path}\")\n",
    "    with np.load(npz_path, allow_pickle=True) as z:\n",
    "        if \"E\" not in z:\n",
    "            raise ValueError(f\"{npz_path} missing array 'E'\")\n",
    "        E = z[\"E\"]\n",
    "    if E.ndim != 2 or E.shape[1] <= 0:\n",
    "        raise ValueError(f\"Invalid embedding matrix in {npz_path}: shape={E.shape}\")\n",
    "    return int(E.shape[1])\n",
    "\n",
    "# Map dim (shared)\n",
    "maps_npz = Path(MAP_EMB_DIR) / MAP_EMBEDDINGS_NPZ_NAME\n",
    "MAP_DIM_INF = _infer_dim_from_npz(maps_npz)\n",
    "print(\"âœ… Inferred MAP_DIM from shared maps:\", MAP_DIM_INF)\n",
    "\n",
    "PROMPT_BASED_MODES = {\"prompt_only\", \"prompt_plus_map\"}\n",
    "dims_by_experiment = {}\n",
    "\n",
    "for exp_name, exp_cfg in EXPERIMENTS.items():\n",
    "    feature_mode = str(exp_cfg[\"feature_mode\"]).strip().lower()\n",
    "\n",
    "    PROMPT_DIM_INF = 0\n",
    "    if feature_mode in PROMPT_BASED_MODES:\n",
    "        prm_npz = Path(exp_cfg[\"train_out\"]) / \"prompt_out\" / PROMPT_EMBEDDINGS_NPZ_NAME\n",
    "        PROMPT_DIM_INF = _infer_dim_from_npz(prm_npz)\n",
    "\n",
    "    if feature_mode == \"prompt_only\":\n",
    "        map_dim, prompt_dim, fused_dim = 0, PROMPT_DIM_INF, PROMPT_DIM_INF\n",
    "    elif feature_mode == \"map_only\":\n",
    "        map_dim, prompt_dim, fused_dim = MAP_DIM_INF, 0, MAP_DIM_INF\n",
    "    elif feature_mode == \"prompt_plus_map\":\n",
    "        map_dim, prompt_dim, fused_dim = MAP_DIM_INF, PROMPT_DIM_INF, MAP_DIM_INF + PROMPT_DIM_INF\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown feature_mode for {exp_name}: {feature_mode}\")\n",
    "\n",
    "    exp_cfg[\"map_dim\"] = int(map_dim)\n",
    "    exp_cfg[\"prompt_dim\"] = int(prompt_dim)\n",
    "    exp_cfg[\"fused_dim\"] = int(fused_dim)\n",
    "\n",
    "    dims_by_experiment[exp_name] = {\n",
    "        \"feature_mode\": feature_mode,\n",
    "        \"MAP_DIM\": int(map_dim),\n",
    "        \"PROMPT_DIM\": int(prompt_dim),\n",
    "        \"FUSED_DIM\": int(fused_dim),\n",
    "    }\n",
    "\n",
    "print(\"\\nâœ… Inferred dims per experiment:\")\n",
    "for exp_name, d in dims_by_experiment.items():\n",
    "    print(\n",
    "        f\" - {exp_name:18s} | mode={d['feature_mode']:14s} | \"\n",
    "        f\"MAP_DIM={d['MAP_DIM']:4d} | PROMPT_DIM={d['PROMPT_DIM']:4d} | FUSED_DIM={d['FUSED_DIM']:4d}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879a1181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Building feature matrices for all experiments ===\n",
      "\n",
      "ðŸ§ª Experiment: openai_prompt_only\n",
      "   Feature mode : prompt_only\n",
      "   Prompt out   : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_openai_prompt_only/prompt_out\n",
      "   Map out      : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/map_out/shared_extent\n",
      "   Train out    : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_openai_prompt_only\n",
      "   âœ… Feature construction completed.\n",
      "\n",
      "ðŸ§ª Experiment: use_prompt_only\n",
      "   Feature mode : prompt_only\n",
      "   Prompt out   : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_use_prompt_only/prompt_out\n",
      "   Map out      : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/map_out/shared_extent\n",
      "   Train out    : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_use_prompt_only\n",
      "   âœ… Feature construction completed.\n",
      "\n",
      "ðŸ§ª Experiment: map_only\n",
      "   Feature mode : map_only\n",
      "   Prompt out   : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_map_only/prompt_out\n",
      "   Map out      : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/map_out/shared_extent\n",
      "   Train out    : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_map_only\n",
      "   Pairs parquet: /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_use_prompt_only/prompt_out/prompts.parquet (shared)\n",
      "   âœ… Feature construction completed.\n",
      "\n",
      "ðŸ§ª Experiment: use_map\n",
      "   Feature mode : prompt_plus_map\n",
      "   Prompt out   : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_use_map/prompt_out\n",
      "   Map out      : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/map_out/shared_extent\n",
      "   Train out    : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_use_map\n",
      "   âœ… Feature construction completed.\n",
      "\n",
      "ðŸ§ª Experiment: openai_map\n",
      "   Feature mode : prompt_plus_map\n",
      "   Prompt out   : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_openai_map/prompt_out\n",
      "   Map out      : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/map_out/shared_extent\n",
      "   Train out    : /Users/amirdonyadide/Documents/GitHub/IMGOFUP/data/output/train_out_openai_map\n",
      "   âœ… Feature construction completed.\n",
      "\n",
      "âœ… All feature construction finished.\n"
     ]
    }
   ],
   "source": [
    "# ===================== 01_generate_embeddings â€” CELL 5: Feature construction (multi-experiment) =====================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from imgofup.pipelines.run_concat_features import run_concat_features_from_dirs\n",
    "from imgofup.config.constants import PROMPTS_PARQUET_NAME\n",
    "\n",
    "print(\"\\n=== Building feature matrices for all experiments ===\")\n",
    "\n",
    "concat_meta_by_experiment = {}\n",
    "\n",
    "# Because prompt_id changed, you should rebuild features at least once.\n",
    "FORCE_REBUILD_FEATURES = True  # set False later when stable\n",
    "\n",
    "# Choose a canonical prompts.parquet source for map_only (pairs table)\n",
    "PAIRS_SOURCE_EXP = \"use_prompt_only\"\n",
    "PAIRS_PARQUET_CANON = Path(EXPERIMENTS[PAIRS_SOURCE_EXP][\"train_out\"]) / \"prompt_out\" / PROMPTS_PARQUET_NAME\n",
    "\n",
    "if not PAIRS_PARQUET_CANON.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Expected prompts parquet for map_only at:\\n  {PAIRS_PARQUET_CANON}\\n\"\n",
    "        f\"Run CELL 2 (prompt embeddings) for '{PAIRS_SOURCE_EXP}' first.\"\n",
    "    )\n",
    "\n",
    "for exp_name, exp_cfg in EXPERIMENTS.items():\n",
    "    feature_mode = exp_cfg[\"feature_mode\"]\n",
    "\n",
    "    train_out_dir = Path(exp_cfg[\"train_out\"])\n",
    "    map_out_dir = Path(MAP_EMB_DIR)\n",
    "    prompt_out_dir = train_out_dir / \"prompt_out\"\n",
    "\n",
    "    # For map_only we still need prompts table, but not prompt embeddings\n",
    "    pairs_parquet = PAIRS_PARQUET_CANON if feature_mode == \"map_only\" else None\n",
    "\n",
    "    print(f\"\\nðŸ§ª Experiment: {exp_name}\")\n",
    "    print(f\"   Feature mode : {feature_mode}\")\n",
    "    print(f\"   Prompt out   : {prompt_out_dir}\")\n",
    "    print(f\"   Map out      : {map_out_dir}\")\n",
    "    print(f\"   Train out    : {train_out_dir}\")\n",
    "    if pairs_parquet is not None:\n",
    "        print(f\"   Pairs parquet: {pairs_parquet} (shared)\")\n",
    "\n",
    "    X_expected = train_out_dir / f\"X_{exp_name}.npy\"\n",
    "    pairs_expected = train_out_dir / f\"train_pairs_{exp_name}.parquet\"\n",
    "\n",
    "    if (not FORCE_REBUILD_FEATURES) and X_expected.is_file() and pairs_expected.is_file():\n",
    "        print(\"   âœ… Features already exist â€” skipping recomputation.\")\n",
    "        meta = {\"skipped\": True, \"X_path\": str(X_expected), \"pairs_path\": str(pairs_expected)}\n",
    "    else:\n",
    "        meta = run_concat_features_from_dirs(\n",
    "            prompt_out_dir=prompt_out_dir,\n",
    "            map_out_dir=map_out_dir,\n",
    "            out_dir=train_out_dir,\n",
    "            exp_name=exp_name,\n",
    "            feature_mode=feature_mode,\n",
    "            verbosity=1,\n",
    "            prompt_id_width=4,\n",
    "            pairs_parquet=pairs_parquet,\n",
    "        )\n",
    "        print(\"   âœ… Feature construction completed.\")\n",
    "\n",
    "    concat_meta_by_experiment[exp_name] = meta\n",
    "\n",
    "print(\"\\nâœ… All feature construction finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c5af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
